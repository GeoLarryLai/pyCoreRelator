{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# **pyCoreRelator** [![GitHub](https://img.shields.io/badge/GitHub-pyCoreRelator-blue?logo=github)](https://github.com/GeoLarryLai/pyCoreRelator) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.xxxxxxxx.svg)](https://doi.org/10.5281/zenodo.xxxxxxxx)\n",
    "## **Workshop Notebook #7: Compare Real Core Correlation to Synthetic Null Hypothesis**   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GeoLarryLai/pyCoreRelator/blob/main/pyCoreRelator_7_compare2syn.ipynb)\n",
    "This notebook demonstrates the workflow for comparing real core pair correlation quality metrics against synthetic null hypothesis distributions using **pyCoreRelator**.\n",
    "\n",
    "### Key Functions from **pyCoreRelator**\n",
    "- **`load_core_log_data()`**: Load and process core log data with picked depths\n",
    "- **`load_core_age_constraints()`**: Load age constraint data for cores\n",
    "- **`load_pickeddepth_ages_from_csv()`**: Load estimated ages for picked boundaries\n",
    "- **`run_multi_parameter_analysis()`**: Run correlation analysis with multiple parameter combinations\n",
    "- **`calculate_quality_comparison_t_statistics()`**: Calculate statistical comparison metrics\n",
    "- **`plot_quality_comparison_t_statistics()`**: Visualize comparison results\n",
    "\n",
    "For advanced usage, see [FUNCTION_DOCUMENTATION.md](https://github.com/GeoLarryLai/pyCoreRelator/blob/main/FUNCTION_DOCUMENTATION.md) for more details.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4awuK6ffO2t"
   },
   "source": [
    "# **0. Check Installation**\n",
    "Check if **pyCoreRelator** is installed and install if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "%pip install pycorerelator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages**\n",
    "Load correlation analysis and comparison functions from **pyCoreRelator**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyCoreRelator import (\n",
    "    load_core_log_data,\n",
    "    load_core_age_constraints,\n",
    "    load_pickeddepth_ages_from_csv,\n",
    "    run_multi_parameter_analysis,\n",
    "    calculate_quality_comparison_t_statistics,\n",
    "    plot_quality_comparison_t_statistics\n",
    ")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Configure Core Pair Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Core Pair\n",
    "\n",
    "Select which cores to correlate (Core A and Core B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_A = \"M9907-25PC\"\n",
    "# CORE_A = \"M9907-23PC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_B = \"M9907-23PC\"\n",
    "# CORE_B = \"M9907-11PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check and Download Example Data**\n",
    "Download necessary example data if not already present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "cores = [\"M9907-25PC\", \"M9907-23PC\"]  # Change as needed\n",
    "\n",
    "print(\"Checking for example data...\")\n",
    "if not all(os.path.exists(f\"example_data/processed_data/{c}/{c}_hiresMS_MLfilled.csv\") for c in cores):\n",
    "    print(\"Downloading...\")\n",
    "    for core in cores:\n",
    "        os.makedirs(f\"example_data/processed_data/{core}\", exist_ok=True)\n",
    "        os.makedirs(\"example_data/picked_datum\", exist_ok=True)\n",
    "        os.makedirs(\"example_data/raw_data/C14age_data\", exist_ok=True)\n",
    "        os.makedirs(\"example_data/analytical_outputs\", exist_ok=True)\n",
    "        for path in [f\"processed_data/{core}/{core}_hiresMS_MLfilled.csv\", f\"processed_data/{core}/{core}_CT_MLfilled.csv\",\n",
    "                     f\"processed_data/{core}/{core}_RGB_MLfilled.csv\", f\"picked_datum/{core}_pickeddepth.csv\",\n",
    "                     f\"picked_datum/{core}_pickeddepth_ages_MonteCarlo.csv\", f\"raw_data/C14age_data/{core}_C14.csv\"]:\n",
    "            try:\n",
    "                with open(f\"example_data/{path}\", \"wb\") as f:\n",
    "                    f.write(requests.get(f\"https://github.com/GeoLarryLai/pyCoreRelator/raw/main/example_data/{path}\").content)\n",
    "            except: pass\n",
    "    for path in [\"analytical_outputs/synthetic_PDFs_hiresMS_CT_Lumin_corr_coef.csv\",\n",
    "                 \"analytical_outputs/synthetic_PDFs_hiresMS_CT_Lumin_norm_dtw.csv\"]:\n",
    "        try:\n",
    "            with open(f\"example_data/{path}\", \"wb\") as f:\n",
    "                f.write(requests.get(f\"https://github.com/GeoLarryLai/pyCoreRelator/raw/main/example_data/{path}\").content)\n",
    "        except: pass\n",
    "    print(\"Download complete\")\n",
    "else:\n",
    "    print(\"âœ“ Data already exists\")\n",
    "\n",
    "print(\"Ready to proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Log Data Paths and Column Structure\n",
    "\n",
    "Configure which log types to use for correlation and specify file paths for each core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log columns to extract\n",
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "# LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "\n",
    "# Define paths for Core A\n",
    "core_a_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_A}/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_A}/{CORE_A}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_A}/{CORE_A}_RGB_MLfilled.csv',\n",
    "}\n",
    "\n",
    "# Define paths for Core B\n",
    "core_b_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_B}/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_B}/{CORE_B}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_B}/{CORE_B}_RGB_MLfilled.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Log Data and Picked Depths\n",
    "\n",
    "**Function: `load_core_log_data()`**\n",
    "\n",
    "**What it does:**\n",
    "Loads and processes core log data from CSV files, resamples to common depth scale, and loads picked stratigraphic boundaries.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_paths` *(dict)*: Dictionary mapping log names to CSV file paths\n",
    "- `core_name` *(str)*: Name of the core for identification\n",
    "- `log_columns` *(list, optional)*: List of log column names to extract from CSV files. If None, uses all keys from log_paths\n",
    "- `depth_column` *(str, default='SB_DEPTH_cm')*: Name of the depth column in CSV files\n",
    "- `normalize` *(bool, default=True)*: Whether to normalize log values to [0, 1] range\n",
    "- `picked_datum` *(str, optional)*: Path to CSV file containing picked depths\n",
    "- `categories` *(int, list, optional)*: Category or categories to filter (e.g., 1 or [1, 2])\n",
    "- `show_fig` *(bool, default=True)*: Whether to display visualization\n",
    "\n",
    "**Returns:**\n",
    "- `log` (numpy.ndarray): Log data array with shape (n_samples, n_logs) or (n_samples,) for single log\n",
    "- `md` (numpy.ndarray): Measured depth array\n",
    "- `picked_depths` (list): List of picked depth values for specified categories\n",
    "- `interpreted_bed` (list): List of interpreted bed names corresponding to picked depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for Core A\n",
    "log_a, md_a, picked_depths_a, interpreted_bed_a = load_core_log_data(\n",
    "    log_paths=core_a_log_paths,\n",
    "    core_name=CORE_A,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column='SB_DEPTH_cm',\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_A}_pickeddepth.csv',\n",
    "    categories=[1],\n",
    "    show_fig=False\n",
    ")\n",
    "\n",
    "# Load data for Core B\n",
    "log_b, md_b, picked_depths_b, interpreted_bed_b = load_core_log_data(\n",
    "    log_paths=core_b_log_paths,\n",
    "    core_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column='SB_DEPTH_cm',\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_B}_pickeddepth.csv',\n",
    "    categories=[1],\n",
    "    show_fig=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Age Constraints\n",
    "\n",
    "**Function: `load_core_age_constraints()`**\n",
    "\n",
    "**What it does:**\n",
    "Loads age constraint data for a single core from CSV files in a directory. Searches for all CSV files containing the core name and combines them.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `core_name` *(str)*: Name of the core to load age constraints for\n",
    "- `age_base_path` *(str)*: Base directory path containing age constraint CSV files\n",
    "- `data_columns` *(dict, default=None)*: Dictionary mapping standard column names to actual CSV column names. Required keys: 'age', 'pos_error', 'neg_error', 'min_depth', 'max_depth', 'in_sequence', 'core', 'interpreted_bed'\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress all print statements\n",
    "\n",
    "**Returns:**\n",
    "- `age_data` (dict): Dictionary containing age constraint data with keys:\n",
    "  - `depths` (list): Mean depths of age constraints\n",
    "  - `ages` (list): Calibrated ages in years BP\n",
    "  - `pos_errors` (list): Positive 2-sigma uncertainties\n",
    "  - `neg_errors` (list): Negative 2-sigma uncertainties\n",
    "  - `in_sequence_flags` (list): Boolean flags for stratigraphic sequence\n",
    "  - `in_sequence_depths`, `in_sequence_ages`, `in_sequence_pos_errors`, `in_sequence_neg_errors` (lists): Filtered in-sequence data\n",
    "  - `out_sequence_depths`, `out_sequence_ages`, `out_sequence_pos_errors`, `out_sequence_neg_errors` (lists): Out-of-sequence data\n",
    "  - `core` (list): Core identifiers\n",
    "  - `interpreted_bed` (list): Interpreted bed names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staisch2024 = {\n",
    "    'age': 'calib810_agebp',\n",
    "    'pos_error': 'calib810_2sigma_pos', \n",
    "    'neg_error': 'calib810_2sigma_neg',\n",
    "    'min_depth': 'mindepth_cm',\n",
    "    'max_depth': 'maxdepth_cm',\n",
    "    'in_sequence': 'in_sequence',\n",
    "    'core': 'core',\n",
    "    'interpreted_bed': 'interpreted_bed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data_a = load_core_age_constraints(\n",
    "    CORE_A,\n",
    "    age_base_path='example_data/raw_data/C14age_data',\n",
    "    data_columns=staisch2024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data_b = load_core_age_constraints(\n",
    "    CORE_B,\n",
    "    age_base_path='example_data/raw_data/C14age_data',\n",
    "    data_columns=staisch2024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Estimated Ages for Picked Boundaries\n",
    "\n",
    "**Function: `load_pickeddepth_ages_from_csv()`**\n",
    "\n",
    "**What it does:**\n",
    "Loads pre-calculated interpolated ages for picked depth boundaries from CSV file (output from `calculate_interpolated_ages()`).\n",
    "\n",
    "**Key Parameters:**\n",
    "- `pickeddepth_age_csv` *(str)*: Path to CSV file containing pre-calculated ages\n",
    "\n",
    "**Returns:**\n",
    "- `age_data` (dict): Dictionary containing age estimates with keys:\n",
    "  - `depths` (numpy.ndarray): Picked datum depths\n",
    "  - `ages` (numpy.ndarray): Interpolated ages in years BP\n",
    "  - `pos_uncertainties` (numpy.ndarray): Positive age uncertainties\n",
    "  - `neg_uncertainties` (numpy.ndarray): Negative age uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the uncertainty method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "uncertainty_method = 'MonteCarlo'   \n",
    "\n",
    "# Load pre-calculated ages for picked depths\n",
    "pickeddepth_ages_a = load_pickeddepth_ages_from_csv(\n",
    "    pickeddepth_age_csv=f\"example_data/picked_datum/{CORE_A}_pickeddepth_ages_{uncertainty_method}.csv\"\n",
    ")\n",
    "\n",
    "pickeddepth_ages_b = load_pickeddepth_ages_from_csv(\n",
    "    pickeddepth_age_csv=f\"example_data/picked_datum/{CORE_B}_pickeddepth_ages_{uncertainty_method}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Comprehensive DTW Analysis\n",
    "\n",
    "**Function: `run_multi_parameter_analysis()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Runs DTW correlation analysis for multiple parameter combinations (with/without age constraints)\n",
    "2. Tests scenarios with progressive removal of age constraints (if enabled)\n",
    "3. Computes quality metric distributions for each scenario\n",
    "4. Fits probability distributions and calculates statistical parameters\n",
    "5. Exports fit parameters and distribution data to CSV files for comparison\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_a`, `log_b` *(array-like)*: Core log data arrays\n",
    "- `md_a`, `md_b` *(array-like)*: Measured depth arrays\n",
    "- `picked_datum_a`, `picked_datum_b` *(list)*: Picked boundary depths (category 1)\n",
    "- `datum_ages_a`, `datum_ages_b` *(dict)*: Age interpolation results for picked depths with keys: 'depths', 'ages', 'pos_uncertainties', 'neg_uncertainties'\n",
    "- `core_a_age_data`, `core_b_age_data` *(dict)*: Age constraint data from `load_core_age_constraints()`\n",
    "- `uncertainty_method` *(str)*: Age uncertainty calculation method ('MonteCarlo', 'Linear', or 'Gaussian')\n",
    "- `core_a_name`, `core_b_name` *(str)*: Core identifiers for output file naming\n",
    "- `output_csv_directory` *(str)*: Directory path where output CSV files will be saved\n",
    "- `parameter_combinations` *(list of dict)*: List of parameter dictionaries to test. Each dict should contain: 'age_consideration', 'restricted_age_correlation', 'shortest_path_search'\n",
    "- `target_quality_indices` *(list, default=['corr_coef', 'norm_dtw'])*: Quality metrics to analyze (e.g., ['corr_coef', 'norm_dtw', 'perc_diag'])\n",
    "- `log_columns` *(list, optional)*: List of log column names (e.g., ['hiresMS', 'CT', 'Lumin']). If provided, creates subdirectory structure\n",
    "- `test_age_constraint_removal` *(bool, default=True)*: Whether to test progressive age constraint removal scenarios\n",
    "- `synthetic_csv_filenames` *(dict, default=None)*: Dictionary mapping quality_index to synthetic CSV filenames for consistent bin sizing\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent multidimensional DTW\n",
    "- `n_jobs` *(int, default=-1)*: Number of parallel jobs (-1 uses all available CPU cores, 1 for sequential)\n",
    "- `max_search_per_layer` *(int or None, default=None)*: Maximum scenarios per constraint removal layer. Higher values yield more comprehensive results but increase computation time. If None, processes all scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Run Multi-Parameter Correlation Analysis**\n",
    "\n",
    "Execute correlation analysis with different parameter combinations to test various hypotheses and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter combinations to test\n",
    "parameter_combinations = [\n",
    "    {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': True},\n",
    "    {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': True}\n",
    "]\n",
    "\n",
    "# Run the multi-parameter analysis\n",
    "run_multi_parameter_analysis(\n",
    "    log_a, \n",
    "    log_b, \n",
    "    md_a, \n",
    "    md_b,\n",
    "    picked_datum_a=picked_depths_a,\n",
    "    picked_datum_b=picked_depths_b,\n",
    "    datum_ages_a=pickeddepth_ages_a,\n",
    "    datum_ages_b=pickeddepth_ages_b,\n",
    "    core_a_age_data=age_data_a,\n",
    "    core_b_age_data=age_data_b,\n",
    "    uncertainty_method=uncertainty_method,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    max_search_per_layer=50,\n",
    "    output_csv_directory=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}',\n",
    "    parameter_combinations=parameter_combinations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Statistical Comparison Metrics\n",
    "\n",
    "**Function: `calculate_quality_comparison_t_statistics()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads real core correlation quality distributions from output CSV files\n",
    "2. Loads synthetic null hypothesis distributions from synthetic PDF directory\n",
    "3. Calculates t-statistics comparing real vs. synthetic distributions\n",
    "4. Computes percentile rankings and significance levels\n",
    "5. Stores statistical comparison results for visualization\n",
    "\n",
    "**Key Parameters:**\n",
    "- `target_quality_indices` *(list)*: Quality metrics to compare (e.g., ['corr_coef', 'norm_dtw'])\n",
    "- `output_csv_directory` *(str)*: Directory path where output CSV files are located\n",
    "- `input_syntheticPDF_directory` *(str)*: Directory path where synthetic/null hypothesis CSV files are located\n",
    "- `core_a_name`, `core_b_name` *(str)*: Core identifiers\n",
    "- `log_columns` *(list, optional)*: List of log column names (e.g., ['hiresMS', 'CT', 'Lumin']). If provided, creates subdirectory structure\n",
    "- `mute_mode` *(bool, default=False)*: Suppress console output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Compare Real Correlation to Synthetic Null Hypothesis**\n",
    "\n",
    "Calculate statistical comparisons and visualize how real core correlation quality compares to synthetic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quality indices to compare (should match those used in run_multi_parameter_analysis)\n",
    "target_quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "# Define directory paths\n",
    "t_stats_dir = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}'\n",
    "syntheticPDF_dir = 'example_data/analytical_outputs'\n",
    "\n",
    "# Calculate statistical comparison metrics\n",
    "calculate_quality_comparison_t_statistics(\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    output_csv_directory=t_stats_dir,\n",
    "    input_syntheticPDF_directory=syntheticPDF_dir,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    mute_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Static Comparison Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Comparison Results\n",
    "\n",
    "**Function: `plot_quality_comparison_t_statistics()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Creates visualizations comparing real core correlation quality to synthetic null hypothesis\n",
    "2. Plots probability distribution curves overlaying real and synthetic data\n",
    "3. Shows statistical significance and percentile rankings\n",
    "4. Can generate static plots (PNG/PDF/SVG) or animated GIFs showing progressive constraint addition\n",
    "5. Optionally highlights the optimal datum match solution\n",
    "\n",
    "**Key Parameters:**\n",
    "- `target_quality_indices` *(list)*: Quality metrics to plot (e.g., ['corr_coef', 'norm_dtw', 'perc_diag'])\n",
    "- `output_csv_directory` *(str)*: Directory path where output CSV files are located (should contain t-statistics columns)\n",
    "- `input_syntheticPDF_directory` *(str)*: Directory path where synthetic/null hypothesis CSV files are located\n",
    "- `core_a_name` *(str)*: Name of core A for plot titles\n",
    "- `core_b_name` *(str)*: Name of core B for plot titles\n",
    "- `log_columns` *(list, optional)*: List of log column names (e.g., ['hiresMS', 'CT', 'Lumin']). If provided, creates subdirectory structure\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress detailed output messages and show only essential progress information\n",
    "- `save_fig` *(bool, default=False)*: If True, save static figures to files\n",
    "- `output_figure_directory` *(str, default=None)*: Directory path where output figures will be saved (filenames auto-generated, only used when save_fig=True)\n",
    "- `fig_format` *(list, default=['png'])*: List of file formats for saved figures. Accepted formats: 'png', 'jpg', 'svg', 'pdf', 'tiff'. Only used when save_fig=True\n",
    "- `dpi` *(int, default=150)*: Resolution for saved figures in dots per inch. Only used when save_fig=True\n",
    "- `save_gif` *(bool, default=False)*: If True, create animated GIF showing progressive addition of age constraints\n",
    "- `output_gif_directory` *(str, default=None)*: Directory path where GIF files will be saved (filenames auto-generated, only used when save_gif=True)\n",
    "- `max_frames` *(int, default=50)*: Maximum number of frames for GIF animations\n",
    "- `plot_real_data_histogram` *(bool, default=False)*: If True, plot histograms for real data (no age and all age constraint cases)\n",
    "- `plot_age_removal_step_pdf` *(bool, default=False)*: If True, plot all PDF curves including dashed lines for partially removed constraints\n",
    "- `show_best_datum_match` *(bool, default=True)*: If True, plot vertical line showing best datum match value from sequential_mappings_csv\n",
    "- `sequential_mappings_csv` *(str or dict, default=None)*: Path to CSV file(s) containing sequential mappings with 'Ranking_datums' column. Can be a single CSV path (str) or dictionary mapping quality indices to CSV paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quality_comparison_t_statistics(\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    output_csv_directory=t_stats_dir,\n",
    "    input_syntheticPDF_directory=syntheticPDF_dir,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    save_fig=True,\n",
    "    plot_real_data_histogram=True,\n",
    "    output_figure_directory=t_stats_dir,   \n",
    "    sequential_mappings_csv=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_restricted_age_optimal.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Animated GIF Showing Progressive Constraint Addition\n",
    "\n",
    "Create animated visualizations showing how the quality metric distributions evolve as age constraints are progressively removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quality_comparison_t_statistics(\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    output_csv_directory=t_stats_dir,\n",
    "    input_syntheticPDF_directory=syntheticPDF_dir,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    save_gif=True, \n",
    "    output_gif_directory=t_stats_dir,\n",
    "    plot_real_data_histogram=False,\n",
    "    plot_age_removal_step_pdf=True,\n",
    "    sequential_mappings_csv=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_restricted_age_optimal.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
