{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# Correlating well log pairs: Complex Dynamic Time Warping with boundary constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4awuK6ffO2t"
   },
   "source": [
    "## Introduction to dynamic time warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import glob\n",
    "from IPython.display import Image as IPImage, display\n",
    "from scipy import stats\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from itertools import combinations\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    calculate_interpolated_ages,\n",
    "    load_log_data,\n",
    "    load_core_age_constraints,\n",
    "    run_multi_parameter_analysis,\n",
    "    plot_quality_comparison,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Define basic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define core pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define core names as variables for easy reference\n",
    "# CORE_A = \"M9907-22PC\"\n",
    "CORE_A = \"M9907-23PC\"\n",
    "# CORE_A = \"M9907-12PC\"\n",
    "# CORE_A = \"RR0207-56PC\" \n",
    "\n",
    "# CORE_B = \"M9907-23PC\"\n",
    "CORE_B = \"M9907-11PC\"\n",
    "# CORE_B = \"RR0207-56PC\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log data paths and column name structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log columns to extract\n",
    "# LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "# Define directory paths\n",
    "mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "# Define paths for Core A\n",
    "core_a_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "# Define paths for Core B\n",
    "core_b_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "# Define column mapping for alternative column names\n",
    "column_alternatives = {\n",
    "    'hiresMS': ['MS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'R': ['R', 'red', 'Red'],\n",
    "    'G': ['G', 'green', 'Green'],\n",
    "    'B': ['B', 'blue', 'Blue'],\n",
    "    'Lumin': ['luminance', 'Luminance'],\n",
    "    'Den_gm/cc': ['Density', 'density']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for Core A\n",
    "log_a, md_a, _, _, _ = load_log_data(\n",
    "    core_a_log_paths,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    column_alternatives=column_alternatives\n",
    ")\n",
    "\n",
    "# Load data for Core B\n",
    "log_b, md_b, _, _, _ = load_log_data(\n",
    "    core_b_log_paths,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    column_alternatives=column_alternatives\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load picked depth boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define paths to the CSV files\n",
    "pickeddepth_a_csv = f'pickeddepth/{CORE_A}_pickeddepth.csv'\n",
    "pickeddepth_b_csv = f'pickeddepth/{CORE_B}_pickeddepth.csv'\n",
    "\n",
    "# Load picked depths and extract category 1 depths\n",
    "if os.path.exists(pickeddepth_b_csv):\n",
    "    picked_data_b = pd.read_csv(pickeddepth_b_csv)\n",
    "    all_depths_b_cat1 = picked_data_b[picked_data_b['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "else:\n",
    "    print(f\"Warning: {pickeddepth_b_csv} not found. Using empty array for all_depths_b_cat1.\")\n",
    "    all_depths_b_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "if os.path.exists(pickeddepth_a_csv):\n",
    "    picked_data_a = pd.read_csv(pickeddepth_a_csv)\n",
    "    all_depths_a_cat1 = picked_data_a[picked_data_a['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "else:\n",
    "    print(f\"Warning: {pickeddepth_a_csv} not found. Using empty array for all_depths_a_cat1.\")\n",
    "    all_depths_a_cat1 = np.array([]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age constraints for both cores\n",
    "consider_adjacent_core = True\n",
    "\n",
    "data_columns = {\n",
    "    'age': 'calib502_agebp',\n",
    "    'pos_error': 'calib502_2sigma_pos', \n",
    "    'neg_error': 'calib502_2sigma_neg',\n",
    "    'min_depth': 'mindepth_cm',\n",
    "    'max_depth': 'maxdepth_cm',\n",
    "    'in_sequence': 'in_sequence',\n",
    "    'core': 'core',\n",
    "    'interpreted_bed': 'interpreted_bed'\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "age_base_path = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/Age constraints/Goldfinger2012'\n",
    "\n",
    "# Load age constraints for both cores\n",
    "age_data_a = load_core_age_constraints(CORE_A, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "age_data_b = load_core_age_constraints(CORE_B, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "\n",
    "uncertainty_method='MonteCarlo'   # 'MonteCarlo', 'Linear', or 'Gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute estimated ages for each picked depth boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interpolated ages for Core A using the function\n",
    "pickeddepth_ages_a = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=all_depths_a_cat1,                                     # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_a['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_a['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_a['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_a['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_a['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_a['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_a[-1],                                               # max depth of core a\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo iterations\n",
    "    # Visualization and output\n",
    "    show_plot=False,                                                      # display plot\n",
    "    core_name=CORE_A,                                                    # core name for plot title\n",
    "    export_csv=False,                                                    # export results to CSV\n",
    "    mute_mode=True\n",
    ")\n",
    "\n",
    "# Calculate interpolated ages for Core B using the function\n",
    "pickeddepth_ages_b = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=all_depths_b_cat1,                                     # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_b['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_b['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_b['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_b['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_b['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_b['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_b[-1],                                               # max depth of core b\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo sampling iterations\n",
    "    # Visualization and output\n",
    "    show_plot=False,                                                      # display plot\n",
    "    core_name=CORE_B,                                                    # core name for plot title\n",
    "    export_csv=False,                                                    # export results to CSV\n",
    "    mute_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Compute quality metric distribution for all stituation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Multi-Parameter Distribution Analysis\n",
    "\n",
    "test_age_constraint_removal = True  # Set to False to disable age constraint removal testing\n",
    "\n",
    "# Run all parameter combinations and plot distribution curves together\n",
    "\n",
    "# Define all parameter combinations to test\n",
    "parameter_combinations = [\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': False},\n",
    "    {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': True},\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': True},\n",
    "    # {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "    {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': True}\n",
    "]\n",
    "\n",
    "# Define all quality indices to process\n",
    "target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag']\n",
    "\n",
    "# Set up output CSV filenames\n",
    "if LOG_COLUMNS == ['hiresMS']:\n",
    "    log_suffix = 'MSonly'\n",
    "elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "    log_suffix = 'MSCTLumin'\n",
    "else:\n",
    "    log_suffix = 'unspecified'\n",
    "\n",
    "output_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        output_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "    else:\n",
    "        output_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "# Execute the analysis function\n",
    "run_multi_parameter_analysis(\n",
    "    # Core data inputs\n",
    "    log_a=log_a, \n",
    "    log_b=log_b, \n",
    "    md_a=md_a, \n",
    "    md_b=md_b,\n",
    "    all_depths_a_cat1=all_depths_a_cat1,\n",
    "    all_depths_b_cat1=all_depths_b_cat1,\n",
    "    pickeddepth_ages_a=pickeddepth_ages_a,\n",
    "    pickeddepth_ages_b=pickeddepth_ages_b,\n",
    "    age_data_a=age_data_a,\n",
    "    age_data_b=age_data_b,\n",
    "    uncertainty_method=uncertainty_method,\n",
    "    \n",
    "    # Analysis parameters\n",
    "    parameter_combinations=parameter_combinations,\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    test_age_constraint_removal=test_age_constraint_removal,\n",
    "    \n",
    "    # Core identifiers\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    \n",
    "    # Output configuration\n",
    "    output_csv_filenames=output_csv_filenames,\n",
    "    \n",
    "    # Optional parameters\n",
    "    log_columns=LOG_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting: compare the quality metric to the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names outside the function\n",
    "target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag', 'dtw_warp_eff']\n",
    "\n",
    "# Set up log suffix based on LOG_COLUMNS (assuming these variables are defined earlier)\n",
    "if LOG_COLUMNS == ['hiresMS']:\n",
    "    log_suffix = 'MSonly'\n",
    "elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "    log_suffix = 'MSCTLumin'\n",
    "else:\n",
    "    log_suffix = 'unspecified'\n",
    "\n",
    "# Define master CSV filenames\n",
    "master_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        master_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "    else:\n",
    "        master_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "# Define synthetic CSV filenames\n",
    "synthetic_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    synthetic_csv_filenames[quality_index] = f'outputs/synthetic_PDFs_{log_suffix}_{quality_index}.csv'\n",
    "\n",
    "# Define output figure filenames\n",
    "output_figure_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        output_figure_filenames[quality_index] = f'outputs/r-values_comparison_{log_suffix}_{CORE_A}_{CORE_B}.png'\n",
    "    else:\n",
    "        output_figure_filenames[quality_index] = f'outputs/{quality_index}_comparison_{log_suffix}_{CORE_A}_{CORE_B}.png'\n",
    "\n",
    "# Use the function to produce EXACTLY the same result as the current code\n",
    "plot_quality_comparison(\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    master_csv_filenames=master_csv_filenames,\n",
    "    synthetic_csv_filenames=synthetic_csv_filenames,\n",
    "    output_figure_filenames=output_figure_filenames,\n",
    "    CORE_A=CORE_A,\n",
    "    CORE_B=CORE_B,\n",
    "    debug=True  # Set to False for detailed output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "## Loop Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-12PC vs M9907-11PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [04:29<00:00, 134.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 4/5 constraints: 100%|██████████| 30/30 [19:22<00:00, 38.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 completed: All age constraint removal scenarios processed\n",
      "\n",
      "✓ All processing completed\n",
      "✓ corr_coef fit_params saved to: outputs/r-values_fit_params_MSonly_M9907-12PC_M9907-11PC.csv\n",
      "✓ norm_dtw fit_params saved to: outputs/norm_dtw_fit_params_MSonly_M9907-12PC_M9907-11PC.csv\n",
      "✓ perc_diag fit_params saved to: outputs/perc_diag_fit_params_MSonly_M9907-12PC_M9907-11PC.csv\n",
      "Completed processing: M9907-12PC vs M9907-11PC\n",
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-12PC vs M9907-23PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [03:06<00:00, 93.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 4/5 constraints: 100%|██████████| 30/30 [07:30<00:00, 15.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 completed: All age constraint removal scenarios processed\n",
      "\n",
      "✓ All processing completed\n",
      "✓ corr_coef fit_params saved to: outputs/r-values_fit_params_MSonly_M9907-12PC_M9907-23PC.csv\n",
      "✓ norm_dtw fit_params saved to: outputs/norm_dtw_fit_params_MSonly_M9907-12PC_M9907-23PC.csv\n",
      "✓ perc_diag fit_params saved to: outputs/perc_diag_fit_params_MSonly_M9907-12PC_M9907-23PC.csv\n",
      "Completed processing: M9907-12PC vs M9907-23PC\n",
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-23PC vs M9907-11PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [02:31<00:00, 75.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 4/5 constraints: 100%|██████████| 30/30 [04:59<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 completed: All age constraint removal scenarios processed\n",
      "\n",
      "✓ All processing completed\n",
      "✓ corr_coef fit_params saved to: outputs/r-values_fit_params_MSonly_M9907-23PC_M9907-11PC.csv\n",
      "✓ norm_dtw fit_params saved to: outputs/norm_dtw_fit_params_MSonly_M9907-23PC_M9907-11PC.csv\n",
      "✓ perc_diag fit_params saved to: outputs/perc_diag_fit_params_MSonly_M9907-23PC_M9907-11PC.csv\n",
      "Completed processing: M9907-23PC vs M9907-11PC\n",
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-25PC vs M9907-11PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [02:49<00:00, 84.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 4/5 constraints: 100%|██████████| 30/30 [04:19<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 completed: All age constraint removal scenarios processed\n",
      "\n",
      "✓ All processing completed\n",
      "✓ corr_coef fit_params saved to: outputs/r-values_fit_params_MSonly_M9907-25PC_M9907-11PC.csv\n",
      "✓ norm_dtw fit_params saved to: outputs/norm_dtw_fit_params_MSonly_M9907-25PC_M9907-11PC.csv\n",
      "✓ perc_diag fit_params saved to: outputs/perc_diag_fit_params_MSonly_M9907-25PC_M9907-11PC.csv\n",
      "Completed processing: M9907-25PC vs M9907-11PC\n",
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-25PC vs M9907-23PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [01:39<00:00, 49.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 4/5 constraints: 100%|██████████| 30/30 [07:12<00:00, 14.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 2 completed: All age constraint removal scenarios processed\n",
      "\n",
      "✓ All processing completed\n",
      "✓ corr_coef fit_params saved to: outputs/r-values_fit_params_MSonly_M9907-25PC_M9907-23PC.csv\n",
      "✓ norm_dtw fit_params saved to: outputs/norm_dtw_fit_params_MSonly_M9907-25PC_M9907-23PC.csv\n",
      "✓ perc_diag fit_params saved to: outputs/perc_diag_fit_params_MSonly_M9907-25PC_M9907-23PC.csv\n",
      "Completed processing: M9907-25PC vs M9907-23PC\n",
      "\n",
      "================================================================================\n",
      "Processing core pair: M9907-30PC vs M9907-11PC\n",
      "================================================================================\n",
      "Running 2 parameter combinations for 3 quality indices...\n",
      "Age constraint removal testing enabled:\n",
      "- Core B has 5 age constraints\n",
      "- Additional scenarios to process: 30\n",
      "\n",
      "=== PHASE 1: Running original parameter combinations ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original parameter combinations: 100%|██████████| 2/2 [04:38<00:00, 139.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All original parameter combinations processed\n",
      "\n",
      "=== PHASE 2: Running age constraint removal scenarios ===\n",
      "- Core B has 5 age constraints\n",
      "- Processing 30 additional constraint removal scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint scenario: 2/5 constraints:  23%|██▎       | 7/30 [10:27<35:07, 91.63s/it]"
     ]
    }
   ],
   "source": [
    "# Define all core options\n",
    "CORE_A_OPTIONS = [\"M9907-12PC\", \"M9907-23PC\", \"M9907-25PC\", \"M9907-30PC\", \"M9907-31PC\", \"RR0207-56PC\"]\n",
    "CORE_B_OPTIONS = [\"M9907-11PC\", \"M9907-23PC\"]\n",
    "\n",
    "# Loop through all valid combinations of CORE_A and CORE_B\n",
    "for CORE_A in CORE_A_OPTIONS:\n",
    "    for CORE_B in CORE_B_OPTIONS:\n",
    "        # Skip if CORE_A and CORE_B are the same\n",
    "        if CORE_A == CORE_B:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing core pair: {CORE_A} vs {CORE_B}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Define log columns to extract\n",
    "        # LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "        LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "        DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "        # Define directory paths\n",
    "        mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "        # Define paths for Core A\n",
    "        core_a_log_paths = {\n",
    "            'hiresMS': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "            'CT': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_CT_MLfilled.csv',\n",
    "            'Lumin': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "            'R': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "            'G': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "            'B': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "            'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_MST_MLfilled.csv'\n",
    "        }\n",
    "\n",
    "        # Define paths for Core B\n",
    "        core_b_log_paths = {\n",
    "            'hiresMS': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "            'CT': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_CT_MLfilled.csv',\n",
    "            'Lumin': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "            'R': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "            'G': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "            'B': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "            'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_MST_MLfilled.csv'\n",
    "        }\n",
    "\n",
    "        # Define column mapping for alternative column names\n",
    "        column_alternatives = {\n",
    "            'hiresMS': ['MS'],\n",
    "            'CT': ['CT_value'],\n",
    "            'R': ['R', 'red', 'Red'],\n",
    "            'G': ['G', 'green', 'Green'],\n",
    "            'B': ['B', 'blue', 'Blue'],\n",
    "            'Lumin': ['luminance', 'Luminance'],\n",
    "            'Den_gm/cc': ['Density', 'density']\n",
    "        }\n",
    "\n",
    "        # Load data for Core A\n",
    "        log_a, md_a, _, _, _ = load_log_data(\n",
    "            core_a_log_paths,\n",
    "            log_columns=LOG_COLUMNS,\n",
    "            depth_column=DEPTH_COLUMN,\n",
    "            normalize=True,\n",
    "            column_alternatives=column_alternatives\n",
    "        )\n",
    "\n",
    "        # Load data for Core B\n",
    "        log_b, md_b, _, _, _ = load_log_data(\n",
    "            core_b_log_paths,\n",
    "            log_columns=LOG_COLUMNS,\n",
    "            depth_column=DEPTH_COLUMN,\n",
    "            normalize=True,\n",
    "            column_alternatives=column_alternatives\n",
    "        )\n",
    "\n",
    "        %matplotlib inline\n",
    "\n",
    "        # Define paths to the CSV files\n",
    "        pickeddepth_a_csv = f'pickeddepth/{CORE_A}_pickeddepth.csv'\n",
    "        pickeddepth_b_csv = f'pickeddepth/{CORE_B}_pickeddepth.csv'\n",
    "\n",
    "        # Load picked depths and extract category 1 depths\n",
    "        if os.path.exists(pickeddepth_b_csv):\n",
    "            picked_data_b = pd.read_csv(pickeddepth_b_csv)\n",
    "            all_depths_b_cat1 = picked_data_b[picked_data_b['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "        else:\n",
    "            print(f\"Warning: {pickeddepth_b_csv} not found. Using empty array for all_depths_b_cat1.\")\n",
    "            all_depths_b_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "        if os.path.exists(pickeddepth_a_csv):\n",
    "            picked_data_a = pd.read_csv(pickeddepth_a_csv)\n",
    "            all_depths_a_cat1 = picked_data_a[picked_data_a['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "        else:\n",
    "            print(f\"Warning: {pickeddepth_a_csv} not found. Using empty array for all_depths_a_cat1.\")\n",
    "            all_depths_a_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "        # Load age constraints for both cores\n",
    "        consider_adjacent_core = True\n",
    "\n",
    "        data_columns = {\n",
    "            'age': 'calib502_agebp',\n",
    "            'pos_error': 'calib502_2sigma_pos', \n",
    "            'neg_error': 'calib502_2sigma_neg',\n",
    "            'min_depth': 'mindepth_cm',\n",
    "            'max_depth': 'maxdepth_cm',\n",
    "            'in_sequence': 'in_sequence',\n",
    "            'core': 'core',\n",
    "            'interpreted_bed': 'interpreted_bed'\n",
    "        }\n",
    "\n",
    "        # Configuration\n",
    "        age_base_path = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/Age constraints/Goldfinger2012'\n",
    "\n",
    "        # Load age constraints for both cores\n",
    "        age_data_a = load_core_age_constraints(CORE_A, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "        age_data_b = load_core_age_constraints(CORE_B, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "\n",
    "        uncertainty_method='MonteCarlo'   # 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "\n",
    "        # Calculate interpolated ages for Core A using the function\n",
    "        pickeddepth_ages_a = calculate_interpolated_ages(\n",
    "            # Input data\n",
    "            picked_depths=all_depths_a_cat1,                                     # depths to interpolate ages for\n",
    "            age_constraints_depths=age_data_a['depths'],                         # age constraint depths\n",
    "            age_constraints_ages=age_data_a['ages'],                             # age constraint ages\n",
    "            age_constraints_pos_errors=age_data_a['pos_errors'],                 # positive errors\n",
    "            age_constraints_neg_errors=age_data_a['neg_errors'],                 # negative errors\n",
    "            age_constraints_in_sequence_flags=age_data_a['in_sequence_flags'],   # in-sequence flags\n",
    "            age_constraint_source_core=age_data_a['core'],                       # source core for each constraint\n",
    "            # Core boundaries\n",
    "            top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "            top_depth=0.0,                                                       # top of core depth\n",
    "            bottom_depth=md_a[-1],                                               # max depth of core a\n",
    "            top_age=0,                                                           # default age at top of core\n",
    "            top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "            top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "            # Uncertainty calculation\n",
    "            uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "            n_monte_carlo=10000,                                                 # number of Monte Carlo iterations\n",
    "            # Visualization and output\n",
    "            show_plot=False,                                                      # display plot\n",
    "            core_name=CORE_A,                                                    # core name for plot title\n",
    "            export_csv=False,                                                    # export results to CSV\n",
    "            mute_mode=True\n",
    "        )\n",
    "\n",
    "        # Calculate interpolated ages for Core B using the function\n",
    "        pickeddepth_ages_b = calculate_interpolated_ages(\n",
    "            # Input data\n",
    "            picked_depths=all_depths_b_cat1,                                     # depths to interpolate ages for\n",
    "            age_constraints_depths=age_data_b['depths'],                         # age constraint depths\n",
    "            age_constraints_ages=age_data_b['ages'],                             # age constraint ages\n",
    "            age_constraints_pos_errors=age_data_b['pos_errors'],                 # positive errors\n",
    "            age_constraints_neg_errors=age_data_b['neg_errors'],                 # negative errors\n",
    "            age_constraints_in_sequence_flags=age_data_b['in_sequence_flags'],   # in-sequence flags\n",
    "            age_constraint_source_core=age_data_b['core'],                       # source core for each constraint\n",
    "            # Core boundaries\n",
    "            top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "            top_depth=0.0,                                                       # top of core depth\n",
    "            bottom_depth=md_b[-1],                                               # max depth of core b\n",
    "            top_age=0,                                                           # default age at top of core\n",
    "            top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "            top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "            # Uncertainty calculation\n",
    "            uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "            n_monte_carlo=10000,                                                 # number of Monte Carlo sampling iterations\n",
    "            # Visualization and output\n",
    "            show_plot=False,                                                      # display plot\n",
    "            core_name=CORE_B,                                                    # core name for plot title\n",
    "            export_csv=False,                                                    # export results to CSV\n",
    "            mute_mode=True\n",
    "        )\n",
    "\n",
    "        # Cell: Multi-Parameter Distribution Analysis\n",
    "\n",
    "        test_age_constraint_removal = True  # Set to False to disable age constraint removal testing\n",
    "\n",
    "        # Run all parameter combinations and plot distribution curves together\n",
    "\n",
    "        # Define all parameter combinations to test\n",
    "        parameter_combinations = [\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': False},\n",
    "            {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': True},\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': True},\n",
    "            # {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "            {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': True}\n",
    "        ]\n",
    "\n",
    "        # Define all quality indices to process\n",
    "        target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag']\n",
    "\n",
    "        # Set up output CSV filenames\n",
    "        if LOG_COLUMNS == ['hiresMS']:\n",
    "            log_suffix = 'MSonly'\n",
    "        elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "            log_suffix = 'MSCTLumin'\n",
    "        else:\n",
    "            log_suffix = 'unspecified'\n",
    "\n",
    "        output_csv_filenames = {}\n",
    "        for quality_index in target_quality_indices:\n",
    "            if quality_index == 'corr_coef':\n",
    "                output_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "            else:\n",
    "                output_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "        # Execute the analysis function\n",
    "        run_multi_parameter_analysis(\n",
    "            # Core data inputs\n",
    "            log_a=log_a, \n",
    "            log_b=log_b, \n",
    "            md_a=md_a, \n",
    "            md_b=md_b,\n",
    "            all_depths_a_cat1=all_depths_a_cat1,\n",
    "            all_depths_b_cat1=all_depths_b_cat1,\n",
    "            pickeddepth_ages_a=pickeddepth_ages_a,\n",
    "            pickeddepth_ages_b=pickeddepth_ages_b,\n",
    "            age_data_a=age_data_a,\n",
    "            age_data_b=age_data_b,\n",
    "            uncertainty_method=uncertainty_method,\n",
    "            \n",
    "            # Analysis parameters\n",
    "            parameter_combinations=parameter_combinations,\n",
    "            target_quality_indices=target_quality_indices,\n",
    "            test_age_constraint_removal=test_age_constraint_removal,\n",
    "            \n",
    "            # Core identifiers\n",
    "            core_a_name=CORE_A,\n",
    "            core_b_name=CORE_B,\n",
    "            \n",
    "            # Output configuration\n",
    "            output_csv_filenames=output_csv_filenames,\n",
    "            \n",
    "            # Optional parameters\n",
    "            log_columns=LOG_COLUMNS\n",
    "        )\n",
    "        \n",
    "        print(f\"Completed processing: {CORE_A} vs {CORE_B}\")\n",
    "        \n",
    "        # Clean up memory before next iteration\n",
    "        del log_a, md_a, log_b, md_b\n",
    "        del pickeddepth_a_csv, pickeddepth_b_csv\n",
    "        del picked_data_a, picked_data_b\n",
    "        del all_depths_a_cat1, all_depths_b_cat1\n",
    "        del consider_adjacent_core, data_columns, age_base_path\n",
    "        del age_data_a, age_data_b\n",
    "        del uncertainty_method\n",
    "        del pickeddepth_ages_a, pickeddepth_ages_b\n",
    "        del output_csv_filenames\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All core pair combinations have been processed!\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
