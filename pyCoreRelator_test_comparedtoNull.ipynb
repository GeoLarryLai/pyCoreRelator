{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# Correlating well log pairs: Complex Dynamic Time Warping with boundary constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4awuK6ffO2t"
   },
   "source": [
    "## Introduction to dynamic time warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import glob\n",
    "from IPython.display import Image as IPImage, display\n",
    "from scipy import stats\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm  # ADD THIS LINE\n",
    "import matplotlib.colors as colors  # ADD THIS LINE\n",
    "from itertools import combinations\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    run_comprehensive_dtw_analysis,\n",
    "    find_complete_core_paths,\n",
    "    calculate_interpolated_ages,\n",
    "    load_log_data,\n",
    "    plot_core_data,\n",
    "    plot_correlation_distribution,\n",
    "    load_core_age_constraints,\n",
    "    # New functions moved from notebook to package\n",
    "    generate_constraint_subsets,\n",
    "    run_multi_parameter_analysis,\n",
    "    load_and_prepare_quality_data,\n",
    "    reconstruct_raw_data_from_histogram,\n",
    "    cohens_d,\n",
    "    plot_quality_comparison,\n",
    "    plot_t_statistics_vs_constraints,\n",
    "    plot_quality_distributions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Define basic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define core pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define core names as variables for easy reference\n",
    "# CORE_A = \"M9907-22PC\"\n",
    "CORE_A = \"M9907-23PC\"\n",
    "# CORE_A = \"M9907-12PC\"\n",
    "# CORE_A = \"RR0207-56PC\" \n",
    "\n",
    "# CORE_B = \"M9907-23PC\"\n",
    "CORE_B = \"M9907-11PC\"\n",
    "# CORE_B = \"RR0207-56PC\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log data paths and column name structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CORE_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m mother_dir = \u001b[33m'\u001b[39m\u001b[33m/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Define paths for Core A\u001b[39;00m\n\u001b[32m     11\u001b[39m core_a_log_paths = {\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhiresMS\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mCORE_A\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_hiresMS_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCT\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_CT_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLumin\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_RGB_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mR\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_RGB_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mG\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_RGB_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_RGB_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDen_gm/cc\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_MST_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m }\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Define paths for Core B\u001b[39;00m\n\u001b[32m     22\u001b[39m core_b_log_paths = {\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhiresMS\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_hiresMS_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCT\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_CT_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDen_gm/cc\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmother_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_compiled_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ML_filled/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_MST_MLfilled.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'CORE_A' is not defined"
     ]
    }
   ],
   "source": [
    "# Define log columns to extract\n",
    "# LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "# Define directory paths\n",
    "mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "# Define paths for Core A\n",
    "core_a_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "# Define paths for Core B\n",
    "core_b_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "# Define column mapping for alternative column names\n",
    "column_alternatives = {\n",
    "    'hiresMS': ['MS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'R': ['R', 'red', 'Red'],\n",
    "    'G': ['G', 'green', 'Green'],\n",
    "    'B': ['B', 'blue', 'Blue'],\n",
    "    'Lumin': ['luminance', 'Luminance'],\n",
    "    'Den_gm/cc': ['Density', 'density']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for Core A\n",
    "log_a, md_a, _, _, _ = load_log_data(\n",
    "    core_a_log_paths,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    column_alternatives=column_alternatives\n",
    ")\n",
    "\n",
    "# Load data for Core B\n",
    "log_b, md_b, _, _, _ = load_log_data(\n",
    "    core_b_log_paths,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    column_alternatives=column_alternatives\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load picked depth boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define paths to the CSV files\n",
    "pickeddepth_a_csv = f'pickeddepth/{CORE_A}_pickeddepth.csv'\n",
    "pickeddepth_b_csv = f'pickeddepth/{CORE_B}_pickeddepth.csv'\n",
    "\n",
    "# Load picked depths and extract category 1 depths\n",
    "if os.path.exists(pickeddepth_b_csv):\n",
    "    picked_data_b = pd.read_csv(pickeddepth_b_csv)\n",
    "    all_depths_b_cat1 = picked_data_b[picked_data_b['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "else:\n",
    "    print(f\"Warning: {pickeddepth_b_csv} not found. Using empty array for all_depths_b_cat1.\")\n",
    "    all_depths_b_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "if os.path.exists(pickeddepth_a_csv):\n",
    "    picked_data_a = pd.read_csv(pickeddepth_a_csv)\n",
    "    all_depths_a_cat1 = picked_data_a[picked_data_a['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "else:\n",
    "    print(f\"Warning: {pickeddepth_a_csv} not found. Using empty array for all_depths_a_cat1.\")\n",
    "    all_depths_a_cat1 = np.array([]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age constraints for both cores\n",
    "consider_adjacent_core = True\n",
    "\n",
    "data_columns = {\n",
    "    'age': 'calib502_agebp',\n",
    "    'pos_error': 'calib502_2sigma_pos', \n",
    "    'neg_error': 'calib502_2sigma_neg',\n",
    "    'min_depth': 'mindepth_cm',\n",
    "    'max_depth': 'maxdepth_cm',\n",
    "    'in_sequence': 'in_sequence',\n",
    "    'core': 'core',\n",
    "    'interpreted_bed': 'interpreted_bed'\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "age_base_path = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/Age constraints/Goldfinger2012'\n",
    "\n",
    "# Load age constraints for both cores\n",
    "age_data_a = load_core_age_constraints(CORE_A, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "age_data_b = load_core_age_constraints(CORE_B, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "\n",
    "uncertainty_method='MonteCarlo'   # 'MonteCarlo', 'Linear', or 'Gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute estimated ages for each picked depth boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interpolated ages for Core A using the function\n",
    "pickeddepth_ages_a = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=all_depths_a_cat1,                                     # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_a['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_a['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_a['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_a['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_a['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_a['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_a[-1],                                               # max depth of core a\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo iterations\n",
    "    # Visualization and output\n",
    "    show_plot=False,                                                      # display plot\n",
    "    core_name=CORE_A,                                                    # core name for plot title\n",
    "    export_csv=False,                                                    # export results to CSV\n",
    "    mute_mode=True\n",
    ")\n",
    "\n",
    "# Calculate interpolated ages for Core B using the function\n",
    "pickeddepth_ages_b = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=all_depths_b_cat1,                                     # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_b['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_b['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_b['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_b['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_b['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_b['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_b[-1],                                               # max depth of core b\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo sampling iterations\n",
    "    # Visualization and output\n",
    "    show_plot=False,                                                      # display plot\n",
    "    core_name=CORE_B,                                                    # core name for plot title\n",
    "    export_csv=False,                                                    # export results to CSV\n",
    "    mute_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Compute quality metric distribution for all stituation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Multi-Parameter Distribution Analysis\n",
    "\n",
    "test_age_constraint_removal = True  # Set to False to disable age constraint removal testing\n",
    "\n",
    "# Run all parameter combinations and plot distribution curves together\n",
    "\n",
    "# Define all parameter combinations to test\n",
    "parameter_combinations = [\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': False},\n",
    "    {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': True},\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "    # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': True},\n",
    "    # {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "    {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': True}\n",
    "]\n",
    "\n",
    "# Define all quality indices to process\n",
    "target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag']\n",
    "\n",
    "# Set up output CSV filenames\n",
    "if LOG_COLUMNS == ['hiresMS']:\n",
    "    log_suffix = 'MSonly'\n",
    "elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "    log_suffix = 'MSCTLumin'\n",
    "else:\n",
    "    log_suffix = 'unspecified'\n",
    "\n",
    "output_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        output_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "    else:\n",
    "        output_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "# Execute the analysis function\n",
    "run_multi_parameter_analysis(\n",
    "    # Core data inputs\n",
    "    log_a=log_a, \n",
    "    log_b=log_b, \n",
    "    md_a=md_a, \n",
    "    md_b=md_b,\n",
    "    all_depths_a_cat1=all_depths_a_cat1,\n",
    "    all_depths_b_cat1=all_depths_b_cat1,\n",
    "    pickeddepth_ages_a=pickeddepth_ages_a,\n",
    "    pickeddepth_ages_b=pickeddepth_ages_b,\n",
    "    age_data_a=age_data_a,\n",
    "    age_data_b=age_data_b,\n",
    "    uncertainty_method=uncertainty_method,\n",
    "    \n",
    "    # Analysis parameters\n",
    "    parameter_combinations=parameter_combinations,\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    test_age_constraint_removal=test_age_constraint_removal,\n",
    "    \n",
    "    # Core identifiers\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    \n",
    "    # Output configuration\n",
    "    output_csv_filenames=output_csv_filenames,\n",
    "    \n",
    "    # Optional parameters\n",
    "    log_columns=LOG_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting: compare the quality metric to the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names outside the function\n",
    "target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag', 'dtw_warp_eff']\n",
    "\n",
    "# Set up log suffix based on LOG_COLUMNS (assuming these variables are defined earlier)\n",
    "if LOG_COLUMNS == ['hiresMS']:\n",
    "    log_suffix = 'MSonly'\n",
    "elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "    log_suffix = 'MSCTLumin'\n",
    "else:\n",
    "    log_suffix = 'unspecified'\n",
    "\n",
    "# Define master CSV filenames\n",
    "master_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        master_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "    else:\n",
    "        master_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "# Define synthetic CSV filenames\n",
    "synthetic_csv_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    synthetic_csv_filenames[quality_index] = f'outputs/synthetic_PDFs_{log_suffix}_{quality_index}.csv'\n",
    "\n",
    "# Define output figure filenames\n",
    "output_figure_filenames = {}\n",
    "for quality_index in target_quality_indices:\n",
    "    if quality_index == 'corr_coef':\n",
    "        output_figure_filenames[quality_index] = f'outputs/r-values_comparison_{log_suffix}_{CORE_A}_{CORE_B}.png'\n",
    "    else:\n",
    "        output_figure_filenames[quality_index] = f'outputs/{quality_index}_comparison_{log_suffix}_{CORE_A}_{CORE_B}.png'\n",
    "\n",
    "# Use the function to produce EXACTLY the same result as the current code\n",
    "plot_quality_comparison(\n",
    "    target_quality_indices=target_quality_indices,\n",
    "    master_csv_filenames=master_csv_filenames,\n",
    "    synthetic_csv_filenames=synthetic_csv_filenames,\n",
    "    output_figure_filenames=output_figure_filenames,\n",
    "    CORE_A=CORE_A,\n",
    "    CORE_B=CORE_B,\n",
    "    debug=True  # Set to False for detailed output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "## Loop Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all core options\n",
    "CORE_A_OPTIONS = [\"M9907-12PC\", \"M9907-23PC\", \"M9907-25PC\", \"M9907-30PC\", \"M9907-31PC\", \"RR0207-56PC\"]\n",
    "CORE_B_OPTIONS = [\"M9907-11PC\", \"M9907-12PC\", \"M9907-23PC\"]\n",
    "\n",
    "# Loop through all valid combinations of CORE_A and CORE_B\n",
    "for CORE_A in CORE_A_OPTIONS:\n",
    "    for CORE_B in CORE_B_OPTIONS:\n",
    "        # Skip if CORE_A and CORE_B are the same\n",
    "        if CORE_A == CORE_B:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing core pair: {CORE_A} vs {CORE_B}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "    # Define log columns to extract\n",
    "    LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "    # LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "    DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "    # Define directory paths\n",
    "    mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "    # Define paths for Core A\n",
    "    core_a_log_paths = {\n",
    "        'hiresMS': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "        'CT': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_CT_MLfilled.csv',\n",
    "        'Lumin': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "        'R': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "        'G': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "        'B': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_RGB_MLfilled.csv',\n",
    "        'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_A}/ML_filled/{CORE_A}_MST_MLfilled.csv'\n",
    "    }\n",
    "\n",
    "    # Define paths for Core B\n",
    "    core_b_log_paths = {\n",
    "        'hiresMS': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "        'CT': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_CT_MLfilled.csv',\n",
    "        'Lumin': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "        'R': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "        'G': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "        'B': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_RGB_MLfilled.csv',\n",
    "        'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_B}/ML_filled/{CORE_B}_MST_MLfilled.csv'\n",
    "    }\n",
    "\n",
    "    # Define column mapping for alternative column names\n",
    "    column_alternatives = {\n",
    "        'hiresMS': ['MS'],\n",
    "        'CT': ['CT_value'],\n",
    "        'R': ['R', 'red', 'Red'],\n",
    "        'G': ['G', 'green', 'Green'],\n",
    "        'B': ['B', 'blue', 'Blue'],\n",
    "        'Lumin': ['luminance', 'Luminance'],\n",
    "        'Den_gm/cc': ['Density', 'density']\n",
    "    }\n",
    "\n",
    "        # Load data for Core A\n",
    "        log_a, md_a, _, _, _ = load_log_data(\n",
    "            core_a_log_paths,\n",
    "            log_columns=LOG_COLUMNS,\n",
    "            depth_column=DEPTH_COLUMN,\n",
    "            normalize=True,\n",
    "            column_alternatives=column_alternatives\n",
    "        )\n",
    "\n",
    "        # Load data for Core B\n",
    "        log_b, md_b, _, _, _ = load_log_data(\n",
    "            core_b_log_paths,\n",
    "            log_columns=LOG_COLUMNS,\n",
    "            depth_column=DEPTH_COLUMN,\n",
    "            normalize=True,\n",
    "            column_alternatives=column_alternatives\n",
    "        )\n",
    "\n",
    "        %matplotlib inline\n",
    "\n",
    "        # Define paths to the CSV files\n",
    "        pickeddepth_a_csv = f'pickeddepth/{CORE_A}_pickeddepth.csv'\n",
    "        pickeddepth_b_csv = f'pickeddepth/{CORE_B}_pickeddepth.csv'\n",
    "\n",
    "        # Load picked depths and extract category 1 depths\n",
    "        if os.path.exists(pickeddepth_b_csv):\n",
    "            picked_data_b = pd.read_csv(pickeddepth_b_csv)\n",
    "            all_depths_b_cat1 = picked_data_b[picked_data_b['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "        else:\n",
    "            print(f\"Warning: {pickeddepth_b_csv} not found. Using empty array for all_depths_b_cat1.\")\n",
    "            all_depths_b_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "        if os.path.exists(pickeddepth_a_csv):\n",
    "            picked_data_a = pd.read_csv(pickeddepth_a_csv)\n",
    "            all_depths_a_cat1 = picked_data_a[picked_data_a['category'] == 1]['picked_depths_cm'].values.astype('float32')\n",
    "        else:\n",
    "            print(f\"Warning: {pickeddepth_a_csv} not found. Using empty array for all_depths_a_cat1.\")\n",
    "            all_depths_a_cat1 = np.array([]).astype('float32')\n",
    "\n",
    "        # Load age constraints for both cores\n",
    "        consider_adjacent_core = True\n",
    "\n",
    "        data_columns = {\n",
    "            'age': 'calib502_agebp',\n",
    "            'pos_error': 'calib502_2sigma_pos', \n",
    "            'neg_error': 'calib502_2sigma_neg',\n",
    "            'min_depth': 'mindepth_cm',\n",
    "            'max_depth': 'maxdepth_cm',\n",
    "            'in_sequence': 'in_sequence',\n",
    "            'core': 'core',\n",
    "            'interpreted_bed': 'interpreted_bed'\n",
    "        }\n",
    "\n",
    "        # Configuration\n",
    "        age_base_path = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/Age constraints/Goldfinger2012'\n",
    "\n",
    "        # Load age constraints for both cores\n",
    "        age_data_a = load_core_age_constraints(CORE_A, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "        age_data_b = load_core_age_constraints(CORE_B, age_base_path, consider_adjacent_core, data_columns, mute_mode=True)\n",
    "\n",
    "        uncertainty_method='MonteCarlo'   # 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "\n",
    "        # Calculate interpolated ages for Core A using the function\n",
    "        pickeddepth_ages_a = calculate_interpolated_ages(\n",
    "            # Input data\n",
    "            picked_depths=all_depths_a_cat1,                                     # depths to interpolate ages for\n",
    "            age_constraints_depths=age_data_a['depths'],                         # age constraint depths\n",
    "            age_constraints_ages=age_data_a['ages'],                             # age constraint ages\n",
    "            age_constraints_pos_errors=age_data_a['pos_errors'],                 # positive errors\n",
    "            age_constraints_neg_errors=age_data_a['neg_errors'],                 # negative errors\n",
    "            age_constraints_in_sequence_flags=age_data_a['in_sequence_flags'],   # in-sequence flags\n",
    "            age_constraint_source_core=age_data_a['core'],                       # source core for each constraint\n",
    "            # Core boundaries\n",
    "            top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "            top_depth=0.0,                                                       # top of core depth\n",
    "            bottom_depth=md_a[-1],                                               # max depth of core a\n",
    "            top_age=0,                                                           # default age at top of core\n",
    "            top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "            top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "            # Uncertainty calculation\n",
    "            uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "            n_monte_carlo=10000,                                                 # number of Monte Carlo iterations\n",
    "            # Visualization and output\n",
    "            show_plot=False,                                                      # display plot\n",
    "            core_name=CORE_A,                                                    # core name for plot title\n",
    "            export_csv=False,                                                    # export results to CSV\n",
    "            mute_mode=True\n",
    "        )\n",
    "\n",
    "        # Calculate interpolated ages for Core B using the function\n",
    "        pickeddepth_ages_b = calculate_interpolated_ages(\n",
    "            # Input data\n",
    "            picked_depths=all_depths_b_cat1,                                     # depths to interpolate ages for\n",
    "            age_constraints_depths=age_data_b['depths'],                         # age constraint depths\n",
    "            age_constraints_ages=age_data_b['ages'],                             # age constraint ages\n",
    "            age_constraints_pos_errors=age_data_b['pos_errors'],                 # positive errors\n",
    "            age_constraints_neg_errors=age_data_b['neg_errors'],                 # negative errors\n",
    "            age_constraints_in_sequence_flags=age_data_b['in_sequence_flags'],   # in-sequence flags\n",
    "            age_constraint_source_core=age_data_b['core'],                       # source core for each constraint\n",
    "            # Core boundaries\n",
    "            top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "            top_depth=0.0,                                                       # top of core depth\n",
    "            bottom_depth=md_b[-1],                                               # max depth of core b\n",
    "            top_age=0,                                                           # default age at top of core\n",
    "            top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "            top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "            # Uncertainty calculation\n",
    "            uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "            n_monte_carlo=10000,                                                 # number of Monte Carlo sampling iterations\n",
    "            # Visualization and output\n",
    "            show_plot=False,                                                      # display plot\n",
    "            core_name=CORE_B,                                                    # core name for plot title\n",
    "            export_csv=False,                                                    # export results to CSV\n",
    "            mute_mode=True\n",
    "        )\n",
    "\n",
    "        # Cell: Multi-Parameter Distribution Analysis\n",
    "\n",
    "        test_age_constraint_removal = True  # Set to False to disable age constraint removal testing\n",
    "\n",
    "        # Run all parameter combinations and plot distribution curves together\n",
    "\n",
    "        # Define all parameter combinations to test\n",
    "        parameter_combinations = [\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': False},\n",
    "            {'age_consideration': True, 'restricted_age_correlation': True, 'shortest_path_search': True},\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "            # {'age_consideration': True, 'restricted_age_correlation': False, 'shortest_path_search': True},\n",
    "            # {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': False},\n",
    "            {'age_consideration': False, 'restricted_age_correlation': False, 'shortest_path_search': True}\n",
    "        ]\n",
    "\n",
    "        # Define all quality indices to process\n",
    "        target_quality_indices = ['corr_coef', 'norm_dtw', 'perc_diag']\n",
    "\n",
    "        # Set up output CSV filenames\n",
    "        if LOG_COLUMNS == ['hiresMS']:\n",
    "            log_suffix = 'MSonly'\n",
    "        elif LOG_COLUMNS == ['hiresMS','CT', 'Lumin']:\n",
    "            log_suffix = 'MSCTLumin'\n",
    "        else:\n",
    "            log_suffix = 'unspecified'\n",
    "\n",
    "        output_csv_filenames = {}\n",
    "        for quality_index in target_quality_indices:\n",
    "            if quality_index == 'corr_coef':\n",
    "                output_csv_filenames[quality_index] = f'outputs/r-values_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "            else:\n",
    "                output_csv_filenames[quality_index] = f'outputs/{quality_index}_fit_params_{log_suffix}_{CORE_A}_{CORE_B}.csv'\n",
    "\n",
    "        # Execute the analysis function\n",
    "        run_multi_parameter_analysis(\n",
    "            # Core data inputs\n",
    "            log_a=log_a, \n",
    "            log_b=log_b, \n",
    "            md_a=md_a, \n",
    "            md_b=md_b,\n",
    "            all_depths_a_cat1=all_depths_a_cat1,\n",
    "            all_depths_b_cat1=all_depths_b_cat1,\n",
    "            pickeddepth_ages_a=pickeddepth_ages_a,\n",
    "            pickeddepth_ages_b=pickeddepth_ages_b,\n",
    "            age_data_a=age_data_a,\n",
    "            age_data_b=age_data_b,\n",
    "            uncertainty_method=uncertainty_method,\n",
    "            \n",
    "            # Analysis parameters\n",
    "            parameter_combinations=parameter_combinations,\n",
    "            target_quality_indices=target_quality_indices,\n",
    "            test_age_constraint_removal=test_age_constraint_removal,\n",
    "            \n",
    "            # Core identifiers\n",
    "            core_a_name=CORE_A,\n",
    "            core_b_name=CORE_B,\n",
    "            \n",
    "            # Output configuration\n",
    "            output_csv_filenames=output_csv_filenames,\n",
    "            \n",
    "            # Optional parameters\n",
    "            log_columns=LOG_COLUMNS\n",
    "        )\n",
    "        \n",
    "        print(f\"Completed processing: {CORE_A} vs {CORE_B}\")\n",
    "        \n",
    "        # Clean up memory before next iteration\n",
    "        del log_a, md_a, log_b, md_b\n",
    "        del pickeddepth_a_csv, pickeddepth_b_csv\n",
    "        del picked_data_a, picked_data_b\n",
    "        del all_depths_a_cat1, all_depths_b_cat1\n",
    "        del consider_adjacent_core, data_columns, age_base_path\n",
    "        del age_data_a, age_data_b\n",
    "        del uncertainty_method\n",
    "        del pickeddepth_ages_a, pickeddepth_ages_b\n",
    "        del output_csv_filenames\n",
    "        \n",
    "        # Force garbage collection\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All core pair combinations have been processed!\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
