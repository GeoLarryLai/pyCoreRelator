{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# Correlating well log pairs: Complex Dynamic Time Warping with boundary constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4awuK6ffO2t"
   },
   "source": [
    "## Introduction to dynamic time warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython.display import Image as IPImage, display\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    run_comprehensive_dtw_analysis,\n",
    "    find_complete_core_paths,\n",
    "    diagnose_chain_breaks,\n",
    "    calculate_interpolated_ages,\n",
    "    load_pickeddepth_ages_from_csv,\n",
    "    visualize_combined_segments,\n",
    "    visualize_dtw_results_from_csv,\n",
    "    load_core_log_data,\n",
    "    plot_dtw_matrix_with_paths,\n",
    "    plot_correlation_distribution,\n",
    "    find_best_mappings,\n",
    "    load_core_age_constraints\n",
    ")\n",
    "\n",
    "## Extract and show each category of picked depths ###\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Test with Cascadia hi-res MS logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define core pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_A = \"M9907-25PC\"\n",
    "# CORE_A = \"M9907-23PC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_B = \"M9907-23PC\"\n",
    "# CORE_B = \"M9907-11PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data structures and core images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log columns to extract\n",
    "# LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for Core A\n",
    "core_a_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_A}/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_A}/{CORE_A}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_A}/{CORE_A}_RGB_MLfilled.csv'\n",
    "}\n",
    "\n",
    "core_a_rgb_img = f\"example_data/processed_data/{CORE_A}/{CORE_A}_RGB.tiff\"\n",
    "core_a_ct_img = f\"example_data/processed_data/{CORE_A}/{CORE_A}_CT.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and plot Core A with picked depths using load_core_log_data\n",
    "log_a, md_a, picked_depths_a, interpreted_bed_a = load_core_log_data(\n",
    "    log_paths=core_a_log_paths,\n",
    "    core_name=CORE_A,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    core_img_1=core_a_rgb_img,\n",
    "    core_img_2=core_a_ct_img,\n",
    "    figsize=(20, 4),\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_A}_pickeddepth.csv',\n",
    "    categories=[1],\n",
    "    show_bed_number=False,\n",
    "    show_fig=True  # Display the figure\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for Core B\n",
    "core_b_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_B}/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_B}/{CORE_B}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_B}/{CORE_B}_RGB_MLfilled.csv'\n",
    "}\n",
    "core_b_rgb_img = f\"example_data/processed_data/{CORE_B}/{CORE_B}_RGB.tiff\"\n",
    "core_b_ct_img = f\"example_data/processed_data/{CORE_B}/{CORE_B}_CT.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and plot Core B with picked depths using load_core_log_data\n",
    "log_b, md_b, picked_depths_b, interpreted_bed_b = load_core_log_data(\n",
    "    log_paths=core_b_log_paths,\n",
    "    core_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    normalize=True,\n",
    "    core_img_1=core_b_rgb_img,\n",
    "    core_img_2=core_b_ct_img,\n",
    "    figsize=(20, 4),\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_B}_pickeddepth.csv',\n",
    "    categories=[1],\n",
    "    show_bed_number=False,\n",
    "    show_fig=True  # Display the figure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Usage Examples and Executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age constraints for both cores\n",
    "data_columns = {\n",
    "    'age': 'calib810_agebp',\n",
    "    'pos_error': 'calib810_2sigma_pos', \n",
    "    'neg_error': 'calib810_2sigma_neg',\n",
    "    'min_depth': 'mindepth_cm',\n",
    "    'max_depth': 'maxdepth_cm',\n",
    "    'in_sequence': 'in_sequence',\n",
    "    'core': 'core',\n",
    "    'interpreted_bed': 'interpreted_bed'\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "age_base_path = 'example_data/raw_data/C14age_data'\n",
    "\n",
    "# Load age constraints for both cores\n",
    "age_data_a = load_core_age_constraints(CORE_A, age_base_path, data_columns, consider_adjacent_core = False)\n",
    "age_data_b = load_core_age_constraints(CORE_B, age_base_path, data_columns, consider_adjacent_core = False)\n",
    "\n",
    "uncertainty_method='MonteCarlo'   # 'MonteCarlo', 'Linear', or 'Gaussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interpolated ages for Core A using the function\n",
    "estimated_datum_ages_a = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=picked_depths_a,                             # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_a['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_a['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_a['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_a['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_a['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_a['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_a[-1],                                               # max depth of core a\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo iterations\n",
    "    # Visualization and output\n",
    "    show_plot=True,                                                      # display plot\n",
    "    core_name=CORE_A,                                                    # core name for plot title\n",
    "    export_csv=True,                                                     # export results to CSV\n",
    "    csv_filename=f'example_data/picked_datum/{CORE_A}_pickeddepth_ages_{uncertainty_method}.csv',                         # CSV filename for results\n",
    "    mute_mode=False\n",
    ")\n",
    "\n",
    "# Print the age constraint data for Core A\n",
    "print(\"\\nAge Constraints for Core A:\")\n",
    "if len(age_data_a['depths']) > 0:\n",
    "    for i in range(len(age_data_a['depths'])):\n",
    "        depth_val = age_data_a['depths'].iloc[i] if isinstance(age_data_a['depths'], pd.Series) else age_data_a['depths'][i]\n",
    "        age_val = age_data_a['ages'][i]\n",
    "        pos_err_val = age_data_a['pos_errors'][i]\n",
    "        neg_err_val = age_data_a['neg_errors'][i]\n",
    "        in_seq = age_data_a['in_sequence_flags'][i]\n",
    "        \n",
    "        # Add source core and interpreted bed info if they exist\n",
    "        source_core_info = f\", Source Core: {age_data_a['core'][i]}\" if i < len(age_data_a['core']) else \"\"\n",
    "        bed_info = f\", Interpreted Bed: {age_data_a['interpreted_bed'][i]}\" if i < len(age_data_a['interpreted_bed']) else \"\"\n",
    "        \n",
    "        print(f\"Depth: {depth_val:.2f} cm, Age: {age_val:.1f} years BP (+{pos_err_val:.1f} ; -{neg_err_val:.1f}), In Sequence: {in_seq}{source_core_info}{bed_info}\")\n",
    "else:\n",
    "    print(f\"No age constraints available in {CORE_A}\")\n",
    "\n",
    "# Print the interpolated ages\n",
    "print(f\"\\nEstimated Ages for picked depths in {CORE_A}:\")\n",
    "for i, depth in enumerate(estimated_datum_ages_a['depths']):\n",
    "    print(f\"Depth: {depth:.2f} cm, Age: {estimated_datum_ages_a['ages'][i]:.1f} years BP (+{estimated_datum_ages_a['pos_uncertainties'][i]:.1f} ; -{estimated_datum_ages_a['neg_uncertainties'][i]:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interpolated ages for Core B using the function\n",
    "estimated_datum_ages_b = calculate_interpolated_ages(\n",
    "    # Input data\n",
    "    picked_depths=picked_depths_b,                             # depths to interpolate ages for\n",
    "    age_constraints_depths=age_data_b['depths'],                         # age constraint depths\n",
    "    age_constraints_ages=age_data_b['ages'],                             # age constraint ages\n",
    "    age_constraints_pos_errors=age_data_b['pos_errors'],                 # positive errors\n",
    "    age_constraints_neg_errors=age_data_b['neg_errors'],                 # negative errors\n",
    "    age_constraints_in_sequence_flags=age_data_b['in_sequence_flags'],   # in-sequence flags\n",
    "    age_constraint_source_core=age_data_b['core'],                       # source core for each constraint\n",
    "    # Core boundaries\n",
    "    top_bottom=True,                                                     # include top and bottom depths/ages\n",
    "    top_depth=0.0,                                                       # top of core depth\n",
    "    bottom_depth=md_b[-1],                                               # max depth of core b\n",
    "    top_age=0,                                                           # default age at top of core\n",
    "    top_age_pos_error=75,                                                # default positive uncertainty of top age\n",
    "    top_age_neg_error=75,                                                # default negative uncertainty of top age\n",
    "    # Uncertainty calculation\n",
    "    uncertainty_method=uncertainty_method,                               # uncertainty calculation method: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "    n_monte_carlo=10000,                                                 # number of Monte Carlo sampling iterations\n",
    "    # Visualization and output\n",
    "    show_plot=True,                                                      # display plot\n",
    "    core_name=CORE_B,                                                    # core name for plot title\n",
    "    export_csv=True,                                                     # export results to CSV\n",
    "    csv_filename=f'example_data/picked_datum/{CORE_B}_pickeddepth_ages_{uncertainty_method}.csv',                         # CSV filename for results\n",
    "    mute_mode=False\n",
    ")\n",
    "\n",
    "# Print the age constraint data for Core B\n",
    "print(\"\\nAge Constraints for Core B:\")\n",
    "if len(age_data_b['depths']) > 0:\n",
    "    for i in range(len(age_data_b['depths'])):\n",
    "        depth_val = age_data_b['depths'].iloc[i] if isinstance(age_data_b['depths'], pd.Series) else age_data_b['depths'][i]\n",
    "        age_val = age_data_b['ages'][i]\n",
    "        pos_err_val = age_data_b['pos_errors'][i]\n",
    "        neg_err_val = age_data_b['neg_errors'][i]\n",
    "        in_seq = age_data_b['in_sequence_flags'][i]\n",
    "        \n",
    "        # Add source core and interpreted bed info if they exist\n",
    "        source_core_info = f\", Source Core: {age_data_b['core'][i]}\" if i < len(age_data_b['core']) else \"\"\n",
    "        bed_info = f\", Interpreted Bed: {age_data_b['interpreted_bed'][i]}\" if i < len(age_data_b['interpreted_bed']) else \"\"\n",
    "        \n",
    "        print(f\"Depth: {depth_val:.2f} cm, Age: {age_val:.1f} years BP (+{pos_err_val:.1f} ; -{neg_err_val:.1f}), In Sequence: {in_seq}{source_core_info}{bed_info}\")\n",
    "else:\n",
    "    print(f\"No age constraints available in {CORE_B}\")\n",
    "\n",
    "print(f\"\\nEstimated Ages for picked depths in {CORE_B}:\")\n",
    "for i, depth in enumerate(estimated_datum_ages_b['depths']):\n",
    "    print(f\"Depth: {depth:.2f} cm, Age: {estimated_datum_ages_b['ages'][i]:.1f} years BP (+{estimated_datum_ages_b['pos_uncertainties'][i]:.1f} ; -{estimated_datum_ages_b['neg_uncertainties'][i]:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip age interpolation and extrapolation, and directly load estimated age csv to get pickeddepth_age parameter\n",
    "# Use load_pickeddepth_ages_from_csv function\n",
    "estimated_datum_ages_a = load_pickeddepth_ages_from_csv(pickeddepth_age_csv = f\"example_data/picked_datum/{CORE_A}_pickeddepth_ages_{uncertainty_method}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_datum_ages_b = load_pickeddepth_ages_from_csv(pickeddepth_age_csv = f\"example_data/picked_datum/{CORE_B}_pickeddepth_ages_{uncertainty_method}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out all segment pairs among boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names for age consideration or not\n",
    "\n",
    "# Check if the last age in either core is NaN to determine age consideration\n",
    "last_age_a = estimated_datum_ages_a['ages'][-1] if len(estimated_datum_ages_a['ages']) > 0 else float('nan')\n",
    "last_age_b = estimated_datum_ages_b['ages'][-1] if len(estimated_datum_ages_b['ages']) > 0 else float('nan')\n",
    "\n",
    "age_consideration = not (pd.isna(last_age_a) or pd.isna(last_age_b))\n",
    "# age_consideration = False\n",
    "\n",
    "restricted_age_correlation=True\n",
    "\n",
    "if age_consideration:\n",
    "    if restricted_age_correlation:\n",
    "        YES_NO_AGE = 'restricted_age'\n",
    "    else:\n",
    "        YES_NO_AGE = 'loose_age'\n",
    "else:\n",
    "    YES_NO_AGE = 'no_age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive DTW analysis\n",
    "dtw_results, valid_dtw_pairs, segments_a, segments_b, depth_boundaries_a, depth_boundaries_b, dtw_distance_matrix_full = run_comprehensive_dtw_analysis(\n",
    "    # Input data\n",
    "    log_a,                                                      # Core A log data\n",
    "    log_b,                                                      # Core B log data\n",
    "    md_a,                                                       # Core A measured depth\n",
    "    md_b,                                                       # Core B measured depth\n",
    "    picked_depths_a=picked_depths_a,                         # Selected depths for core A\n",
    "    picked_depths_b=picked_depths_b,                         # Selected depths for core B\n",
    "    core_a_name=CORE_A,                                        # Name identifier for core A\n",
    "    core_b_name=CORE_B,                                        # Name identifier for core B\n",
    "    # Analysis parameters\n",
    "    top_bottom=True,                                            # Include top and bottom boundaries\n",
    "    top_depth=0.0,                                              # Starting depth for analysis\n",
    "    independent_dtw=False,                            # Use independent DTW if True\n",
    "    exclude_deadend=True,                                       # Exclude dead-end segments\n",
    "    pca_for_dependent_dtw=False,                # Use PCA for dependent DTW\n",
    "    # Age constraints\n",
    "    age_consideration=age_consideration,                        # Include age constraints\n",
    "    ages_a=estimated_datum_ages_a,                                  # Age data for core A depths\n",
    "    ages_b=estimated_datum_ages_b,                                  # Age data for core B depths\n",
    "    restricted_age_correlation=restricted_age_correlation,      # Use strict age correlation\n",
    "    all_constraint_ages_a=age_data_a['in_sequence_ages'],      # All age constraints for core A\n",
    "    all_constraint_ages_b=age_data_b['in_sequence_ages'],      # All age constraints for core B\n",
    "    all_constraint_depths_a=age_data_a['in_sequence_depths'],  # All depth constraints for core A\n",
    "    all_constraint_depths_b=age_data_b['in_sequence_depths'],  # All depth constraints for core B\n",
    "    all_constraint_pos_errors_a=age_data_a['in_sequence_pos_errors'], # Positive age errors for core A\n",
    "    all_constraint_pos_errors_b=age_data_b['in_sequence_pos_errors'], # Positive age errors for core B\n",
    "    all_constraint_neg_errors_a=age_data_a['in_sequence_neg_errors'], # Negative age errors for core A\n",
    "    all_constraint_neg_errors_b=age_data_b['in_sequence_neg_errors'], # Negative age errors for core B\n",
    "    age_constraint_a_source_cores=age_data_a['core'],          # Source cores for age constraints A\n",
    "    age_constraint_b_source_cores=age_data_b['core'],          # Source cores for age constraints B\n",
    "    # Visualization\n",
    "    visualize_pairs=True,                                       # Create pair visualizations\n",
    "    visualize_segment_labels=False,                             # Show segment labels in plots\n",
    "    create_dtw_matrix=True,                                     # Generate DTW distance matrix\n",
    "    dtwmatrix_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/SegmentPair_DTW_matrix_{YES_NO_AGE}.png', # Matrix plot filename\n",
    "    creategif=True,                                             # Create animated GIF\n",
    "    gif_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/SegmentPair_DTW_animation_{YES_NO_AGE}.gif', # GIF filename\n",
    "    max_frames=50,                                              # Maximum frames in animation\n",
    "    color_interval_size=5,                                      # Color coding interval size\n",
    "    keep_frames=False,                                           # Save individual frames\n",
    "    # Debug and processing\n",
    "    debug=False                                                 # Enable debug output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Estimation of the Number of Possible Solutions (Total Complete Paths)\n",
    "\n",
    "### 1. Segment Generation Formula\n",
    "\n",
    "Given $n$ units for each core, the **number of valid segments per core** follows:\n",
    "\n",
    "$$S = 2n + 1$$\n",
    "\n",
    "### 2. Valid Segment Pairs\n",
    "\n",
    "**Theoretical maximum number of segment pairs**: $P_{\\max} = S_A \\times S_B$  \n",
    "\n",
    "However, because the 'optimal search' try to filters pairs based on shortest DTW path search method (minimze pinch-outs), not all segment pairs $(S_A \\times S_B)$ are valid. $P_{\\mathrm{valid}} < P_{\\max}$\n",
    "\n",
    "Based 97 Cascadida core data pairs, we fund the typical retention rate is ~70-75% of theoretical maximum pairs remain valid after DTW filtering.\n",
    "\n",
    "$$P_{\\mathrm{valid}} \\approx 0.745 \\times (S_A \\times S_B)$$\n",
    "\n",
    "### 3. Solution Count Formula\n",
    "\n",
    "The relationship between valid pairs and total solutions follows a **quadratic-in-log-space** pattern:\n",
    "\n",
    "$$C \\approx e^{4.395 (\\ln P_{\\mathrm{valid}})^2 - 43.179 \\ln P_{\\mathrm{valid}} + 116.872}$$\n",
    "\n",
    "This empirical formula was fitted to 97 core pair analyses with $R^2 > 0.999$.\n",
    "\n",
    "### 4. Practical Examples\n",
    "\n",
    "Based on actual data from 97 core pair analyses:\n",
    "\n",
    "| Units per core ($n$) | Valid segments per core ($S$) | Valid pairs ($P_{\\mathrm{valid}}$) | Est. solutions ($C$) |\n",
    "|----------------|----------------|-------------|---------------------|\n",
    "| 6-8 | 13-17 | 150-700 | $10^{4}$ - $10^{8}$ |\n",
    "| 11-14 | 23-29 | 250-1,100 | $10^{5}$ - $10^{13}$ |\n",
    "| 18-22 | 37-45 | 1,100-1,900 | $10^{13}$ - $10^{18}$ |\n",
    "| 24-28 | 49-57 | 1,400-2,700 | $10^{15}$ - $10^{22}$ |\n",
    "| 30-31 | 61-63 | 2,400-2,900 | $10^{20}$ - $10^{24}$ |\n",
    "\n",
    "**Key finding**: The quadratic-in-log-space relationship means solution count grows rapidly with problem size. Small increases in the number of units per core lead to dramatic increases in computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_result = diagnose_chain_breaks(\n",
    "    # Input data\n",
    "    valid_dtw_pairs,                                        # Valid DTW segment pairs from analysis\n",
    "    segments_a,                                             # Segment definitions for core A\n",
    "    segments_b,                                             # Segment definitions for core Bss\n",
    "    depth_boundaries_a,                                     # Depth boundaries for core A segments\n",
    "    depth_boundaries_b                                      # Depth boundaries for core B segments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Search complete DTW paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_search=True\n",
    "\n",
    "if shortest_path_search:\n",
    "    SEARCH_METHOD = 'optimal'\n",
    "else:\n",
    "    SEARCH_METHOD = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_path_search_result = find_complete_core_paths(\n",
    "    # Input data\n",
    "    valid_dtw_pairs,                                                                # Valid DTW segment pairs from analysis\n",
    "    segments_a,                                                                     # Segment definitions for core A\n",
    "    segments_b,                                                                     # Segment definitions for core B\n",
    "    log_a,                                                                          # Log data for core A\n",
    "    log_b,                                                                          # Log data for core B\n",
    "    depth_boundaries_a,                                                             # Depth boundaries for core A segments\n",
    "    depth_boundaries_b,                                                             # Depth boundaries for core B segments\n",
    "    dtw_results,                                                                    # DTW analysis results\n",
    "    dtw_distance_matrix_full,                                                       # Full DTW distance matrix\n",
    "    # Output settings\n",
    "    output_csv=f\"example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}_{SEARCH_METHOD}.csv\",     # Output CSV filename for mappings\n",
    "    # Search parameters\n",
    "    start_from_top_only=True,                                                       # Start path search from top segments only\n",
    "    shortest_path_search=shortest_path_search,                                      # Use shortest path search algorithm\n",
    "    shortest_path_level=2,                                                          # Path level preference (higher = more segments)\n",
    "    max_search_path=10000,                                                          # Maximum paths per segment pair to avoid memory issues\n",
    "    # Processing settings\n",
    "    batch_size=1000,                                                                # Processing batch size\n",
    "    n_jobs=-1,                                                                      # Number of CPU cores (-1 uses all available)\n",
    "    debug=False,                                                                    # Enable debug output,\n",
    "    pca_for_dependent_dtw=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "correlation_gif_name=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_correlation_mappings_{YES_NO_AGE}_{SEARCH_METHOD}.gif'\n",
    "matrix_gif_name=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_matrix_mappings_{YES_NO_AGE}_{SEARCH_METHOD}.gif'\n",
    "\n",
    "# 1. First, read all available mappings from a CSV (assuming it was created by find_all_sequential_mappings)\n",
    "sequential_mappings_csv = f\"example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}_{SEARCH_METHOD}.csv\"\n",
    "\n",
    "# 3. Visualize a representative subset of the mappings\n",
    "visualize_dtw_results_from_csv(\n",
    "    # Input data\n",
    "    sequential_mappings_csv,                                                        # CSV file with sequential mappings\n",
    "    log_a,                                                                          # Log data for core A\n",
    "    log_b,                                                                          # Log data for core B\n",
    "    md_a,                                                                           # Measured depth data for core A\n",
    "    md_b,                                                                           # Measured depth data for core B\n",
    "    dtw_results,                                                                    # DTW analysis results\n",
    "    valid_dtw_pairs,                                                                # Valid DTW segment pairs\n",
    "    segments_a,                                                                     # Segment definitions for core A\n",
    "    segments_b,                                                                     # Segment definitions for core B\n",
    "    depth_boundaries_a,                                                             # Depth boundaries for core A segments\n",
    "    depth_boundaries_b,                                                             # Depth boundaries for core B segments\n",
    "    dtw_distance_matrix_full,                                                       # Full DTW distance matrix\n",
    "    # Core identifiers\n",
    "    core_a_name=CORE_A,                                                             # Name identifier for core A\n",
    "    core_b_name=CORE_B,                                                             # Name identifier for core B\n",
    "    # Visualization settings\n",
    "    color_interval_size=10,                                                         # Color interval size for visualization\n",
    "    debug=False,                                                                    # Enable debug output\n",
    "    visualize_pairs=False,                                                          # Show DTW pairs in visualization\n",
    "    visualize_segment_labels=False,                                                 # Show segment labels in visualization\n",
    "    mark_depths=False,                                                               # Mark depth points in visualization\n",
    "    # GIF output settings\n",
    "    creategif=True,                                                                 # Create animated GIF output\n",
    "    correlation_gif_output_filename=correlation_gif_name,                          # Output filename for correlation GIF\n",
    "    matrix_gif_output_filename=matrix_gif_name,                                    # Output filename for matrix GIF\n",
    "    max_frames=50,                                                                  # Maximum number of frames in GIF\n",
    "    keep_frames=False,                                                               # Keep individual frames after GIF creation\n",
    "    # Age constraints\n",
    "    mark_ages=age_consideration,                                                    # Mark age constraints in visualization\n",
    "    ages_a=estimated_datum_ages_a,                                                      # Age data for core A\n",
    "    ages_b=estimated_datum_ages_b,                                                      # Age data for core B\n",
    "    all_constraint_depths_a=age_data_a['in_sequence_depths'],                       # Depth constraints for core A\n",
    "    all_constraint_depths_b=age_data_b['in_sequence_depths'],                       # Depth constraints for core B\n",
    "    all_constraint_ages_a=age_data_a['in_sequence_ages'],                           # Age constraints for core A\n",
    "    all_constraint_ages_b=age_data_b['in_sequence_ages'],                           # Age constraints for core B\n",
    "    all_constraint_pos_errors_a=age_data_a['in_sequence_pos_errors'],               # Positive age errors for core A\n",
    "    all_constraint_pos_errors_b=age_data_b['in_sequence_pos_errors'],               # Positive age errors for core B\n",
    "    all_constraint_neg_errors_a=age_data_a['in_sequence_neg_errors'],               # Negative age errors for core A\n",
    "    all_constraint_neg_errors_b=age_data_b['in_sequence_neg_errors'],               # Negative age errors for core B\n",
    "    age_constraint_a_source_cores=age_data_a['core'],                               # Source cores for age constraints A\n",
    "    age_constraint_b_source_cores=age_data_b['core'],                                # Source cores for age constraints B\n",
    "    # Interpreted bed correlation\n",
    "    interpreted_bed_a=interpreted_bed_a,         # Interpreted bed name for Core A\n",
    "    interpreted_bed_b=interpreted_bed_b          # Interpreted bed name for Core B\n",
    ")\n",
    "\n",
    "# Display the GIFs\n",
    "print(\"DTW Correlation Mappings GIF:\")\n",
    "display(IPImage(correlation_gif_name))\n",
    "\n",
    "print(\"DTW Matrix Mappings GIF:\")\n",
    "display(IPImage(matrix_gif_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved DTW results\n",
    "sequential_mappings_csv = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}_{SEARCH_METHOD}.csv'\n",
    "output_matrix_png_filename = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_matrix_mappings_colored_{YES_NO_AGE}_{SEARCH_METHOD}.png'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "_ = plot_dtw_matrix_with_paths(\n",
    "    # Input data\n",
    "    dtw_distance_matrix_full,                                                       # Full DTW distance matrix\n",
    "    sequential_mappings_csv=sequential_mappings_csv,                                # CSV file with sequential mappings\n",
    "    # Core identifiers\n",
    "    core_a_name=CORE_A,                                                             # Name identifier for core A\n",
    "    core_b_name=CORE_B,                                                             # Name identifier for core B\n",
    "    md_a=md_a,                                                                      # Metadata for core A\n",
    "    md_b=md_b,                                                                      # Metadata for core B\n",
    "    # Visualization settings\n",
    "    mode='all_paths_colored',                                                       # Visualization mode\n",
    "    color_metric='norm_dtw',                                                    # Metric used for coloring paths\n",
    "                                                                                    # Available options: 'corr_coef', 'norm_dtw', 'dtw_ratio', 'perc_diag', 'dtw_warp_eff', 'perc_age_overlap', None (uses mapping_id)\n",
    "    output_filename=output_matrix_png_filename,                                     # Output filename for the plot\n",
    "    # Age constraint data\n",
    "    age_constraint_a_depths=age_data_a['in_sequence_depths'] if age_consideration else None,  # Depth constraints for core A\n",
    "    age_constraint_a_ages=age_data_a['in_sequence_ages'] if age_consideration else None,      # Age constraints for core A\n",
    "    age_constraint_a_source_cores=age_data_a['core'] if age_consideration else None,          # Source cores for age constraints A\n",
    "    age_constraint_b_depths=age_data_b['in_sequence_depths'] if age_consideration else None,  # Depth constraints for core B\n",
    "    age_constraint_b_ages=age_data_b['in_sequence_ages'] if age_consideration else None,      # Age constraints for core B\n",
    "    age_constraint_b_source_cores=age_data_b['core'] if age_consideration else None,          # Source cores for age constraints B\n",
    "    # Performance settings\n",
    "    n_jobs=-1                                                                       # Number of parallel jobs (-1 means use all processors)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the best mapping ####\n",
    "# Load the DTW results\n",
    "sequential_mappings_csv = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}_{SEARCH_METHOD}.csv'\n",
    "\n",
    "# Use custom metric weights\n",
    "custom_weights = {\n",
    "    'corr_coef': 1.0,\n",
    "    'perc_diag': 0.0,\n",
    "    'norm_dtw': 1.0,\n",
    "    'dtw_ratio': 0.0,\n",
    "    'perc_age_overlap': 0.0,\n",
    "    'dtw_warp_eff': 0.0\n",
    "}\n",
    "\n",
    "# # To just find the best-scored mappings\n",
    "# top_mapping_ids, top_mapping_pairs, top_mappings_df = find_best_mappings(\n",
    "#     csv_file_path=sequential_mappings_csv,\n",
    "#     top_n=10,\n",
    "#     filter_shortest_dtw=True,\n",
    "#     metric_weight=custom_weights\n",
    "# )\n",
    "\n",
    "### To find the best-scored mappings that comply the intepreted bed correlation\n",
    "top_mapping_ids, top_mapping_pairs, top_mappings_df = find_best_mappings(\n",
    "    csv_file_path=sequential_mappings_csv,\n",
    "    metric_weight=custom_weights,\n",
    "    picked_depths_a_cat1=picked_depths_a,\n",
    "    picked_depths_b_cat1=picked_depths_b,\n",
    "    interpreted_bed_a=interpreted_bed_a,\n",
    "    interpreted_bed_b=interpreted_bed_b,\n",
    "    valid_dtw_pairs=valid_dtw_pairs,\n",
    "    segments_a=segments_a,\n",
    "    segments_b=segments_b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "visualize_pairs=False\n",
    "\n",
    "if visualize_pairs:\n",
    "    visualize_type='pairs'\n",
    "    visualize_segment_labels=False\n",
    "    mark_depths=True\n",
    "else:\n",
    "    visualize_type='fullpath'\n",
    "    visualize_segment_labels=False\n",
    "    mark_depths=False\n",
    "\n",
    "# Visualize the combined segments\n",
    "_, _, _, _ = visualize_combined_segments(\n",
    "    # Input data\n",
    "    log_a=log_a,                                # Core A log data\n",
    "    log_b=log_b,                                # Core B log data\n",
    "    md_a=md_a,                                  # Core A measured depths\n",
    "    md_b=md_b,                                  # Core B measured depths\n",
    "    dtw_results=dtw_results,                    # DTW alignment results\n",
    "    valid_dtw_pairs=valid_dtw_pairs,            # Valid DTW pairs\n",
    "    segments_a=segments_a,                      # Core A segments\n",
    "    segments_b=segments_b,                      # Core B segments\n",
    "    depth_boundaries_a=depth_boundaries_a,      # Core A depth boundaries\n",
    "    depth_boundaries_b=depth_boundaries_b,      # Core B depth boundaries\n",
    "    dtw_distance_matrix_full=dtw_distance_matrix_full,       # Full DTW distance matrix\n",
    "    segment_pairs_to_combine=top_mapping_pairs[0],           # Valid pairs to combine\n",
    "    # Visualization options\n",
    "    color_interval_size=10,                     # Size of color intervals\n",
    "    visualize_pairs=visualize_pairs,            # Whether to visualize pairs (True/False)\n",
    "    visualize_segment_labels=visualize_segment_labels, # Whether to show segment labels (True/False)\n",
    "    mark_depths=mark_depths,                    # Whether to mark depths (True/False)\n",
    "    # Output paths\n",
    "    correlation_save_path=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_correlation_{YES_NO_AGE}_{SEARCH_METHOD}_{top_mapping_ids[0]}_{visualize_type}.png',\n",
    "    matrix_save_path=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_matrix_{YES_NO_AGE}_{SEARCH_METHOD}_{top_mapping_ids[0]}_{visualize_type}.png',\n",
    "    # Age constraint parameters\n",
    "    mark_ages=age_consideration,                # Whether to mark ages (True/False)\n",
    "    ages_a=estimated_datum_ages_a if age_consideration else None, # Core A ages\n",
    "    ages_b=estimated_datum_ages_b if age_consideration else None, # Core B ages\n",
    "    all_constraint_ages_a=age_data_a['in_sequence_ages'] if age_consideration else None, # Core A constraint ages\n",
    "    all_constraint_ages_b=age_data_b['in_sequence_ages'] if age_consideration else None, # Core B constraint ages\n",
    "    all_constraint_depths_a=age_data_a['in_sequence_depths'] if age_consideration else None, # Core A constraint depths\n",
    "    all_constraint_depths_b=age_data_b['in_sequence_depths'] if age_consideration else None, # Core B constraint depths\n",
    "    all_constraint_pos_errors_a=age_data_a['in_sequence_pos_errors'] if age_consideration else None, # Core A positive errors\n",
    "    all_constraint_pos_errors_b=age_data_b['in_sequence_pos_errors'] if age_consideration else None, # Core B positive errors\n",
    "    all_constraint_neg_errors_a=age_data_a['in_sequence_neg_errors'] if age_consideration else None, # Core A negative errors\n",
    "    all_constraint_neg_errors_b=age_data_b['in_sequence_neg_errors'] if age_consideration else None, # Core B negative errors\n",
    "    age_constraint_a_source_cores=age_data_a['core'] if age_consideration else None, # Core A source cores\n",
    "    age_constraint_b_source_cores=age_data_b['core'] if age_consideration else None, # Core B source cores\n",
    "    # Core identifiers\n",
    "    core_a_name=CORE_A,                         # Name of Core A\n",
    "    core_b_name=CORE_B,                         # Name of Core B\n",
    "    # Interpreted bed correlation\n",
    "    interpreted_bed_a=interpreted_bed_a,         # Interpreted bed name for Core A\n",
    "    interpreted_bed_b=interpreted_bed_b          # Interpreted bed name for Core B\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available quality indices: 'corr_coef', 'norm_dtw', 'dtw_ratio', 'perc_diag', 'dtw_warp_eff', 'perc_age_overlap'\n",
    "targeted_quality_index = ['corr_coef', 'norm_dtw']  # Can be a single string or list of strings\n",
    "\n",
    "# Handle both single index and multiple indices\n",
    "if isinstance(targeted_quality_index, str):\n",
    "    targeted_quality_index = [targeted_quality_index]\n",
    "\n",
    "# Loop over all targeted quality indices\n",
    "for quality_idx in targeted_quality_index:\n",
    "    plot_correlation_distribution(\n",
    "        # Input parameters\n",
    "        csv_file=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}_{SEARCH_METHOD}.csv',  # Path to mappings CSV file\n",
    "        target_mapping_id=top_mapping_ids[0],                                             # ID of mapping to analyze\n",
    "        quality_index=quality_idx,                                                        # Quality metric to plot\n",
    "        # Core names\n",
    "        core_a_name=CORE_A,                                                               # Core A name\n",
    "        core_b_name=CORE_B,                                                               # Core B name\n",
    "        # Histogram parameters\n",
    "        bin_width=None,                                                                   # Bin width (auto if None)\n",
    "        # Output parameters\n",
    "        save_png=True,                                                                    # Whether to save plot as PNG\n",
    "        png_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/{\"r-values\" if quality_idx == \"corr_coef\" else quality_idx}_distribution_{YES_NO_AGE}_{SEARCH_METHOD}.png',  # Output filename\n",
    "        # Distribution fitting parameters\n",
    "        pdf_method='normal',                                                              # PDF fitting method: 'KDE', 'skew-normal', or 'normal'\n",
    "        kde_bandwidth=0.05,                                                               # Bandwidth for KDE method\n",
    "        mute_mode=False                                                                   # Whether to suppress print statements\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
