{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# **pyCoreRelator** [![GitHub](https://img.shields.io/badge/GitHub-pyCoreRelator-blue?logo=github)](https://github.com/GeoLarryLai/pyCoreRelator) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.xxxxxxxx.svg)](https://doi.org/10.5281/zenodo.xxxxxxxx)\n",
    "## **Workshop Notebook #5: Core Pair Correlation Analysis**   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GeoLarryLai/pyCoreRelator/blob/main/pyCoreRelator_5_core_pair_analysis.ipynb)\n",
    "This notebook demonstrates the general workflow for using modules from **pyCoreRelator** to correlate core log pairs using Dynamic Time Warping (DTW) with boundary constraints and age considerations.\n",
    "\n",
    "### Key Functions from **pyCoreRelator**\n",
    "- **`load_core_log_data()`**: Load and visualize core log data with picked datums\n",
    "- **`load_core_age_constraints()`**: Load age constraint data for cores\n",
    "- **`calculate_interpolated_ages()`**: Calculate interpolated ages for picked depths\n",
    "- **`run_comprehensive_dtw_analysis()`**: Perform comprehensive DTW analysis on core pairs\n",
    "- **`find_complete_core_paths()`**: Search for complete correlation paths\n",
    "- **`find_best_mappings()`**: Identify best correlation mappings\n",
    "- **`visualize_combined_segments()`**: Visualize combined DTW segments\n",
    "- **`plot_correlation_distribution()`**: Plot quality metric distributions\n",
    "\n",
    "For advanced usage, see [FUNCTION_DOCUMENTATION.md](https://github.com/GeoLarryLai/pyCoreRelator/blob/main/FUNCTION_DOCUMENTATION.md) for more details.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4awuK6ffO2t"
   },
   "source": [
    "# **Import Packages**\n",
    "Load core correlation and DTW analysis functions from **pyCoreRelator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    run_comprehensive_dtw_analysis,\n",
    "    find_complete_core_paths,\n",
    "    diagnose_chain_breaks,\n",
    "    calculate_interpolated_ages,\n",
    "    load_pickeddepth_ages_from_csv,\n",
    "    visualize_combined_segments,\n",
    "    visualize_dtw_results_from_csv,\n",
    "    load_core_log_data,\n",
    "    plot_correlation_distribution,\n",
    "    find_best_mappings,\n",
    "    load_core_age_constraints\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Define Core Pair Configuration**\n",
    "\n",
    "Configure the core pairs and data sources for correlation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Core A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_A = \"M9907-25PC\"\n",
    "# CORE_A = \"M9907-23PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Core B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_B = \"M9907-23PC\"\n",
    "# CORE_B = \"M9907-11PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Log Columns and Data Paths\n",
    "\n",
    "Specify which log types to use for correlation and configure file paths for both cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Choose which logs to include\n",
    "# LOG_COLUMNS = ['hiresMS']\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `load_core_log_data()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads log data from multiple CSV files for a single core\n",
    "2. Normalizes log values to [0, 1] range if requested\n",
    "3. Loads picked datum depths from CSV file\n",
    "4. Creates visualization with core images and log traces\n",
    "5. Returns log data arrays and picked depth information\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_paths` *(dict)*: Dictionary mapping log names to file paths\n",
    "- `core_name` *(str)*: Name identifier for the core\n",
    "- `log_columns` *(list, default=None)*: List of log column names to extract (if None, uses all keys from log_paths)\n",
    "- `depth_column` *(str, default='SB_DEPTH_cm')*: Name of the depth column\n",
    "- `normalize` *(bool, default=True)*: Whether to normalize log values to [0, 1]\n",
    "- `column_alternatives` *(dict, default=None)*: Optional. Dictionary of alternative log column names\n",
    "- `core_img_1` *(str or array, default=None)*: Path to first core image (e.g., RGB) or pre-loaded image array\n",
    "- `core_img_2` *(str or array, default=None)*: Path to second core image (e.g., CT) or pre-loaded image array\n",
    "- `figsize` *(tuple, default=(20, 4))*: Figure size (width, height)\n",
    "- `picked_datum` *(str, default=None)*: Path to CSV file with picked depths\n",
    "- `categories` *(int/list/tuple/set, default=None)*: Category or categories to filter and display (None displays all)\n",
    "- `show_bed_number` *(bool, default=False)*: If True, displays bed numbers next to category depth lines\n",
    "- `cluster_data` *(dict, default=None)*: Dictionary containing cluster data with keys: 'depth_vals', 'labels_vals', 'k'\n",
    "- `core_img_1_cmap_range` *(tuple, default=None)*: Color map range for first core image (min_value, max_value)\n",
    "- `core_img_2_cmap_range` *(tuple, default=None)*: Color map range for second core image (min_value, max_value)\n",
    "- `show_fig` *(bool, default=True)*: Whether to display the figure\n",
    "\n",
    "**Returns:**\n",
    "- `log` (numpy.ndarray): Combined normalized log data array\n",
    "- `md` (numpy.ndarray): Measured depth array\n",
    "- `picked_depths` (numpy.ndarray): Array of picked datum depths\n",
    "- `interpreted_beds` (numpy.ndarray): Array of interpreted bed names corresponding to picked depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_a_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_A}/{CORE_A}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_A}/{CORE_A}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_A}/{CORE_A}_RGB_MLfilled.csv'\n",
    "}\n",
    "\n",
    "core_a_rgb_img = f\"example_data/processed_data/{CORE_A}/{CORE_A}_RGB.tiff\"\n",
    "core_a_ct_img = f\"example_data/processed_data/{CORE_A}/{CORE_A}_CT.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_a, md_a, picked_depths_a, interpreted_bed_a = load_core_log_data(\n",
    "    log_paths=core_a_log_paths,\n",
    "    core_name=CORE_A,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    core_img_1=core_a_rgb_img,\n",
    "    core_img_2=core_a_ct_img,\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_A}_pickeddepth.csv',\n",
    "    categories=[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_b_log_paths = {\n",
    "    'hiresMS': f'example_data/processed_data/{CORE_B}/{CORE_B}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'example_data/processed_data/{CORE_B}/{CORE_B}_CT_MLfilled.csv',\n",
    "    'Lumin': f'example_data/processed_data/{CORE_B}/{CORE_B}_RGB_MLfilled.csv'\n",
    "}\n",
    "core_b_rgb_img = f\"example_data/processed_data/{CORE_B}/{CORE_B}_RGB.tiff\"\n",
    "core_b_ct_img = f\"example_data/processed_data/{CORE_B}/{CORE_B}_CT.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_b, md_b, picked_depths_b, interpreted_bed_b = load_core_log_data(\n",
    "    log_paths=core_b_log_paths,\n",
    "    core_name=CORE_B,\n",
    "    log_columns=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    core_img_1=core_b_rgb_img,\n",
    "    core_img_2=core_b_ct_img,\n",
    "    picked_datum=f'example_data/picked_datum/{CORE_B}_pickeddepth.csv',\n",
    "    categories=[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Load Age Data and Estimate Ages for Datums**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Age Data Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `load_core_age_constraints()`**\n",
    "\n",
    "**What it does:**\n",
    "Loads radiocarbon age constraint data from CSV files for a specific core.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `core_name` *(str)*: Name identifier for the core\n",
    "- `age_base_path` *(str)*: Directory path containing age data CSV files\n",
    "- `data_columns` *(dict, default=None)*: Dictionary mapping standard field names to CSV column names. Expected keys: 'age', 'pos_error', 'neg_error', 'min_depth', 'max_depth', 'in_sequence', 'core', 'interpreted_bed'\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress all print statements\n",
    "\n",
    "**Required items in `data_columns` dictionary:**\n",
    "- `'age'`: CSV column name containing calibrated radiocarbon ages (in years BP)\n",
    "- `'pos_error'`: CSV column name containing positive 2-sigma age uncertainties (in years)\n",
    "- `'neg_error'`: CSV column name containing negative 2-sigma age uncertainties (in years)\n",
    "- `'min_depth'`: CSV column name containing minimum depth of the dated interval (in cm)\n",
    "- `'max_depth'`: CSV column name containing maximum depth of the dated interval (in cm)\n",
    "- `'in_sequence'`: CSV column name containing flag indicating if constraint is stratigraphically in sequence (boolean or 1/0)\n",
    "- `'core'`: CSV column name containing core identifier/name\n",
    "- `'interpreted_bed'`: CSV column name containing interpreted bed name or identifier\n",
    "\n",
    "**Returns:**\n",
    "- `depths` (list): Mean depths of age constraints\n",
    "- `ages` (list): Calibrated radiocarbon ages in years BP\n",
    "- `pos_errors` (list): Positive 2-sigma uncertainties\n",
    "- `neg_errors` (list): Negative 2-sigma uncertainties\n",
    "- `in_sequence_flags` (list): Boolean flags for stratigraphic sequence\n",
    "- `core` (str): Core identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staisch2024 = {\n",
    "    'age': 'calib810_agebp',\n",
    "    'pos_error': 'calib810_2sigma_pos', \n",
    "    'neg_error': 'calib810_2sigma_neg',\n",
    "    'min_depth': 'mindepth_cm',\n",
    "    'max_depth': 'maxdepth_cm',\n",
    "    'in_sequence': 'in_sequence',\n",
    "    'core': 'core',\n",
    "    'interpreted_bed': 'interpreted_bed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize age constraints loading for Core A\n",
    "age_data_a = load_core_age_constraints(\n",
    "    CORE_A,\n",
    "    age_base_path='example_data/raw_data/C14age_data',\n",
    "    data_columns=staisch2024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data_b = load_core_age_constraints(\n",
    "    CORE_B,\n",
    "    age_base_path='example_data/raw_data/C14age_data',\n",
    "    data_columns=staisch2024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Age for Every Picked Datum\n",
    "\n",
    "**Function: `calculate_interpolated_ages()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Interpolates ages for picked depths using age constraint data\n",
    "2. Calculates age uncertainties using Monte Carlo, Linear, or Gaussian methods\n",
    "3. Handles top and bottom boundary ages\n",
    "4. Exports results to CSV and creates visualization plots\n",
    "\n",
    "**Key Parameters:**\n",
    "- `picked_datum` *(list)*: Depths to interpolate ages for\n",
    "- `age_constraints_depths` *(list or pd.Series, default=None)*: List of mean depths for all age constraints (not required if age_data is provided)\n",
    "- `age_constraints_ages` *(list, default=None)*: List of calibrated ages for all age constraints in years BP (not required if age_data is provided)\n",
    "- `age_constraints_pos_errors` *(list, default=None)*: List of positive error values for all age constraints in years (not required if age_data is provided)\n",
    "- `age_constraints_neg_errors` *(list, default=None)*: List of negative error values for all age constraints in years (not required if age_data is provided)\n",
    "- `age_constraint_source_core` *(list, default=None)*: List of source core names for each age constraint (not required if age_data is provided)\n",
    "- `age_constraints_in_sequence_flags` *(list, default=None)*: List indicating which age constraints are in sequence (not required if age_data is provided)\n",
    "- `age_data` *(dict, default=None)*: Dictionary containing age constraint data from `load_core_age_constraints()`. If provided, individual age constraint parameters are not required. Expected keys: 'depths', 'ages', 'pos_errors', 'neg_errors', 'in_sequence_flags', 'core'\n",
    "- `top_bottom` *(bool, default=True)*: Include top and bottom boundary depths/ages\n",
    "- `top_age` *(float, default=0)*: Age at top of core in years BP\n",
    "- `top_age_pos_error` *(float, default=0)*: Positive uncertainty of top age in years\n",
    "- `top_age_neg_error` *(float, default=0)*: Negative uncertainty of top age in years\n",
    "- `top_depth` *(float, default=0.0)*: Depth at top of core in cm\n",
    "- `bottom_depth` *(float, default=None)*: Maximum depth of core in cm (if None, uses last in-sequence constraint depth)\n",
    "- `uncertainty_method` *(str, default='MonteCarlo')*: Method for uncertainty calculation ('MonteCarlo', 'Linear', or 'Gaussian')\n",
    "- `n_monte_carlo` *(int, default=10000)*: Number of Monte Carlo iterations (only used when uncertainty_method='MonteCarlo')\n",
    "- `show_plot` *(bool, default=True)*: Whether to display age-depth plot\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the age-depth plot\n",
    "- `plot_filename` *(str, default=None)*: Filename for saving the plot\n",
    "- `core_name` *(str, default=None)*: Core name for plot title and file naming\n",
    "- `export_csv` *(bool, default=True)*: Whether to export results to CSV\n",
    "- `csv_filename` *(str, default=None)*: Output CSV filename (if None, default is '{core_name}_pickeddepth_age_{uncertainty_method}.csv')\n",
    "- `print_ages` *(bool, default=True)*: Whether to print age data\n",
    "- `mute_mode` *(bool, default=False)*: Whether to suppress console output\n",
    "\n",
    "**Alternative Function: `load_pickeddepth_ages_from_csv()`**\n",
    "\n",
    "**What it does:**\n",
    "Loads pre-calculated interpolated ages from CSV file (skips the age interpolation calculation step).\n",
    "\n",
    "**Key Parameters:**\n",
    "- `pickeddepth_age_csv` *(str)*: Path to CSV file containing pre-calculated ages from `calculate_interpolated_ages()`\n",
    "\n",
    "**Returns:**\n",
    "- `depths` (numpy.ndarray): Picked datum depths\n",
    "- `ages` (numpy.ndarray): Interpolated ages in years BP\n",
    "- `pos_uncertainties` (numpy.ndarray): Positive age uncertainties\n",
    "- `neg_uncertainties` (numpy.ndarray): Negative age uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the method for age uncertainty calculation: 'MonteCarlo', 'Linear', or 'Gaussian'\n",
    "sigma_method = 'MonteCarlo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_datum_ages_a = calculate_interpolated_ages(\n",
    "    picked_datum=picked_depths_a,\n",
    "    age_data=age_data_a,\n",
    "    top_depth=0.0,\n",
    "    bottom_depth=md_a[-1],\n",
    "    top_age=0,\n",
    "    top_age_pos_error=75,\n",
    "    top_age_neg_error=75,\n",
    "    uncertainty_method=sigma_method,\n",
    "    core_name=CORE_A,\n",
    "    csv_filename=f'example_data/picked_datum/{CORE_A}_pickeddepth_ages_{sigma_method}.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Load pre-calculated ages from CSV\n",
    "# estimated_datum_ages_a = load_pickeddepth_ages_from_csv(\n",
    "#     pickeddepth_age_csv=f\"example_data/picked_datum/{CORE_A}_pickeddepth_ages_{sigma_method}.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_datum_ages_b = calculate_interpolated_ages(\n",
    "    picked_datum=picked_depths_b,\n",
    "    age_data=age_data_b,\n",
    "    top_depth=0.0,\n",
    "    bottom_depth=md_b[-1],\n",
    "    top_age=0,\n",
    "    top_age_pos_error=75,\n",
    "    top_age_neg_error=75,\n",
    "    uncertainty_method=sigma_method,\n",
    "    core_name=CORE_B,\n",
    "    csv_filename=f'example_data/picked_datum/{CORE_B}_pickeddepth_ages_{sigma_method}.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated_datum_ages_b = load_pickeddepth_ages_from_csv(\n",
    "#     pickeddepth_age_csv=f\"example_data/picked_datum/{CORE_B}_pickeddepth_ages_{sigma_method}.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Run DTW Analysis Between Two Cores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform DTW Analysis on Segment Pairs\n",
    "\n",
    "**Function: `run_comprehensive_dtw_analysis()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Creates segments between picked datum boundaries\n",
    "2. Identifies valid segment pairs based on depth and age constraints\n",
    "3. Performs DTW analysis on each valid segment pair\n",
    "4. Calculates DTW distances and quality metrics\n",
    "5. Creates visualizations (DTW matrix, animations) of segment pairs\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_a` *(array)*: Core A log data\n",
    "- `log_b` *(array)*: Core B log data\n",
    "- `md_a` *(array)*: Core A measured depths\n",
    "- `md_b` *(array)*: Core B measured depths\n",
    "- `picked_datum_a` *(list, default=None)*: Picked datum depths for Core A\n",
    "- `picked_datum_b` *(list, default=None)*: Picked datum depths for Core B\n",
    "- `top_bottom` *(bool, default=True)*: Include top and bottom boundaries\n",
    "- `top_depth` *(float, default=0.0)*: Starting depth for analysis\n",
    "- `independent_dtw` *(bool, default=False)*: Use independent DTW for each log dimension\n",
    "- `create_dtw_matrix` *(bool, default=False)*: Generate DTW distance matrix visualization\n",
    "- `visualize_pairs` *(bool, default=True)*: Show segment pairs in matrix plot\n",
    "- `visualize_segment_labels` *(bool, default=False)*: Show segment labels in visualizations\n",
    "- `dtwmatrix_output_filename` *(str, default='SegmentPair_DTW_matrix.png')*: Filename for DTW matrix output\n",
    "- `creategif` *(bool, default=False)*: Create animated GIF of segment correlations\n",
    "- `gif_output_filename` *(str, default='SegmentPair_DTW_animation.gif')*: Filename for animation output\n",
    "- `max_frames` *(int, default=100)*: Maximum number of frames in animation\n",
    "- `debug` *(bool, default=False)*: Enable debug output\n",
    "- `color_interval_size` *(float, default=10)*: Color interval size for visualizations\n",
    "- `keep_frames` *(bool, default=True)*: Keep individual animation frames\n",
    "- `age_consideration` *(bool, default=False)*: Apply age constraint analysis\n",
    "- `ages_a` *(dict, default=None)*: Age data for Core A with keys: 'depths', 'ages', 'pos_uncertainties', 'neg_uncertainties'\n",
    "- `ages_b` *(dict, default=None)*: Age data for Core B with keys: 'depths', 'ages', 'pos_uncertainties', 'neg_uncertainties'\n",
    "- `restricted_age_correlation` *(bool, default=True)*: Use strict age overlap requirements\n",
    "- `core_a_age_data` *(dict, default=None)*: Complete age constraint data for Core A from `load_core_age_constraints()`. Expected keys: 'in_sequence_ages', 'in_sequence_depths', 'in_sequence_pos_errors', 'in_sequence_neg_errors', 'core'\n",
    "- `core_b_age_data` *(dict, default=None)*: Complete age constraint data for Core B from `load_core_age_constraints()`. Expected keys: 'in_sequence_ages', 'in_sequence_depths', 'in_sequence_pos_errors', 'in_sequence_neg_errors', 'core'\n",
    "- `dtw_distance_threshold` *(float, default=None)*: Maximum allowed DTW distance for segment acceptance\n",
    "- `exclude_deadend` *(bool, default=True)*: Filter out dead-end segment pairs\n",
    "- `core_a_name` *(str, default=None)*: Core A identifier\n",
    "- `core_b_name` *(str, default=None)*: Core B identifier\n",
    "- `mute_mode` *(bool, default=False)*: Suppress all print output\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent multidimensional DTW (if False, uses conventional multidimensional DTW)\n",
    "- `dpi` *(int, default=None)*: Resolution for saved figures and GIF frames in dots per inch. If None, uses default (150)\n",
    "\n",
    "**Returns:**\n",
    "- `dtw_result` (dict): Dictionary containing all DTW analysis results with keys:\n",
    "  - `dtw_correlation` (dict): DTW results for valid segment pairs (renamed from dtw_results)\n",
    "  - `valid_dtw_pairs` (set): Set of valid segment pair tuples (a_idx, b_idx)\n",
    "  - `segments_a` (list): Segment definitions for Core A\n",
    "  - `segments_b` (list): Segment definitions for Core B\n",
    "  - `depth_boundaries_a` (list): Depth boundary indices for Core A\n",
    "  - `depth_boundaries_b` (list): Depth boundary indices for Core B\n",
    "  - `dtw_distance_matrix_full` (numpy.ndarray): Full DTW distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if age constraints should be considered based on missing values in estimated ages\n",
    "age_consideration = not (pd.isna(estimated_datum_ages_a['ages']).any() or pd.isna(estimated_datum_ages_b['ages']).any())\n",
    "# age_consideration = False  # (manual override option for debugging)\n",
    "\n",
    "# Set whether to enforce strict age overlap requirement for valid segment pairs\n",
    "restricted_age_overlap = True\n",
    "\n",
    "# Choose code for which age consideration method is in effect (for filenames/logic)\n",
    "if age_consideration:\n",
    "    if restricted_age_overlap:\n",
    "        YES_NO_AGE = 'restricted_age'   # If strict (restricted) age overlap is used\n",
    "    else:\n",
    "        YES_NO_AGE = 'loose_age'        # If looser age overlap acceptance is used\n",
    "else:\n",
    "    YES_NO_AGE = 'no_age'               # If age consideration is disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_result = run_comprehensive_dtw_analysis(\n",
    "    log_a,\n",
    "    log_b,\n",
    "    md_a,\n",
    "    md_b,\n",
    "    picked_datum_a=picked_depths_a,\n",
    "    picked_datum_b=picked_depths_b,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    age_consideration=age_consideration,\n",
    "    ages_a=estimated_datum_ages_a,\n",
    "    ages_b=estimated_datum_ages_b,\n",
    "    restricted_age_correlation=restricted_age_overlap,\n",
    "    core_a_age_data=age_data_a,\n",
    "    core_b_age_data=age_data_b,\n",
    "    create_dtw_matrix=True,\n",
    "    dtwmatrix_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/SegmentPair_DTW_matrix_{YES_NO_AGE}.png',\n",
    "    creategif=True,\n",
    "    gif_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/SegmentPair_DTW_animation_{YES_NO_AGE}.gif'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnose Connectivity for Topological Solution Search\n",
    "\n",
    "**Function: `diagnose_chain_breaks()`**\n",
    "\n",
    "**What it does:**\n",
    "Analyzes the segment network to identify connectivity issues and potential breaks in the correlation chain. Traces all possible paths and identifies missing connections. Computes total complete paths and finds the \"far most\" bounding complete paths.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'valid_dtw_pairs', 'segments_a', 'segments_b', 'depth_boundaries_a', 'depth_boundaries_b'\n",
    "\n",
    "#### Estimating Total Possible Solutions\n",
    "\n",
    "Given $n$ picked datums per core, segments are $S = 2n + 1$. Theoretical maximum segment pairs: $P_{\\max} = S_A \\times S_B$. DTW shortest path filtering often retains ~74.5%, giving:\n",
    "\n",
    "$$P_{\\mathrm{valid}} \\approx 0.745 \\times (S_A \\times S_B)$$\n",
    "\n",
    "Total solution count follows a quadratic-in-log-space pattern (fitted on 97 Cascadia turbidite core pairs, $R^2 > 0.999$):\n",
    "\n",
    "$$C \\approx e^{4.395 (\\ln P_{\\mathrm{valid}})^2 - 43.179 \\ln P_{\\mathrm{valid}} + 116.872}$$\n",
    "\n",
    "**Example:** Cores with 6-8 datums (13-17 segments) yield $10^{4}$-$10^{8}$ solutions; 30-31 datums (61-63 segments) yield $10^{20}$-$10^{24}$ solutions. Solution space grows exponentially with problem size.\n",
    "**Returns:**\n",
    "- `complete_paths` (list): All complete correlation paths found\n",
    "- `num_complete_paths` (int): Total number of complete paths\n",
    "- `chain_breaks` (list): Identified connectivity breaks in the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_result = diagnose_chain_breaks(dtw_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Find Stratigraphically Plausible Correlation Solutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for All Complete DTW Paths\n",
    "\n",
    "**Function: `find_complete_core_paths()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Searches through all valid segment pairs to find complete correlation paths\n",
    "2. Calculates quality metrics for each complete path\n",
    "3. Uses shortest path algorithms to optimize search\n",
    "4. Exports all valid mappings to CSV file\n",
    "\n",
    "**Key Parameters:**\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'dtw_correlation', 'valid_dtw_pairs', 'segments_a', 'segments_b', 'depth_boundaries_a', 'depth_boundaries_b', 'dtw_distance_matrix_full'\n",
    "- `log_a` *(array)*: Core A log data for metric computation\n",
    "- `log_b` *(array)*: Core B log data for metric computation\n",
    "- `output_csv` *(str, default='complete_core_paths.csv')*: Output CSV filename for mappings\n",
    "- `debug` *(bool, default=False)*: Enable detailed progress reporting\n",
    "- `start_from_top_only` *(bool, default=True)*: Only start paths from top segments\n",
    "- `batch_size` *(int, default=1000)*: Processing batch size for memory management\n",
    "- `n_jobs` *(int, default=-1)*: Number of parallel jobs (-1 uses all CPU cores)\n",
    "- `shortest_path_search` *(bool, default=True)*: Keep only shortest path lengths during search\n",
    "- `shortest_path_level` *(int, default=2)*: Number of shortest unique lengths to keep (higher = more segments)\n",
    "- `max_search_path` *(int, default=5000)*: Maximum paths per segment pair to prevent memory overflow. Higher, more comprehensive in the solution search (e.g., 100000 would typically work great).\n",
    "- `output_metric_only` *(bool, default=False)*: If True, only output quality metrics without full path details\n",
    "- `mute_mode` *(bool, default=False)*: Suppress all print output\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent DTW quality calculations\n",
    "\n",
    "**Returns:**\n",
    "- `complete_path_search_result` (dict): Dictionary containing:\n",
    "    - `complete_paths` (list): All complete correlation paths with quality metrics\n",
    "    - `num_paths` (int): Total number of complete paths found\n",
    "    - `csv_file` (str): Path to output CSV file containing all mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_path_search_result = find_complete_core_paths(\n",
    "    dtw_result,\n",
    "    log_a,\n",
    "    log_b,\n",
    "    output_csv=f\"example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}.csv\",\n",
    "    shortest_path_level=2,\n",
    "    max_search_path=5000 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Mapping Results\n",
    "\n",
    "**Function: `visualize_dtw_results_from_csv()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads complete path mappings from CSV file\n",
    "2. Creates visualizations for a representative subset of mappings\n",
    "3. Generates animated GIFs showing correlation and DTW matrix views\n",
    "4. Displays age constraints and interpreted bed correlations\n",
    "\n",
    "**Key Parameters:**\n",
    "- `input_mapping_csv` *(str)*: Path to CSV file containing DTW mapping results\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'dtw_correlation', 'valid_dtw_pairs', 'segments_a', 'segments_b', 'depth_boundaries_a', 'depth_boundaries_b', 'dtw_distance_matrix_full'\n",
    "- `log_a` *(array)*: Normalized log data for Core A\n",
    "- `log_b` *(array)*: Normalized log data for Core B\n",
    "- `md_a` *(array)*: Measured depth array for Core A\n",
    "- `md_b` *(array)*: Measured depth array for Core B\n",
    "- `color_interval_size` *(int, default=None)*: Step size for warping path visualization\n",
    "- `max_frames` *(int, default=150)*: Maximum number of frames to generate\n",
    "- `debug` *(bool, default=False)*: Enable debug output\n",
    "- `creategif` *(bool, default=True)*: Whether to create GIF files\n",
    "- `keep_frames` *(bool, default=False)*: Whether to keep individual PNG frames\n",
    "- `correlation_gif_output_filename` *(str, default='CombinedDTW_correlation_mappings.gif')*: Output filename for correlation GIF\n",
    "- `matrix_gif_output_filename` *(str, default='CombinedDTW_matrix_mappings.gif')*: Output filename for matrix GIF\n",
    "- `visualize_pairs` *(bool, default=False)*: Whether to visualize segment pairs\n",
    "- `visualize_segment_labels` *(bool, default=False)*: Whether to show segment labels\n",
    "- `mark_depths` *(bool, default=True)*: Whether to mark depth boundaries\n",
    "- `mark_ages` *(bool, default=True)*: Whether to mark age constraints\n",
    "- `ages_a` *(dict, default=None)*: Age data dictionaries for Core A picked depths\n",
    "- `ages_b` *(dict, default=None)*: Age data dictionaries for Core B picked depths\n",
    "- `core_a_age_data` *(dict, default=None)*: Complete age constraint data from `load_core_age_constraints()`. Expected keys: 'in_sequence_ages', 'in_sequence_depths', 'in_sequence_pos_errors', 'in_sequence_neg_errors', 'core'\n",
    "- `core_b_age_data` *(dict, default=None)*: Complete age constraint data from `load_core_age_constraints()`. Expected keys: 'in_sequence_ages', 'in_sequence_depths', 'in_sequence_pos_errors', 'in_sequence_neg_errors', 'core'\n",
    "- `core_a_name` *(str, default=None)*: Core A identifier for labels\n",
    "- `core_b_name` *(str, default=None)*: Core B identifier for labels\n",
    "- `core_a_interpreted_beds` *(dict, default=None)*: Interpreted bed names for Core A\n",
    "- `core_b_interpreted_beds` *(dict, default=None)*: Interpreted bed names for Core B\n",
    "- `dpi` *(int, default=None)*: Resolution for saved frames and GIFs in dots per inch. If None, uses default (150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dtw_results_from_csv(\n",
    "    dtw_result,\n",
    "    log_a,\n",
    "    log_b,\n",
    "    md_a,\n",
    "    md_b,\n",
    "    input_mapping_csv = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}.csv',\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    visualize_pairs=False,\n",
    "    visualize_segment_labels=False,\n",
    "    mark_depths=False,\n",
    "    creategif=True,\n",
    "    correlation_gif_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_correlation_mappings_{YES_NO_AGE}.gif',\n",
    "    matrix_gif_output_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_matrix_mappings_{YES_NO_AGE}.gif',\n",
    "    mark_ages=age_consideration,\n",
    "    ages_a=estimated_datum_ages_a,\n",
    "    ages_b=estimated_datum_ages_b,\n",
    "    core_a_age_data=age_data_a,\n",
    "    core_b_age_data=age_data_b,\n",
    "    core_a_interpreted_beds=interpreted_bed_a,\n",
    "    core_b_interpreted_beds=interpreted_bed_b\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Correlation Mapping\n",
    "\n",
    "**Function: `find_best_mappings()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads all complete path mappings from CSV\n",
    "2. Filters mappings based on interpreted bed correlations (if provided)\n",
    "3. Ranks mappings by quality metrics\n",
    "4. Returns top-scored mapping(s)\n",
    "\n",
    "**Key Parameters:**\n",
    "- `input_mapping_csv` *(str)*: Path to mappings CSV file\n",
    "- `top_n` *(int, default=10)*: Number of top mappings to return\n",
    "- `filter_shortest_dtw` *(bool, default=True)*: Filter for shortest DTW paths\n",
    "- `metric_weight` *(dict, default=None)*: Custom weights for quality metrics (e.g., {'corr_coef': 2.0, 'norm_dtw': 1.5})\n",
    "- `core_a_picked_datums` *(array, default=None)*: Picked depths for Core A\n",
    "- `core_b_picked_datums` *(array, default=None)*: Picked depths for Core B\n",
    "- `core_a_interpreted_beds` *(dict, default=None)*: Interpreted bed names for Core A\n",
    "- `core_b_interpreted_beds` *(dict, default=None)*: Interpreted bed names for Core B\n",
    "- `dtw_result` *(dict, default=None)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'valid_dtw_pairs', 'segments_a', 'segments_b'. Required only for boundary correlation mode\n",
    "\n",
    "**Returns:**\n",
    "- `top_mapping_ids` (list): Mapping IDs of top-ranked solutions\n",
    "- `top_mapping_pairs` (list): Segment pair lists for each top mapping\n",
    "- `top_mappings_df` (pandas.DataFrame): DataFrame containing top mappings with all quality metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mapping_ids, top_mapping_pairs, top_mappings_df = find_best_mappings(\n",
    "    input_mapping_csv = f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}.csv',\n",
    "    core_a_picked_datums=picked_depths_a,\n",
    "    core_b_picked_datums=picked_depths_b,\n",
    "    core_a_interpreted_beds=interpreted_bed_a,\n",
    "    core_b_interpreted_beds=interpreted_bed_b,\n",
    "    dtw_result=dtw_result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Best Mapping\n",
    "\n",
    "**Function: `visualize_combined_segments()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Combines all segment pairs in the selected mapping\n",
    "2. Creates comprehensive correlation visualization\n",
    "3. Shows DTW paths, age constraints, and interpreted bed correlations\n",
    "4. Saves high-quality figures in specified formats\n",
    "\n",
    "**Key Parameters:**\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'dtw_correlation', 'valid_dtw_pairs', 'segments_a', 'segments_b', 'depth_boundaries_a', 'depth_boundaries_b', 'dtw_distance_matrix_full'\n",
    "- `log_a` *(array)*: Core A log data\n",
    "- `log_b` *(array)*: Core B log data\n",
    "- `md_a` *(array)*: Core A measured depths\n",
    "- `md_b` *(array)*: Core B measured depths\n",
    "- `segment_pairs_to_combine` *(list)*: List of tuples (a_idx, b_idx) for segment pairs to combine\n",
    "- `correlation_save_path` *(str, default='CombinedSegmentPairs_DTW_correlation.png')*: Path to save correlation figure\n",
    "- `matrix_save_path` *(str, default='CombinedSegmentPairs_DTW_matrix.png')*: Path to save DTW matrix figure\n",
    "- `color_interval_size` *(int, default=None)*: Step size for warping path visualization\n",
    "- `visualize_pairs` *(bool, default=True)*: Whether to show segment pair boundaries\n",
    "- `visualize_segment_labels` *(bool, default=True)*: Whether to show segment labels\n",
    "- `mark_depths` *(bool, default=True)*: Whether to mark picked depths\n",
    "- `mark_ages` *(bool, default=False)*: Whether to mark age constraints\n",
    "- `ages_a` *(dict, default=None)*: Age data for Core A picked depths\n",
    "- `ages_b` *(dict, default=None)*: Age data for Core B picked depths\n",
    "- `core_a_age_data` *(dict, default=None)*: Complete age constraint data for Core A from `load_core_age_constraints()`\n",
    "- `core_b_age_data` *(dict, default=None)*: Complete age constraint data for Core B from `load_core_age_constraints()`\n",
    "- `core_a_name` *(str, default=None)*: Core A identifier for labels\n",
    "- `core_b_name` *(str, default=None)*: Core B identifier for labels\n",
    "- `core_a_interpreted_beds` *(dict, default=None)*: Arrays of interpreted bed names corresponding to depth boundaries (when both provided with matching bed names, correlation lines will be drawn between cores)\n",
    "- `core_b_interpreted_beds` *(dict, default=None)*: Arrays of interpreted bed names corresponding to depth boundaries (when both provided with matching bed names, correlation lines will be drawn between cores)\n",
    "\n",
    "**Returns:**\n",
    "- `combined_wp` (numpy.ndarray): Combined warping path spanning all selected segments\n",
    "- `combined_quality` (dict): Aggregated quality metrics for the combined correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "_, _ = visualize_combined_segments(\n",
    "    dtw_result,\n",
    "    log_a,\n",
    "    log_b,\n",
    "    md_a,\n",
    "    md_b,\n",
    "    segment_pairs_to_combine=top_mapping_pairs[0],\n",
    "    visualize_pairs=True,\n",
    "    visualize_segment_labels=False,\n",
    "    mark_depths=True,\n",
    "    correlation_save_path=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_correlation_{YES_NO_AGE}_{top_mapping_ids[0]}.png',\n",
    "    matrix_save_path=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/CombinedDTW_matrix_{YES_NO_AGE}_{top_mapping_ids[0]}.png',\n",
    "    mark_ages=age_consideration,\n",
    "    ages_a=estimated_datum_ages_a if age_consideration else None,\n",
    "    ages_b=estimated_datum_ages_b if age_consideration else None,\n",
    "    core_a_age_data=age_data_a if age_consideration else None,\n",
    "    core_b_age_data=age_data_b if age_consideration else None,\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    core_a_interpreted_beds=interpreted_bed_a,\n",
    "    core_b_interpreted_beds=interpreted_bed_b\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Quality Metric Distributions\n",
    "\n",
    "**Function: `plot_correlation_distribution()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads all mappings from CSV file\n",
    "2. Extracts quality metrics for the target mapping\n",
    "3. Plots histogram and probability distribution\n",
    "4. Compares target mapping against all other solutions\n",
    "5. Saves distribution plot as PNG\n",
    "\n",
    "**Key Parameters:**\n",
    "- `mapping_csv` *(str)*: Path to mappings CSV or Parquet file\n",
    "- `target_mapping_id` *(int, default=None)*: ID of mapping to highlight in the plot (optional)\n",
    "- `quality_index` *(str)*: Quality metric to plot - **required**. Options: 'corr_coef', 'norm_dtw', 'dtw_ratio', 'variance_deviation', 'perc_diag', 'match_min', 'match_mean', 'perc_age_overlap'\n",
    "- `save_png` *(bool, default=True)*: Whether to save plot as PNG\n",
    "- `png_filename` *(str, default=None)*: Output PNG filename (optional)\n",
    "- `core_a_name` *(str, default=None)*: Core A name for plot title (optional)\n",
    "- `core_b_name` *(str, default=None)*: Core B name for plot title (optional)\n",
    "- `bin_width` *(float, default=None)*: Histogram bin width (auto if None, based on quality_index)\n",
    "- `pdf_method` *(str, default='normal')*: PDF fitting method ('KDE', 'skew-normal', or 'normal')\n",
    "- `kde_bandwidth` *(float, default=0.05)*: Bandwidth for KDE when pdf_method='KDE'\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress all print statements\n",
    "- `targeted_binsize` *(tuple, default=None)*: (synthetic_bins, bin_width) for consistent bin sizing with synthetic data\n",
    "- `dpi` *(int, default=None)*: Resolution for saved figures in dots per inch. If None, uses default (150)\n",
    "\n",
    "**Returns:**\n",
    "- `fit_params` (dict): Dictionary containing distribution statistics including histogram data, PDF parameters, and percentile information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Correlation Coefficient Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}.csv',\n",
    "    target_mapping_id=top_mapping_ids[0],\n",
    "    quality_index='corr_coef',\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    save_png=True,\n",
    "    png_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/r-values_distribution_{YES_NO_AGE}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Normalized DTW Cost Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/mappings_{YES_NO_AGE}.csv',\n",
    "    target_mapping_id=top_mapping_ids[0],\n",
    "    quality_index='norm_dtw',\n",
    "    core_a_name=CORE_A,\n",
    "    core_b_name=CORE_B,\n",
    "    save_png=True,\n",
    "    png_filename=f'example_data/analytical_outputs/{CORE_A}_{CORE_B}/{\"_\".join(LOG_COLUMNS)}/norm_dtw_distribution_{YES_NO_AGE}.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
