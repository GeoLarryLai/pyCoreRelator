{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# Manual core depth picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image and file handling\n",
    "import os\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyCoreRelator import plot_core_data, pick_stratigraphic_levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the core to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORE_NAME = \"M9907-01PC\"\n",
    "# CORE_NAME = \"M9907-02TC\"\n",
    "# CORE_NAME = \"M9907-03PC\"\n",
    "# CORE_NAME = \"M9907-05TC\"\n",
    "# CORE_NAME = \"M9907-06PC\"\n",
    "# CORE_NAME = \"M9907-07PC\"\n",
    "# CORE_NAME = \"M9907-07TC\"\n",
    "# CORE_NAME = \"M9907-08PC\"\n",
    "# CORE_NAME = \"M9907-09PC\"\n",
    "# CORE_NAME = \"M9907-09TC\"\n",
    "# CORE_NAME = \"M9907-10PC\"\n",
    "# CORE_NAME = \"M9907-11PC\"\n",
    "# CORE_NAME = \"M9907-12PC\"\n",
    "# CORE_NAME = \"M9907-13PC\"\n",
    "# CORE_NAME = \"M9907-14PC\"\n",
    "# CORE_NAME = \"M9907-14TC\"\n",
    "# CORE_NAME = \"M9907-15PC\"\n",
    "# CORE_NAME = \"M9907-16PC\"\n",
    "# CORE_NAME = \"M9907-17PC\"\n",
    "CORE_NAME = \"M9907-19PC\"\n",
    "\n",
    "# CORE_NAME = \"M9907-22PC\"\n",
    "# CORE_NAME = \"M9907-23PC\"\n",
    "# CORE_NAME = \"M9907-25PC\"\n",
    "# CORE_NAME = \"M9907-30PC\"\n",
    "# CORE_NAME = \"M9907-31PC\"\n",
    "# CORE_NAME = \"RR0207-56PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load core data and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names to extract from dataset\n",
    "# LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "LOG_COLUMNS = ['hiresMS','CT', 'Lumin', 'Den_gm/cc', 'MS']  # Choose which logs to include\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "# Define directory paths\n",
    "mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "# Define paths for the core\n",
    "core_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_MST_MLfilled.csv',\n",
    "    'MS': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "rgb_img_path = f\"{mother_dir}_compiled_logs/{CORE_NAME}/{CORE_NAME}_RGB.tiff\"\n",
    "ct_img_path = f\"{mother_dir}_compiled_logs/{CORE_NAME}/{CORE_NAME}_CT.tiff\"\n",
    "\n",
    "# Define column mapping for alternative column names\n",
    "column_alternatives = {\n",
    "    'hiresMS': ['hiresMS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'R': ['R', 'red', 'Red'],\n",
    "    'G': ['G', 'green', 'Green'],\n",
    "    'B': ['B', 'blue', 'Blue'],\n",
    "    'Lumin': ['luminance', 'Luminance'],\n",
    "    'Den_gm/cc': ['Density', 'density'],\n",
    "    'MS': ['MS']\n",
    "}\n",
    "\n",
    "# Load images only if they exist\n",
    "rgb_img = None\n",
    "ct_img = None\n",
    "\n",
    "if os.path.exists(rgb_img_path):\n",
    "    rgb_img = plt.imread(rgb_img_path)\n",
    "else:\n",
    "    print(f\"RGB image not found: {rgb_img_path}\")\n",
    "\n",
    "if os.path.exists(ct_img_path):\n",
    "    ct_img = plt.imread(ct_img_path)\n",
    "else:\n",
    "    print(f\"CT image not found: {ct_img_path}\")\n",
    "\n",
    "# Load log data from separate files\n",
    "dfs = {}\n",
    "for log in LOG_COLUMNS:\n",
    "    try:\n",
    "        df = pd.read_csv(core_log_paths[log])\n",
    "        # Find the correct column name using alternatives if needed\n",
    "        col_name = log\n",
    "        if log not in df.columns:\n",
    "            for alt in column_alternatives.get(log, []):\n",
    "                if alt in df.columns:\n",
    "                    col_name = alt\n",
    "                    break\n",
    "        # Check if DEPTH_COLUMN exists in the dataframe\n",
    "        if DEPTH_COLUMN not in df.columns:\n",
    "            print(f\"Skipping {log}: {DEPTH_COLUMN} column not found\")\n",
    "            continue\n",
    "        dfs[log] = df[[DEPTH_COLUMN, col_name]].rename(columns={col_name: log})\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {log}: {e}\")\n",
    "\n",
    "# Merge dataframes on depth column\n",
    "if dfs:\n",
    "    # Get list of successfully loaded logs\n",
    "    available_logs = list(dfs.keys())\n",
    "    print(f\"Successfully loaded logs: {available_logs}\")\n",
    "    \n",
    "    # Start with the first available log\n",
    "    merged_df = dfs[available_logs[0]]\n",
    "    \n",
    "    # Merge with remaining available logs\n",
    "    for log in available_logs[1:]:\n",
    "        merged_df = pd.merge(merged_df, dfs[log], on=DEPTH_COLUMN, how='outer')\n",
    "    \n",
    "    # Sort by depth and handle missing values\n",
    "    merged_df = merged_df.sort_values(by=DEPTH_COLUMN).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Extract data only for available logs\n",
    "    log_data = np.array(merged_df[available_logs])\n",
    "    log_data = (log_data - np.min(log_data, axis=0)) / (np.max(log_data, axis=0) - np.min(log_data, axis=0))  # normalize to 0-1\n",
    "    measured_depth = np.array(merged_df[DEPTH_COLUMN])  # measured depth\n",
    "    \n",
    "    %matplotlib inline\n",
    "    \n",
    "    # Call plot_core_data with conditional image parameters\n",
    "    kwargs = {}\n",
    "    \n",
    "    if rgb_img is not None:\n",
    "        kwargs['core_img_1'] = rgb_img\n",
    "    if ct_img is not None:\n",
    "        kwargs['core_img_2'] = ct_img\n",
    "    \n",
    "    plot_core_data(\n",
    "        measured_depth, \n",
    "        log_data, \n",
    "        CORE_NAME, \n",
    "        label_name=available_logs,\n",
    "        **kwargs\n",
    "        )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data could be loaded for the specified logs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Interactive picking for stratigraphic levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "# should install ipympl\n",
    "\n",
    "# Pick stratigraphic levels for the core\n",
    "print(f\"Please pick stratigraphic levels for {CORE_NAME}\")\n",
    "picked_depths, picked_categories = pick_stratigraphic_levels(\n",
    "    measured_depth, \n",
    "    log_data, \n",
    "    core_name=CORE_NAME,\n",
    "    csv_filename=f\"pickeddepth/{CORE_NAME}_pickeddepth.csv\",\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sort and save picked depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and save the picked depths CSV file\n",
    "csv_file = f'pickeddepth/{CORE_NAME}_pickeddepth.csv'\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if not df.empty:\n",
    "        # Convert columns to numeric types to ensure correct sorting\n",
    "        df['category'] = pd.to_numeric(df['category'], errors='coerce')\n",
    "        df['picked_depths_cm'] = pd.to_numeric(df['picked_depths_cm'], errors='coerce')\n",
    "        # Drop rows with conversion issues\n",
    "        df = df.dropna(subset=['category', 'picked_depths_cm'])\n",
    "        \n",
    "        # Sort first by category, then by picked_depths_cm\n",
    "        df_sorted = df.sort_values(by=['category', 'picked_depths_cm'])\n",
    "        # Save the sorted DataFrame back to the CSV file\n",
    "        df_sorted.to_csv(csv_file, index=False)\n",
    "        print(f\"Sorted and saved {csv_file} with {len(df_sorted)} records.\")\n",
    "    else:\n",
    "        print(f\"File {csv_file} is empty. Skipping sorting.\")\n",
    "else:\n",
    "    print(f\"File {csv_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize picked boundaries & assign bed names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive datum naming for picked depths\n",
    "csv_file = f'pickeddepth/{CORE_NAME}_pickeddepth.csv'\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Add 'interpreted_bed' column if it doesn't exist\n",
    "    if 'interpreted_bed' not in df.columns:\n",
    "        df['interpreted_bed'] = ''\n",
    "    \n",
    "    # Handle NaN values by converting them to empty strings\n",
    "    df['interpreted_bed'] = df['interpreted_bed'].fillna('')\n",
    "    \n",
    "    print(f\"Interactive datum naming for {CORE_NAME}\")\n",
    "    print(\"Current data:\")\n",
    "    display(df[['category', 'picked_depths_cm', 'interpreted_bed']])\n",
    "    \n",
    "    # Show the figure with depths before entering names\n",
    "    picked_points = list(zip(df['picked_depths_cm'].values.tolist(), \n",
    "                            df['category'].values.tolist()))\n",
    "    picked_uncertainty = [1] * len(picked_points)\n",
    "    \n",
    "    # Define colors for different categories\n",
    "    category_colors = {\n",
    "        1: 'red',\n",
    "        2: 'blue',\n",
    "        3: 'green',\n",
    "        4: 'purple',\n",
    "        5: 'orange',\n",
    "        6: 'cyan',\n",
    "        7: 'magenta',\n",
    "        8: 'yellow',\n",
    "        9: 'black'\n",
    "    }\n",
    "    \n",
    "    # Plot core with picked boundaries colored by category\n",
    "    fig = plot_core_data(measured_depth, \n",
    "                         log_data, \n",
    "                         f\"{CORE_NAME} with Picked Boundaries\", \n",
    "                         core_img_1=rgb_img, \n",
    "                         core_img_2=ct_img,\n",
    "                         figsize=(20, 4))\n",
    "    \n",
    "    # Add colored uncertainty shading and boundaries\n",
    "    for (depth, category), uncertainty in zip(picked_points, picked_uncertainty):\n",
    "        color = category_colors.get(category, 'red')  # Default to red if category not in dictionary\n",
    "        # Add transparent shading covering the uncertainty interval\n",
    "        plt.axvspan(depth - uncertainty, \n",
    "                    depth + uncertainty, \n",
    "                    color=color, \n",
    "                    alpha=0.1)\n",
    "        # Add the picked depth line on top\n",
    "        plt.axvline(x=depth, \n",
    "                    color=color, \n",
    "                    linestyle='--', \n",
    "                    linewidth=1.2, \n",
    "                    label=f'#{category}' if f'#{category}' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    \n",
    "    # Add legend with unique category entries\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), \n",
    "               by_label.keys(), \n",
    "               loc='upper left', \n",
    "               ncol=len(by_label))\n",
    "    plt.title(f\"{CORE_NAME} with {len(picked_points)} Picked Boundaries\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create interactive widgets for datum naming\n",
    "    from ipywidgets import interact, widgets, VBox, HBox, Button, Output\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    # Create widgets\n",
    "    row_selector = widgets.Dropdown(\n",
    "        options=[(f\"Row {i}: Depth {df.loc[i, 'picked_depths_cm']} cm, Cat {df.loc[i, 'category']}\", i) \n",
    "                for i in range(len(df))],\n",
    "        description='Select Row:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    name_input = widgets.Text(\n",
    "        description='Bed Name:',\n",
    "        placeholder='Enter bed name (e.g., Bed_A)'\n",
    "    )\n",
    "    \n",
    "    update_button = widgets.Button(\n",
    "        description='Update Name',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    save_button = widgets.Button(\n",
    "        description='Save All Changes',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    # Event handlers\n",
    "    def on_row_change(change):\n",
    "        if change['new'] is not None:\n",
    "            current_name = df.loc[change['new'], 'interpreted_bed']\n",
    "            name_input.value = str(current_name) if pd.notna(current_name) else ''\n",
    "    \n",
    "    def on_update_click(b):\n",
    "        row_idx = row_selector.value\n",
    "        bed_name = name_input.value.strip()\n",
    "        \n",
    "        if row_idx is not None:\n",
    "            df.loc[row_idx, 'interpreted_bed'] = bed_name if bed_name else ''\n",
    "            with output_area:\n",
    "                clear_output()\n",
    "                print(f\"Updated row {row_idx} with name '{bed_name}'\")\n",
    "                print(f\"Depth: {df.loc[row_idx, 'picked_depths_cm']} cm, Category: {df.loc[row_idx, 'category']}\")\n",
    "        else:\n",
    "            with output_area:\n",
    "                clear_output()\n",
    "                print(\"Please select a row\")\n",
    "    \n",
    "    def on_save_click(b):\n",
    "        # Save data to CSV\n",
    "        df_to_save = df.copy()\n",
    "        df_to_save.to_csv(csv_file, index=False)\n",
    "        \n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(f\"Saved updated data to {csv_file}\")\n",
    "            \n",
    "            # Reload the data from the saved CSV file\n",
    "            updated_df = pd.read_csv(csv_file)\n",
    "            # Keep empty cells as empty strings instead of NaN\n",
    "            updated_df['interpreted_bed'] = updated_df['interpreted_bed'].fillna('')\n",
    "            print(\"Final data:\")\n",
    "            display(updated_df[['category', 'picked_depths_cm', 'interpreted_bed']])\n",
    "            \n",
    "            # Plot using the plot_core_data function with interpreted bed names\n",
    "            fig, plot_ax = plot_core_data(\n",
    "                measured_depth, \n",
    "                log_data, \n",
    "                f\"{CORE_NAME} with Named Boundaries\", \n",
    "                core_img_1=rgb_img, \n",
    "                core_img_2=ct_img,\n",
    "                figsize=(20, 4),\n",
    "                picked_depths=updated_df['picked_depths_cm'].tolist(),\n",
    "                picked_categories=updated_df['category'].tolist(),\n",
    "                picked_uncertainties=[1] * len(updated_df),\n",
    "                show_interpreted_bed_name=updated_df['interpreted_bed'].tolist()\n",
    "            )\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    # Connect event handlers\n",
    "    row_selector.observe(on_row_change, names='value')\n",
    "    update_button.on_click(on_update_click)\n",
    "    save_button.on_click(on_save_click)\n",
    "    \n",
    "    # Display widgets\n",
    "    controls = VBox([\n",
    "        row_selector,\n",
    "        name_input,\n",
    "        HBox([update_button, save_button]),\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    display(controls)\n",
    "    \n",
    "else:\n",
    "    print(f\"File {csv_file} not found. Please pick depths first.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
