{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25kTe2nS84Tf"
   },
   "source": [
    "# Manual core depth picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "47Kk07X_84Th"
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image and file handling\n",
    "import os\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyCoreRelator import plot_core_data, pick_stratigraphic_levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the core to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define core name for analysis\n",
    "# CORE_NAME = \"M9907-31PC\"\n",
    "# CORE_NAME = \"M9907-30PC\"\n",
    "# CORE_NAME = \"M9907-23PC\"\n",
    "# CORE_NAME = \"M9907-14TC\"\n",
    "# CORE_NAME = \"RR0207-56PC\"\n",
    "CORE_NAME = \"M9907-01PC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load core data and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading hiresMS: [Errno 2] No such file or directory: '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/_compiled_logs/M9907-01PC/ML_filled/M9907-01PC_hiresMS_MLfilled.csv'\n",
      "Error loading CT: [Errno 2] No such file or directory: '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/_compiled_logs/M9907-01PC/ML_filled/M9907-01PC_CT_MLfilled.csv'\n",
      "Error loading Lumin: [Errno 2] No such file or directory: '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/_compiled_logs/M9907-01PC/ML_filled/M9907-01PC_RGB_MLfilled.csv'\n",
      "No data could be loaded for the specified logs.\n"
     ]
    }
   ],
   "source": [
    "# Define column names to extract from dataset\n",
    "# LOG_COLUMNS = ['hiresMS']  # Choose which logs to include\n",
    "LOG_COLUMNS = ['hiresMS','CT', 'Lumin']  # Choose which logs to include\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "# Define directory paths\n",
    "mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/'\n",
    "\n",
    "# Define paths for the core\n",
    "core_log_paths = {\n",
    "    'hiresMS': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_hiresMS_MLfilled.csv',\n",
    "    'CT': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_CT_MLfilled.csv',\n",
    "    'Lumin': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'R': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'G': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'B': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_RGB_MLfilled.csv',\n",
    "    'Den_gm/cc': f'{mother_dir}_compiled_logs/{CORE_NAME}/ML_filled/{CORE_NAME}_MST_MLfilled.csv'\n",
    "}\n",
    "\n",
    "rgb_img_path = f\"{mother_dir}_compiled_logs/{CORE_NAME}/{CORE_NAME}_RGB.tiff\"\n",
    "ct_img_path = f\"{mother_dir}_compiled_logs/{CORE_NAME}/{CORE_NAME}_CT.tiff\"\n",
    "\n",
    "# Define column mapping for alternative column names\n",
    "column_alternatives = {\n",
    "    'hiresMS': ['MS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'R': ['R', 'red', 'Red'],\n",
    "    'G': ['G', 'green', 'Green'],\n",
    "    'B': ['B', 'blue', 'Blue'],\n",
    "    'Lumin': ['luminance', 'Luminance'],\n",
    "    'Den_gm/cc': ['Density', 'density']\n",
    "}\n",
    "\n",
    "# Load images\n",
    "rgb_img = plt.imread(rgb_img_path)\n",
    "ct_img = plt.imread(ct_img_path)\n",
    "\n",
    "# Load log data from separate files\n",
    "dfs = {}\n",
    "for log in LOG_COLUMNS:\n",
    "    try:\n",
    "        df = pd.read_csv(core_log_paths[log])\n",
    "        # Find the correct column name using alternatives if needed\n",
    "        col_name = log\n",
    "        if log not in df.columns:\n",
    "            for alt in column_alternatives.get(log, []):\n",
    "                if alt in df.columns:\n",
    "                    col_name = alt\n",
    "                    break\n",
    "        dfs[log] = df[[DEPTH_COLUMN, col_name]].rename(columns={col_name: log})\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {log}: {e}\")\n",
    "\n",
    "# Merge dataframes on depth column\n",
    "if dfs:\n",
    "    merged_df = dfs[LOG_COLUMNS[0]]\n",
    "    for log in LOG_COLUMNS[1:]:\n",
    "        if log in dfs:\n",
    "            merged_df = pd.merge(merged_df, dfs[log], on=DEPTH_COLUMN, how='outer')\n",
    "    \n",
    "    # Sort by depth and handle missing values\n",
    "    merged_df = merged_df.sort_values(by=DEPTH_COLUMN).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Extract data\n",
    "    log_data = np.array(merged_df[LOG_COLUMNS])\n",
    "    log_data = (log_data - np.min(log_data, axis=0)) / (np.max(log_data, axis=0) - np.min(log_data, axis=0))  # normalize to 0-1\n",
    "    measured_depth = np.array(merged_df[DEPTH_COLUMN])  # measured depth\n",
    "    \n",
    "    %matplotlib inline\n",
    "    \n",
    "    # Plot core with RGB image, CT image, and log curve\n",
    "    plot_core_data(\n",
    "        measured_depth, \n",
    "        log_data, \n",
    "        CORE_NAME, \n",
    "        core_img_1=rgb_img, \n",
    "        core_img_2=ct_img, \n",
    "        label_name=LOG_COLUMNS\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data could be loaded for the specified logs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Interactive picking for stratigraphic levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please pick stratigraphic levels for M9907-01PC\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'measured_depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# should install ipympl\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Pick stratigraphic levels for the core\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease pick stratigraphic levels for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m picked_depths, picked_categories = pick_stratigraphic_levels(\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mmeasured_depth\u001b[49m, \n\u001b[32m      8\u001b[39m     log_data, \n\u001b[32m      9\u001b[39m     core_img_1=rgb_img, \n\u001b[32m     10\u001b[39m     core_img_2=ct_img, \n\u001b[32m     11\u001b[39m     core_name=CORE_NAME,\n\u001b[32m     12\u001b[39m     csv_filename=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpickeddepth/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_pickeddepth.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'measured_depth' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib widget \n",
    "# should install ipympl\n",
    "\n",
    "# Pick stratigraphic levels for the core\n",
    "print(f\"Please pick stratigraphic levels for {CORE_NAME}\")\n",
    "picked_depths, picked_categories = pick_stratigraphic_levels(\n",
    "    measured_depth, \n",
    "    log_data, \n",
    "    core_img_1=rgb_img, \n",
    "    core_img_2=ct_img, \n",
    "    core_name=CORE_NAME,\n",
    "    csv_filename=f\"pickeddepth/{CORE_NAME}_pickeddepth.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sort and save picked depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and save the picked depths CSV file\n",
    "csv_file = f'pickeddepth/{CORE_NAME}_pickeddepth.csv'\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if not df.empty:\n",
    "        # Convert columns to numeric types to ensure correct sorting\n",
    "        df['category'] = pd.to_numeric(df['category'], errors='coerce')\n",
    "        df['picked_depths_cm'] = pd.to_numeric(df['picked_depths_cm'], errors='coerce')\n",
    "        # Drop rows with conversion issues\n",
    "        df = df.dropna(subset=['category', 'picked_depths_cm'])\n",
    "        \n",
    "        # Sort first by category, then by picked_depths_cm\n",
    "        df_sorted = df.sort_values(by=['category', 'picked_depths_cm'])\n",
    "        # Save the sorted DataFrame back to the CSV file\n",
    "        df_sorted.to_csv(csv_file, index=False)\n",
    "        print(f\"Sorted and saved {csv_file} with {len(df_sorted)} records.\")\n",
    "    else:\n",
    "        print(f\"File {csv_file} is empty. Skipping sorting.\")\n",
    "else:\n",
    "    print(f\"File {csv_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Visualize picked boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load picked depths and categories from CSV file\n",
    "pickeddepth_csv = f'pickeddepth/{CORE_NAME}_pickeddepth.csv'\n",
    "\n",
    "if os.path.exists(pickeddepth_csv):\n",
    "    picked_data = pd.read_csv(pickeddepth_csv)\n",
    "    # Combine depths and categories into tuples\n",
    "    picked_points = list(zip(picked_data['picked_depths_cm'].values.tolist(), \n",
    "                            picked_data['category'].values.tolist()))\n",
    "    print(f\"Loaded {len(picked_points)} picked depths for {CORE_NAME}\")\n",
    "else:\n",
    "    print(f\"Warning: {pickeddepth_csv} not found. Using empty list for picked points.\")\n",
    "    picked_points = []\n",
    "\n",
    "# Create uncertainty array (assuming uncertainty size is 1 cm)\n",
    "picked_uncertainty = [1] * len(picked_points)\n",
    "\n",
    "# Define colors for different categories\n",
    "category_colors = {\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'green',\n",
    "    4: 'purple',\n",
    "    5: 'orange',\n",
    "    6: 'cyan',\n",
    "    7: 'magenta',\n",
    "    8: 'yellow',\n",
    "    9: 'black'\n",
    "}\n",
    "\n",
    "# Plot core with picked boundaries colored by category\n",
    "fig = plot_core_data(measured_depth, \n",
    "                     log_data, \n",
    "                     f\"{CORE_NAME} with Picked Boundaries\", \n",
    "                     core_img_1=rgb_img, \n",
    "                     core_img_2=ct_img,\n",
    "                     figsize=(20, 4))\n",
    "\n",
    "# Add colored uncertainty shading and boundaries\n",
    "for (depth, category), uncertainty in zip(picked_points, picked_uncertainty):\n",
    "    color = category_colors.get(category, 'red')  # Default to red if category not in dictionary\n",
    "    # Add transparent shading covering the uncertainty interval\n",
    "    plt.axvspan(depth - uncertainty, \n",
    "                depth + uncertainty, \n",
    "                color=color, \n",
    "                alpha=0.1)\n",
    "    # Add the picked depth line on top\n",
    "    plt.axvline(x=depth, \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=1.2, \n",
    "                label=f'#{category}' if f'#{category}' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# Add legend with unique category entries\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), \n",
    "           by_label.keys(), \n",
    "           loc='upper left', \n",
    "           ncol=len(by_label))\n",
    "plt.title(f\"{CORE_NAME} with {len(picked_points)} Picked Boundaries\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-TimeSeriesCorrelation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
