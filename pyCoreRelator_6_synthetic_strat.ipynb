{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pyCoreRelator** [![GitHub](https://img.shields.io/badge/GitHub-pyCoreRelator-blue?logo=github)](https://github.com/GeoLarryLai/pyCoreRelator) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.xxxxxxxx.svg)](https://doi.org/10.5281/zenodo.xxxxxxxx)\n",
    "## **Workshop Notebook #6: Synthetic Stratigraphy Analysis**   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GeoLarryLai/pyCoreRelator/blob/main/pyCoreRelator_6_synthetic_strat.ipynb)\n",
    "This notebook demonstrates the workflow for generating synthetic stratigraphic sequences and analyzing correlation quality distributions using **pyCoreRelator**.\n",
    "\n",
    "### Key Functions from **pyCoreRelator**\n",
    "- **`load_segment_pool()`**: Load and organize turbidite segments from multiple cores\n",
    "- **`modify_segment_pool()`**: Remove or modify segments in the pool\n",
    "- **`plot_segment_pool()`**: Visualize all segments in the pool\n",
    "- **`create_synthetic_log()`**: Generate synthetic core logs from segment pool\n",
    "- **`plot_synthetic_log()`**: Visualize synthetic core logs\n",
    "- **`run_comprehensive_dtw_analysis()`**: Perform DTW analysis on synthetic pairs\n",
    "- **`find_complete_core_paths()`**: Search for complete correlation paths\n",
    "- **`plot_correlation_distribution()`**: Plot quality metric distributions\n",
    "- **`synthetic_correlation_quality()`**: Run multiple synthetic iterations\n",
    "- **`plot_synthetic_correlation_quality()`**: Visualize synthetic correlation results\n",
    "\n",
    "For advanced usage, see [FUNCTION_DOCUMENTATION.md](https://github.com/GeoLarryLai/pyCoreRelator/blob/main/FUNCTION_DOCUMENTATION.md) for more details.\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages**\n",
    "Load synthetic stratigraphy and correlation analysis functions from **pyCoreRelator**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    load_segment_pool,\n",
    "    modify_segment_pool,\n",
    "    plot_segment_pool,\n",
    "    create_synthetic_log,\n",
    "    plot_synthetic_log,\n",
    "    run_comprehensive_dtw_analysis,\n",
    "    find_complete_core_paths,\n",
    "    plot_correlation_distribution,\n",
    "    synthetic_correlation_quality,\n",
    "    plot_synthetic_correlation_quality\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Build Segment Pool from Real Cores**\n",
    "\n",
    "Configure the cores and data sources to create a pool of stratigraphic segments for synthetic generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Segment Pool from Multiple Cores\n",
    "\n",
    "**Function: `load_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Extracts stratigraphic segments from multiple cores to create a reusable pool for synthetic core generation.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `core_names` *(list)*: List of core identifiers\n",
    "- `core_log_paths` *(dict)*: Nested dictionary mapping core names to log file paths\n",
    "- `picked_depth_paths` *(dict)*: Dictionary mapping core names to picked datum CSV files\n",
    "- `log_column_names` *(list)*: List of log column names to extract\n",
    "- `depth_column` *(str, default='SB_DEPTH_cm')*: Name of the depth column\n",
    "- `alternative_column_names` *(dict, default=None)*: Dictionary of alternative column names\n",
    "- `boundary_category` *(int, default=1)*: Category filter for segment boundaries\n",
    "- `neglect_topbottom` *(bool, default=True)*: Exclude top/bottom boundary segments\n",
    "\n",
    "**Returns:**\n",
    "- `segment_logs` (list): List of log arrays for each segment\n",
    "- `segment_depths` (list): List of depth arrays for each segment\n",
    "- `segment_info` (list): List of dictionaries with segment metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG_COLUMNS = ['hiresMS']  # Single log option\n",
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Multiple logs for correlation\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_POOL_CORES = [\n",
    "    \"M9907-11PC\", \"M9907-23PC\", \"M9907-25PC\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_LOG_PATHS = {\n",
    "    core_name: {\n",
    "        'hiresMS': f'example_data/processed_data/{core_name}/{core_name}_hiresMS_MLfilled.csv',\n",
    "        'CT': f'example_data/processed_data/{core_name}/{core_name}_CT_MLfilled.csv',\n",
    "        'Lumin': f'example_data/processed_data/{core_name}/{core_name}_RGB_MLfilled.csv'\n",
    "    }\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}\n",
    "\n",
    "COLUMN_ALTERNATIVES = {\n",
    "    'hiresMS': ['MS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'Lumin': ['luminance', 'Luminance']\n",
    "}\n",
    "\n",
    "PICKED_DEPTH_PATHS = {\n",
    "    core_name: f'example_data/picked_datum/{core_name}_pickeddepth.csv'\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_logs, seg_depths, _ = load_segment_pool(\n",
    "    core_names=SEGMENT_POOL_CORES,\n",
    "    core_log_paths=CORE_LOG_PATHS,\n",
    "    picked_depth_paths=PICKED_DEPTH_PATHS,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    alternative_column_names=COLUMN_ALTERNATIVES,\n",
    "    boundary_category=1,\n",
    "    neglect_topbottom=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Segment Pool\n",
    "\n",
    "**Function: `plot_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Creates a visualization of all segments in the pool, displaying log traces for quality inspection.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `segment_logs` *(list)*: List of log arrays from `load_segment_pool()`\n",
    "- `segment_depths` *(list)*: List of depth arrays from `load_segment_pool()`\n",
    "- `log_column_names` *(list)*: List of log names to plot\n",
    "- `n_cols` *(int, default=10)*: Number of columns in the plot grid\n",
    "- `figsize_per_row` *(float, default=3)*: Figure height per row\n",
    "- `plot_segments` *(bool, default=True)*: Whether to display the plot\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename for saved plot\n",
    "\n",
    "**Returns:**\n",
    "- `fig` (matplotlib.figure.Figure): Figure object\n",
    "- `axes` (numpy.ndarray): Array of axes objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_segment_pool(\n",
    "    segment_logs=seg_logs,\n",
    "    segment_depths=seg_depths,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    n_cols=10,\n",
    "    figsize_per_row=3,\n",
    "    plot_segments=True,\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Segment Pool (Optional)\n",
    "\n",
    "**Function: `modify_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Removes unwanted segments from the pool based on quality or suitability criteria.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `segment_logs` *(list)*: List of log arrays\n",
    "- `segment_depths` *(list)*: List of depth arrays\n",
    "- `remove_list` *(list)*: List of segment indices to remove\n",
    "\n",
    "**Returns:**\n",
    "- `modified_segment_logs` (list): Filtered log arrays\n",
    "- `modified_segment_depths` (list): Filtered depth arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_segs = [18, 19, 20, 21, 22, 23, 24, 25, 26, 50, 51]\n",
    "\n",
    "mod_seg_logs, mod_seg_depths = modify_segment_pool(seg_logs, seg_depths, remove_list=exclude_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = plot_segment_pool(\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    n_cols=10,\n",
    "    figsize_per_row=3,\n",
    "    plot_segments=True,\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Generate Synthetic Core Pair**\n",
    "\n",
    "Create synthetic stratigraphic sequences by randomly selecting segments from the pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Core A\n",
    "\n",
    "**Function: `create_synthetic_log()`**\n",
    "\n",
    "**What it does:**\n",
    "Generates a synthetic core log by randomly selecting and stacking segments from the pool to reach a target thickness.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `target_thickness` *(float)*: Desired total thickness in cm\n",
    "- `segment_logs` *(list)*: List of available segment log arrays\n",
    "- `segment_depths` *(list)*: List of available segment depth arrays\n",
    "- `repetition` *(bool, default=False)*: Allow re-selecting the same segment\n",
    "\n",
    "**Returns:**\n",
    "- `synthetic_log` (numpy.ndarray): Combined log array\n",
    "- `synthetic_md` (numpy.ndarray): Measured depth array\n",
    "- `synthetic_picked_datum` (list): List of boundary depths with categories\n",
    "- `selected_indices` (list): Indices of segments used from the pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_log_a, syn_md_a, syn_depth_a, inds_a = create_synthetic_log(\n",
    "    target_thickness=400,\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths,\n",
    "    repetition=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_log(\n",
    "    synthetic_log=syn_log_a,\n",
    "    synthetic_md=syn_md_a,\n",
    "    synthetic_picked_datum=syn_depth_a,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    title=f'Synthetic Core A\\n({len(inds_a)} layers)',\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Core B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_log_b, syn_md_b, syn_depth_b, inds_b = create_synthetic_log(\n",
    "    target_thickness=400,\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths,\n",
    "    repetition=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `plot_synthetic_log()`**\n",
    "\n",
    "**What it does:**\n",
    "Visualizes the generated synthetic core log with picked datum boundaries.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `synthetic_log` *(numpy.ndarray)*: Synthetic log array from `create_synthetic_log()`\n",
    "- `synthetic_md` *(numpy.ndarray)*: Synthetic measured depth array\n",
    "- `synthetic_picked_datum` *(list)*: List of picked datum depths with categories\n",
    "- `log_column_names` *(list)*: List of log names to plot\n",
    "- `title` *(str, default=None)*: Plot title\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename for saved plot\n",
    "\n",
    "**Returns:**\n",
    "None (displays and optionally saves plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_log(\n",
    "    synthetic_log=syn_log_b,\n",
    "    synthetic_md=syn_md_b,\n",
    "    synthetic_picked_datum=syn_depth_b,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    title=f'Synthetic Core B\\n({len(inds_b)} layers)',\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Analyze Single Synthetic Core Pair**\n",
    "\n",
    "Perform DTW correlation analysis on one synthetic pair to examine the distribution of correlation solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DTW Analysis on Synthetic Pair\n",
    "**Function: `run_comprehensive_dtw_analysis()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Creates segments between picked datum boundaries\n",
    "2. Identifies valid segment pairs based on depth constraints\n",
    "3. Performs DTW analysis on each valid segment pair\n",
    "4. Calculates DTW distances and quality metrics\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_a` *(array)*: Synthetic Core A log data\n",
    "- `log_b` *(array)*: Synthetic Core B log data\n",
    "- `md_a` *(array)*: Synthetic Core A measured depths\n",
    "- `md_b` *(array)*: Synthetic Core B measured depths\n",
    "- `picked_datum_a` *(list)*: Picked datum depths for Core A\n",
    "- `picked_datum_b` *(list)*: Picked datum depths for Core B\n",
    "- `independent_dtw` *(bool, default=False)*: Use independent DTW for each log dimension\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent multidimensional DTW\n",
    "- `top_bottom` *(bool, default=False)*: Include top and bottom boundaries\n",
    "- `mute_mode` *(bool, default=False)*: Suppress print output\n",
    "\n",
    "**Returns:**\n",
    "- `dtw_result` (dict): Dictionary containing DTW analysis results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_depth_a_values = [depth for depth, category in syn_depth_a]\n",
    "syn_depth_b_values = [depth for depth, category in syn_depth_b]\n",
    "\n",
    "dtw_result = run_comprehensive_dtw_analysis(\n",
    "    syn_log_a, syn_log_b, syn_md_a, syn_md_b,\n",
    "    picked_datum_a=syn_depth_a_values,\n",
    "    picked_datum_b=syn_depth_b_values,\n",
    "    independent_dtw=False,\n",
    "    pca_for_dependent_dtw=False,\n",
    "    top_bottom=False,\n",
    "    mute_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `find_complete_core_paths()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Searches through all valid segment pairs to find complete correlation paths\n",
    "2. Calculates quality metrics for each complete path\n",
    "3. Uses shortest path algorithms to optimize search\n",
    "4. Exports all valid mappings to CSV file\n",
    "\n",
    "**Key Parameters:**\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`\n",
    "- `log_a` *(array)*: Core A log data for metric computation\n",
    "- `log_b` *(array)*: Core B log data for metric computation\n",
    "- `output_csv` *(str)*: Output CSV filename for mappings\n",
    "- `output_metric_only` *(bool, default=False)*: If True, only output quality metrics without full path details\n",
    "- `shortest_path_search` *(bool, default=True)*: Keep only shortest path lengths during search\n",
    "- `shortest_path_level` *(int, default=2)*: Number of shortest unique lengths to keep\n",
    "- `max_search_path` *(int, default=5000)*: Maximum paths per segment pair to prevent memory overflow\n",
    "- `mute_mode` *(bool, default=False)*: Suppress print output\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent DTW quality calculations\n",
    "\n",
    "**Returns:**\n",
    "- `complete_paths` (list): All complete correlation paths with quality metrics\n",
    "- `num_paths` (int): Total number of complete paths found\n",
    "- `csv_file` (str): Path to output CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = find_complete_core_paths(\n",
    "    dtw_result,\n",
    "    syn_log_a, \n",
    "    syn_log_b,\n",
    "    output_csv=f\"example_data/analytical_outputs/temp_synthetic_{'_'.join(LOG_COLUMNS)}_core_pair_metrics.csv\",\n",
    "    output_metric_only=True,\n",
    "    shortest_path_search=True,\n",
    "    shortest_path_level=2,\n",
    "    max_search_path=5000,\n",
    "    mute_mode=False,\n",
    "    pca_for_dependent_dtw=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality Metric Distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `plot_correlation_distribution()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads all mappings from CSV file\n",
    "2. Extracts quality metrics for analysis\n",
    "3. Plots histogram and probability distribution\n",
    "4. Saves distribution plot as PNG\n",
    "\n",
    "**Key Parameters:**\n",
    "- `mapping_csv` *(str)*: Path to mappings CSV file from `find_complete_core_paths()`\n",
    "- `quality_index` *(str)*: Quality metric to plot - **required**. Options: 'corr_coef', 'norm_dtw', 'dtw_ratio', 'variance_deviation', 'perc_diag', 'match_min', 'match_mean'\n",
    "- `save_png` *(bool, default=True)*: Whether to save plot as PNG\n",
    "- `pdf_method` *(str, default='normal')*: PDF fitting method ('KDE', 'skew-normal', or 'normal')\n",
    "- `kde_bandwidth` *(float, default=0.05)*: Bandwidth for KDE when pdf_method='KDE'\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress print statements\n",
    "\n",
    "**Returns:**\n",
    "- `fig` (matplotlib.figure.Figure): Figure object\n",
    "- `ax` (matplotlib.axes.Axes): Axes object\n",
    "- `distribution_params` (dict): Distribution parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='corr_coef',\n",
    "    save_png=False,\n",
    "    pdf_method='normal',\n",
    "    kde_bandwidth=0.05,\n",
    "    mute_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='norm_dtw',\n",
    "    save_png=False,\n",
    "    pdf_method='normal',\n",
    "    kde_bandwidth=0.05,\n",
    "    mute_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv'):\n",
    "    os.remove(f\"example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Run Multiple Synthetic Iterations**\n",
    "\n",
    "Generate and analyze many synthetic core pairs to establish null hypothesis distributions for correlation quality metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Iterative Synthetic Analysis\n",
    "\n",
    "**Function: `synthetic_correlation_quality()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Generates multiple synthetic core pairs from the segment pool\n",
    "2. Runs DTW analysis on each pair\n",
    "3. Collects quality metrics from all correlation solutions\n",
    "4. Exports probability distributions for each quality metric to CSV\n",
    "\n",
    "**Key Parameters:**\n",
    "- `mod_seg_logs` *(list)*: Modified segment log arrays\n",
    "- `mod_seg_depths` *(list)*: Modified segment depth arrays\n",
    "- `log_column_names` *(list)*: List of log names to analyze\n",
    "- `quality_indices` *(list)*: Quality metrics to compute (e.g., ['corr_coef', 'norm_dtw'])\n",
    "- `number_of_iterations` *(int)*: Number of synthetic pairs to generate\n",
    "- `core_a_length` *(float)*: Target thickness for synthetic Core A\n",
    "- `core_b_length` *(float)*: Target thickness for synthetic Core B\n",
    "- `repetition` *(bool, default=False)*: Allow segment reuse within a core\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for multidimensional DTW\n",
    "- `output_csv_dir` *(str, default=None)*: Directory for output CSV files\n",
    "- `max_search_path` *(int, default=5000)*: Maximum paths to search per segment pair\n",
    "- `mute_mode` *(bool, default=False)*: Suppress console output\n",
    "\n",
    "**Returns:**\n",
    "None (outputs CSV files for each quality index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_correlation_quality(\n",
    "    mod_seg_logs=mod_seg_logs,\n",
    "    mod_seg_depths=mod_seg_depths,\n",
    "    log_column_names=LOG_COLUMNS,\n",
    "    quality_indices=['corr_coef', 'norm_dtw'],\n",
    "    number_of_iterations=50,\n",
    "    core_a_length=400,\n",
    "    core_b_length=400,\n",
    "    repetition=False,\n",
    "    pca_for_dependent_dtw=False,\n",
    "    output_csv_dir='example_data/analytical_outputs',\n",
    "    max_search_path=5000,\n",
    "    mute_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Visualize Synthetic Correlation Results**\n",
    "\n",
    "Plot the probability distributions from multiple iterations to establish baseline correlation quality expectations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Individual Iteration PDFs\n",
    "\n",
    "**Function: `plot_synthetic_correlation_quality()`**\n",
    "\n",
    "**What it does:**\n",
    "Visualizes the probability distribution functions (PDFs) from synthetic correlation analysis, either as individual iteration curves or as a combined distribution.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `input_csv` *(str)*: Path to CSV file with `{quality_index}` placeholder\n",
    "- `quality_indices` *(list)*: Quality metrics to plot\n",
    "- `bin_width` *(float, default=None)*: Histogram bin width (auto if None)\n",
    "- `plot_individual_pdf` *(bool, default=True)*: True shows individual PDFs, False shows combined\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename with `{quality_index}` placeholder\n",
    "\n",
    "**Returns:**\n",
    "None (displays and optionally saves plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_data/analytical_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices,\n",
    "    bin_width=None,\n",
    "    plot_individual_pdf=True,\n",
    "    save_plot=True,\n",
    "    plot_filename=f'example_data/analytical_outputs/every_synthetic_iterations_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Combined Distribution from All Iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_data/analytical_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices,\n",
    "    bin_width=None,\n",
    "    plot_individual_pdf=False,\n",
    "    save_plot=True,\n",
    "    plot_filename=f'example_data/analytical_outputs/combined_synthetic_distribution_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
