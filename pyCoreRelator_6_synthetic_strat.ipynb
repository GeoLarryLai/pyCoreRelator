{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Required Packages\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Extract Core Lengths and Load Segment Pool\n",
    "from pyCoreRelator import load_segment_pool\n",
    "\n",
    "# Define directory paths\n",
    "mother_dir = '/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites'\n",
    "\n",
    "# Function to extract core length from depth data\n",
    "def get_core_length(core_name, depth_column='SB_DEPTH_cm', log_column=None):\n",
    "    \"\"\"Extract maximum depth from core data\"\"\"\n",
    "    # Try hiresMS file first (most common)\n",
    "    depth_file = f'{mother_dir}/Cascadia_core_data/OSU_dataset/_compiled_logs/{core_name}/ML_filled/{core_name}_{log_column}_MLfilled.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(depth_file)\n",
    "        return df[depth_column].max()\n",
    "    except:\n",
    "        print(f\"Warning: Could not read depth from {depth_file}\")\n",
    "        return None\n",
    "\n",
    "#####\n",
    "\n",
    "# LOG_COLUMNS = ['hiresMS']  # Choose one log column for segment pool\n",
    "# LOG_COLUMNS = ['CT']\n",
    "# LOG_COLUMNS = ['Lumin']\n",
    "# LOG_COLUMNS = ['hiresMS', 'CT']\n",
    "# LOG_COLUMNS = ['hiresMS', 'Lumin']\n",
    "# LOG_COLUMNS = ['CT', 'Lumin']\n",
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']\n",
    "\n",
    "\n",
    "# Define core names and target parameters\n",
    "DEPTH_COLUMN = 'SB_DEPTH_cm'\n",
    "\n",
    "###\n",
    "# For multidimensional DTW, choose DTW method:\n",
    "pca_for_dependent_dtw=False \n",
    "\n",
    "# Define all cores for segment pool\n",
    "SEGMENT_POOL_CORES = [\n",
    "    \"M9907-11PC\", \"M9907-23PC\", \"M9907-25PC\"\n",
    "]\n",
    "\n",
    "# Define paths and parameters for multiple log types\n",
    "CORE_LOG_PATHS = {\n",
    "    core_name: {\n",
    "        'hiresMS': f'{mother_dir}/Cascadia_core_data/OSU_dataset/_compiled_logs/{core_name}/ML_filled/{core_name}_hiresMS_MLfilled.csv',\n",
    "        'CT': f'{mother_dir}/Cascadia_core_data/OSU_dataset/_compiled_logs/{core_name}/ML_filled/{core_name}_CT_MLfilled.csv',\n",
    "        'Lumin': f'{mother_dir}/Cascadia_core_data/OSU_dataset/_compiled_logs/{core_name}/ML_filled/{core_name}_RGB_MLfilled.csv',\n",
    "    }\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}\n",
    "\n",
    "COLUMN_ALTERNATIVES = {\n",
    "    'hiresMS': ['MS'],\n",
    "    'CT': ['CT_value'],\n",
    "    'Lumin': ['luminance', 'Luminance']\n",
    "}\n",
    "\n",
    "PICKED_DEPTH_PATHS = {\n",
    "    core_name: f'{mother_dir}/pyCoreRelator/pickeddepth/{core_name}_pickeddepth.csv'\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}\n",
    "\n",
    "# Execute the function using the imported function from pyCoreRelator\n",
    "seg_logs, seg_depths, _ = load_segment_pool(\n",
    "    core_names = SEGMENT_POOL_CORES,\n",
    "    core_log_paths = CORE_LOG_PATHS,\n",
    "    picked_depth_paths = PICKED_DEPTH_PATHS,\n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    depth_column=DEPTH_COLUMN,\n",
    "    alternative_column_names = COLUMN_ALTERNATIVES,\n",
    "    boundary_category=1,\n",
    "    neglect_topbottom=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Plot All Turbidite Segments from Pool\n",
    "from pyCoreRelator import plot_segment_pool\n",
    "\n",
    "# Plot the segment pool using imported function\n",
    "_, _ = plot_segment_pool(\n",
    "    segment_logs = seg_logs,\n",
    "    segment_depths = seg_depths,\n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    n_cols=10,\n",
    "    figsize_per_row=3,\n",
    "    plot_segments=True,\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.5: Remove unwanted segments from Pool\n",
    "from pyCoreRelator import modify_segment_pool\n",
    "\n",
    "# Define the segment numbers to be excluded\n",
    "exclude_segs = [18, 19, 20, 21, 22, 23, 24, 25, 26, 50, 51]\n",
    "\n",
    "# Remove segments from the pool\n",
    "mod_seg_logs, mod_seg_depths = modify_segment_pool(seg_logs, seg_depths, remove_list=exclude_segs)\n",
    "\n",
    "# Plot the modified segment pool\n",
    "_, _ = plot_segment_pool(\n",
    "    segment_logs = mod_seg_logs,\n",
    "    segment_depths = mod_seg_depths,\n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    n_cols=10,\n",
    "    figsize_per_row=3,\n",
    "    plot_segments=True,\n",
    "    save_plot=False,\n",
    "    plot_filename=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create and Plot Synthetic Core Pair\n",
    "from pyCoreRelator import create_synthetic_log, plot_synthetic_log\n",
    "\n",
    "# Generate & plot synthetic core A\n",
    "syn_log_a, syn_md_a, syn_pickeddepth_a, inds_a = create_synthetic_log(\n",
    "    target_thickness = 300,\n",
    "    segment_logs = mod_seg_logs,\n",
    "    segment_depths = mod_seg_depths,\n",
    "    exclude_inds = None,\n",
    "    repetition = False         # If True: allow reselecting the same layer from the pool\n",
    ")\n",
    "\n",
    "syn_depth_a = [depth[0] for depth in syn_pickeddepth_a] # Extract only depth arraynly for plotting\n",
    "\n",
    "plot_synthetic_log(\n",
    "    synthetic_log = syn_log_a,\n",
    "    synthetic_md = syn_md_a,\n",
    "    synthetic_picked_depths = syn_depth_a,    \n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    title = f'Synthetic Core A\\n({len(inds_a)} layers)',\n",
    "    save_plot = False,\n",
    "    plot_filename = None\n",
    ")\n",
    "\n",
    "# Generate & plot synthetic core B\n",
    "syn_log_b, syn_md_b, syn_pickeddepth_b, inds_b = create_synthetic_log(\n",
    "    target_thickness = 300,\n",
    "    segment_logs = mod_seg_logs,\n",
    "    segment_depths = mod_seg_depths,\n",
    "    exclude_inds = None,\n",
    "    repetition = False          # If True: allow reselecting the same layer from the pool\n",
    ")\n",
    "\n",
    "syn_depth_b = [depth[0] for depth in syn_pickeddepth_b] # Extract only depth arraynly for plotting\n",
    "\n",
    "plot_synthetic_log(\n",
    "    synthetic_log = syn_log_b,\n",
    "    synthetic_md = syn_md_b,\n",
    "    synthetic_picked_depths = syn_depth_b,    \n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    title = f'Synthetic Core B\\n({len(inds_b)} layers)',\n",
    "    save_plot = False,\n",
    "    plot_filename = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: DTW Analysis on Synthetic Pair\n",
    "from pyCoreRelator import run_comprehensive_dtw_analysis, find_complete_core_paths\n",
    "\n",
    "# Run DTW analysis\n",
    "dtw_results, valid_dtw_pairs, segments_a, segments_b, _, _, dtw_distance_matrix_full = run_comprehensive_dtw_analysis(\n",
    "    syn_log_a, syn_log_b, syn_md_a, syn_md_b,\n",
    "    picked_depths_a = syn_depth_a,\n",
    "    picked_depths_b = syn_depth_b,\n",
    "    independent_dtw = False,\n",
    "    pca_for_dependent_dtw = pca_for_dependent_dtw,\n",
    "    top_bottom = False,\n",
    "    mute_mode = False\n",
    ")\n",
    "\n",
    "# Find complete core paths and extract r-values\n",
    "_ = find_complete_core_paths(\n",
    "    valid_dtw_pairs,\n",
    "    segments_a, \n",
    "    segments_b, \n",
    "    syn_log_a, \n",
    "    syn_log_b,\n",
    "    syn_depth_a, \n",
    "    syn_depth_b,\n",
    "    dtw_results,\n",
    "    dtw_distance_matrix_full,\n",
    "    output_csv=f\"example_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv\",\n",
    "    output_metric_only=True,\n",
    "    shortest_path_search=True,\n",
    "    shortest_path_level=2,\n",
    "    max_search_path=100000,\n",
    "    mute_mode=False,\n",
    "    pca_for_dependent_dtw=pca_for_dependent_dtw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plot R-Values Distribution from Synthetic Pair\n",
    "from pyCoreRelator import plot_correlation_distribution\n",
    "\n",
    "# Plot correlation distribution\n",
    "_, _, _ = plot_correlation_distribution(\n",
    "    csv_file=f'example_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='corr_coef',   # available metrics: corr_coef, norm_dtw, dtw_ratio, perc_diag, dtw_warp_eff, perc_age_overlap\n",
    "    save_png=False,\n",
    "    pdf_method='normal',         # 'KDE', 'skew-normal', 'normal'\n",
    "    kde_bandwidth=0.05,\n",
    "    mute_mode=False\n",
    ")\n",
    "\n",
    "# Plot correlation distribution\n",
    "_, _, _ = plot_correlation_distribution(\n",
    "    csv_file=f'example_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='norm_dtw',   # available metrics: corr_coef, norm_dtw, dtw_ratio, perc_diag, dtw_warp_eff, perc_age_overlap\n",
    "    save_png=False,\n",
    "    pdf_method='normal',         # 'KDE', 'skew-normal', 'normal'\n",
    "    kde_bandwidth=0.05,\n",
    "    mute_mode=False\n",
    ")\n",
    "\n",
    "# Remove temporary CSV file after loop is complete\n",
    "if os.path.exists(f'example_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv'):\n",
    "    os.remove(f\"example_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Run Multiple Iterations for Synthetic Logs R-Value Findings\n",
    "from pyCoreRelator import synthetic_correlation_quality\n",
    "\n",
    "# Run synthetic correlation quality analysis\n",
    "synthetic_correlation_quality(\n",
    "    mod_seg_logs = mod_seg_logs,\n",
    "    mod_seg_depths = mod_seg_depths,\n",
    "    log_column_names = LOG_COLUMNS,\n",
    "    quality_indices = ['corr_coef','norm_dtw'], # Define quality indices to iterate through (norm_dtw, dtw_ratio, perc_diag, corr_coef, dtw_warp_eff, perc_age_overlap)\n",
    "    number_of_iterations = 100,                 # Number of iterations to run\n",
    "    core_a_length=600,\n",
    "    core_b_length=600,\n",
    "    repetition=False,                           # True: allow reselecting turbidite segments; False: each segment can only be selected once\n",
    "    pca_for_dependent_dtw=pca_for_dependent_dtw,\n",
    "    output_csv_dir =f'example_outputs',         # Directory for the output CSV files (optional)\n",
    "    mute_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Plot all distribution curves for each quality index\n",
    "from pyCoreRelator import plot_synthetic_correlation_quality\n",
    "\n",
    "# Define quality indices to plot\n",
    "# quality_indices = ['corr_coef', 'norm_dtw', 'dtw_ratio', 'perc_diag', 'dtw_warp_eff', 'perc_age_overlap']\n",
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "# Plot individual PDF curves from each iteration\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices,\n",
    "    bin_width=None,                # If not specified, corr_coef=0.025, norm_dtw=0.0025\n",
    "    plot_individual_pdf=True,      # True: overlay individual PDFs; False: combined distribution\n",
    "    save_plot=True,\n",
    "    plot_filename= f'example_outputs/every_synthetic_iterations_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.png'  # Uncomment to save with save_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Combine all binned data and recalculate distribution for each quality index\n",
    "from pyCoreRelator import plot_synthetic_correlation_quality\n",
    "\n",
    "# Define quality indices to iterate through (matching Cell 8)\n",
    "# quality_indices = ['corr_coef', 'norm_dtw', 'dtw_ratio', 'perc_diag', 'dtw_warp_eff', 'perc_age_overlap']\n",
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "# Plot combined distribution across all iterations\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices,\n",
    "    bin_width=None,                   # If not specified, corr_coef=0.025, norm_dtw=0.0025\n",
    "    plot_individual_pdf=False,        # False: combined distribution; True: overlay individual PDFs\n",
    "    save_plot=True,\n",
    "    plot_filename=f'example_outputs/combined_synthetic_distribution_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.png' # Uncomment to save with save_plot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
