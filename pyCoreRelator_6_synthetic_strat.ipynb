{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pyCoreRelator** [![GitHub](https://img.shields.io/badge/GitHub-pyCoreRelator-blue?logo=github)](https://github.com/GeoLarryLai/pyCoreRelator) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.xxxxxxxx.svg)](https://doi.org/10.5281/zenodo.xxxxxxxx)\n",
    "## **Workshop Notebook #6: Synthetic Stratigraphy Analysis**   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GeoLarryLai/pyCoreRelator/blob/main/pyCoreRelator_6_synthetic_strat.ipynb)\n",
    "This notebook demonstrates the workflow for generating synthetic stratigraphic sequences and analyzing correlation quality distributions using **pyCoreRelator**.\n",
    "\n",
    "### Key Functions from **pyCoreRelator**\n",
    "- **`load_segment_pool()`**: Load and organize turbidite segments from multiple cores\n",
    "- **`modify_segment_pool()`**: Remove or modify segments in the pool\n",
    "- **`plot_segment_pool()`**: Visualize all segments in the pool\n",
    "- **`create_synthetic_log()`**: Generate synthetic core logs from segment pool\n",
    "- **`plot_synthetic_log()`**: Visualize synthetic core logs\n",
    "- **`run_comprehensive_dtw_analysis()`**: Perform DTW analysis on synthetic pairs\n",
    "- **`find_complete_core_paths()`**: Search for complete correlation paths\n",
    "- **`plot_correlation_distribution()`**: Plot quality metric distributions\n",
    "- **`synthetic_correlation_quality()`**: Run multiple synthetic iterations\n",
    "- **`plot_synthetic_correlation_quality()`**: Visualize synthetic correlation results\n",
    "\n",
    "For advanced usage, see [FUNCTION_DOCUMENTATION.md](https://github.com/GeoLarryLai/pyCoreRelator/blob/main/FUNCTION_DOCUMENTATION.md) for more details.\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check Installation**\n",
    "Check if **pyCoreRelator** is installed and install if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pycorerelator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages**\n",
    "Load synthetic stratigraphy and correlation analysis functions from **pyCoreRelator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyCoreRelator import (\n",
    "    load_segment_pool,\n",
    "    modify_segment_pool,\n",
    "    plot_segment_pool,\n",
    "    create_synthetic_log,\n",
    "    plot_synthetic_log,\n",
    "    run_comprehensive_dtw_analysis,\n",
    "    find_complete_core_paths,\n",
    "    plot_correlation_distribution,\n",
    "    synthetic_correlation_quality,\n",
    "    plot_synthetic_correlation_quality\n",
    ")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Build Segment Pool from Real Cores**\n",
    "\n",
    "Configure the cores and data sources to create a pool of stratigraphic segments for synthetic generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG_COLUMNS = ['hiresMS']  # Single log option\n",
    "LOG_COLUMNS = ['hiresMS', 'CT', 'Lumin']  # Multiple logs for correlation\n",
    "\n",
    "SEGMENT_POOL_CORES = [\"M9907-11PC\", \"M9907-23PC\", \"M9907-25PC\"]\n",
    "\n",
    "CORE_LOG_PATHS = {\n",
    "    core_name: {\n",
    "        'hiresMS': f'example_data/processed_data/{core_name}/{core_name}_hiresMS_MLfilled.csv',\n",
    "        'CT': f'example_data/processed_data/{core_name}/{core_name}_CT_MLfilled.csv',\n",
    "        'Lumin': f'example_data/processed_data/{core_name}/{core_name}_RGB_MLfilled.csv'\n",
    "    }\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}\n",
    "\n",
    "PICKED_DEPTH_PATHS = {\n",
    "    core_name: f'example_data/picked_datum/{core_name}_pickeddepth.csv'\n",
    "    for core_name in SEGMENT_POOL_CORES\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check and Download Example Data**\n",
    "Download necessary example data if not already present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "print(\"Checking for example data...\")\n",
    "if not all(os.path.exists(f\"example_data/processed_data/{c}/{c}_hiresMS_MLfilled.csv\") for c in SEGMENT_POOL_CORES):\n",
    "    print(\"Downloading...\")\n",
    "    for core in SEGMENT_POOL_CORES:\n",
    "        os.makedirs(f\"example_data/processed_data/{core}\", exist_ok=True)\n",
    "        os.makedirs(\"example_data/picked_datum\", exist_ok=True)\n",
    "        for path in [f\"processed_data/{core}/{core}_hiresMS_MLfilled.csv\", f\"processed_data/{core}/{core}_CT_MLfilled.csv\",\n",
    "                     f\"processed_data/{core}/{core}_RGB_MLfilled.csv\", f\"picked_datum/{core}_pickeddepth.csv\"]:\n",
    "            try:\n",
    "                with open(f\"example_data/{path}\", \"wb\") as f:\n",
    "                    f.write(requests.get(f\"https://github.com/GeoLarryLai/pyCoreRelator/raw/main/example_data/{path}\").content)\n",
    "            except: pass\n",
    "    print(\"Download complete\")\n",
    "else:\n",
    "    print(\"âœ“ Data already exists\")\n",
    "print(\"Ready to proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Segment Pool from Multiple Cores\n",
    "\n",
    "**Function: `load_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Extracts stratigraphic segments from multiple cores to create a reusable pool for synthetic core generation.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `core_names` *(list)*: List of core identifiers\n",
    "- `log_data_csv` *(dict)*: Nested dictionary mapping core names to log file paths\n",
    "- `log_data_type` *(list)*: List of log column names to extract\n",
    "- `picked_datum` *(dict)*: Dictionary mapping core names to picked datum CSV files\n",
    "- `depth_column` *(str, default='SB_DEPTH_cm')*: Name of the depth column\n",
    "- `alternative_column_names` *(dict, default=None)*: Optional dictionary of alternative column names (e.g., {'hiresMS': ['MS'], 'CT': ['CT_value'], 'Lumin': ['luminance', 'Luminance']})\n",
    "- `boundary_category` *(int, default=None)*: Category filter for segment boundaries. If None, uses category 1 if available, otherwise uses the lowest available category\n",
    "- `neglect_topbottom` *(bool, default=True)*: Exclude top/bottom boundary segments\n",
    "\n",
    "**Returns:**\n",
    "- `segment_logs` (list): List of log arrays for each segment\n",
    "- `segment_depths` (list): List of depth arrays for each segment\n",
    "- `segment_info` (list): List of dictionaries with segment metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_logs, seg_depths, _ = load_segment_pool(\n",
    "    core_names=SEGMENT_POOL_CORES,\n",
    "    log_data_csv=CORE_LOG_PATHS,\n",
    "    log_data_type=LOG_COLUMNS,\n",
    "    picked_datum=PICKED_DEPTH_PATHS,\n",
    "    depth_column='SB_DEPTH_cm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Segment Pool\n",
    "\n",
    "**Function: `plot_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Creates a visualization of all segments in the pool, displaying log traces for quality inspection.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `segment_logs` *(list)*: List of log arrays from `load_segment_pool()`\n",
    "- `segment_depths` *(list)*: List of depth arrays from `load_segment_pool()`\n",
    "- `log_data_type` *(list)*: List of log names to plot\n",
    "- `n_cols` *(int, default=10)*: Number of columns in the plot grid\n",
    "- `figsize_per_row` *(float, default=3)*: Figure height per row\n",
    "- `plot_segments` *(bool, default=True)*: Whether to display the plot\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename for saved plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segment_pool(\n",
    "    segment_logs=seg_logs,\n",
    "    segment_depths=seg_depths,\n",
    "    log_data_type=LOG_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Segment Pool (Optional)\n",
    "\n",
    "**Function: `modify_segment_pool()`**\n",
    "\n",
    "**What it does:**\n",
    "Removes unwanted segments from the pool based on quality or suitability criteria.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `segment_logs` *(list)*: List of log arrays\n",
    "- `segment_depths` *(list)*: List of depth arrays\n",
    "- `remove_list` *(list)*: List of segment indices to remove\n",
    "\n",
    "**Returns:**\n",
    "- `modified_segment_logs` (list): Filtered log arrays\n",
    "- `modified_segment_depths` (list): Filtered depth arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_segs = [18, 19, 20, 21, 22, 23, 24, 25, 26, 50, 51]\n",
    "\n",
    "mod_seg_logs, mod_seg_depths = modify_segment_pool(seg_logs, seg_depths, remove_list=exclude_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segment_pool(\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths,\n",
    "    log_data_type=LOG_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Generate Synthetic Core Pair**\n",
    "\n",
    "Create synthetic stratigraphic sequences by randomly selecting segments from the pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Synthetic Core A\n",
    "\n",
    "**Function: `create_synthetic_log()`**\n",
    "\n",
    "**What it does:**\n",
    "Generates a synthetic core log by randomly selecting and stacking segments from the pool to reach a target thickness.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `target_thickness` *(float)*: Desired total thickness in cm\n",
    "- `segment_logs` *(list)*: List of available segment log arrays\n",
    "- `segment_depths` *(list)*: List of available segment depth arrays\n",
    "- `repetition` *(bool, default=False)*: Allow re-selecting the same segment\n",
    "\n",
    "**Returns:**\n",
    "- `synthetic_log` (numpy.ndarray): Combined log array\n",
    "- `synthetic_md` (numpy.ndarray): Measured depth array\n",
    "- `synthetic_picked_datum` (list): List of boundary depth values\n",
    "- `selected_indices` (list): Indices of segments used from the pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_log_a, syn_md_a, syn_depth_a, _ = create_synthetic_log(\n",
    "    target_thickness=400,\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `plot_synthetic_log()`**\n",
    "\n",
    "**What it does:**\n",
    "Visualizes the generated synthetic core log with picked datum boundaries.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `synthetic_log` *(numpy.ndarray)*: Synthetic log array from `create_synthetic_log()`\n",
    "- `synthetic_md` *(numpy.ndarray)*: Synthetic measured depth array\n",
    "- `synthetic_picked_datum` *(list)*: List of picked datum depth values\n",
    "- `log_data_type` *(list)*: List of log names to plot\n",
    "- `title` *(str, default=None)*: Plot title (optional)\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename for saved plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_log(\n",
    "    synthetic_log=syn_log_a,\n",
    "    synthetic_md=syn_md_a,\n",
    "    synthetic_picked_datum=syn_depth_a,\n",
    "    log_data_type=LOG_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Synthetic Core B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_log_b, syn_md_b, syn_depth_b, _ = create_synthetic_log(\n",
    "    target_thickness=400,\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_log(\n",
    "    synthetic_log=syn_log_b,\n",
    "    synthetic_md=syn_md_b,\n",
    "    synthetic_picked_datum=syn_depth_b,\n",
    "    log_data_type=LOG_COLUMNS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Analyze Single Synthetic Core Pair**\n",
    "\n",
    "Perform DTW correlation analysis on one synthetic pair to examine the distribution of correlation solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DTW Analysis on Synthetic Pair\n",
    "**Function: `run_comprehensive_dtw_analysis()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Creates segments between picked datum boundaries\n",
    "2. Identifies valid segment pairs based on depth constraints\n",
    "3. Performs DTW analysis on each valid segment pair\n",
    "4. Calculates DTW distances and quality metrics\n",
    "\n",
    "**Key Parameters:**\n",
    "- `log_a` *(array)*: Synthetic Core A log data\n",
    "- `log_b` *(array)*: Synthetic Core B log data\n",
    "- `md_a` *(array)*: Synthetic Core A measured depths\n",
    "- `md_b` *(array)*: Synthetic Core B measured depths\n",
    "- `picked_datum_a` *(list)*: Picked datum depths for Core A\n",
    "- `picked_datum_b` *(list)*: Picked datum depths for Core B\n",
    "- `independent_dtw` *(bool, default=False)*: Use independent DTW for each log dimension\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent multidimensional DTW\n",
    "- `top_bottom` *(bool, default=False)*: Include top and bottom boundaries\n",
    "- `mute_mode` *(bool, default=False)*: Suppress print output\n",
    "\n",
    "**Returns:**\n",
    "- `dtw_result` (dict): Dictionary containing DTW analysis results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_result = run_comprehensive_dtw_analysis(\n",
    "    syn_log_a, syn_log_b, syn_md_a, syn_md_b,\n",
    "    picked_datum_a=syn_depth_a,\n",
    "    picked_datum_b=syn_depth_b\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for All Complete DTW Paths\n",
    "\n",
    "**Function: `find_complete_core_paths()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Searches through all valid segment pairs to find complete correlation paths\n",
    "2. Calculates quality metrics for each complete path\n",
    "3. Uses shortest path algorithms to optimize search\n",
    "4. Exports all valid mappings to CSV file\n",
    "\n",
    "**Key Parameters:**\n",
    "- `dtw_result` *(dict)*: Dictionary containing DTW analysis results from `run_comprehensive_dtw_analysis()`. Expected keys: 'dtw_correlation', 'valid_dtw_pairs', 'segments_a', 'segments_b', 'depth_boundaries_a', 'depth_boundaries_b', 'dtw_distance_matrix_full'\n",
    "- `log_a` *(array)*: Core A log data for metric computation\n",
    "- `log_b` *(array)*: Core B log data for metric computation\n",
    "- `output_csv` *(str, default='complete_core_paths.csv')*: Output CSV filename for mappings\n",
    "- `debug` *(bool, default=False)*: Enable detailed progress reporting\n",
    "- `start_from_top_only` *(bool, default=True)*: Only start paths from top segments\n",
    "- `batch_size` *(int, default=1000)*: Processing batch size for memory management\n",
    "- `n_jobs` *(int, default=-1)*: Number of parallel jobs (-1 uses all CPU cores)\n",
    "- `shortest_path_search` *(bool, default=True)*: Keep only shortest path lengths during search\n",
    "- `shortest_path_level` *(int, default=2)*: Number of shortest unique lengths to keep (higher = more segments)\n",
    "- `max_search_path` *(int, default=5000)*: Maximum paths per segment pair to prevent memory overflow. Higher, more comprehensive in the solution search (e.g., 100000 would typically work great).\n",
    "- `output_metric_only` *(bool, default=False)*: If True, only output quality metrics without full path details\n",
    "- `mute_mode` *(bool, default=False)*: Suppress all print output\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for dependent DTW quality calculations\n",
    "\n",
    "**Returns:**\n",
    "- `complete_path_search_result` (dict): Dictionary containing:\n",
    "    - `complete_paths` (list): All complete correlation paths with quality metrics\n",
    "    - `num_paths` (int): Total number of complete paths found\n",
    "    - `csv_file` (str): Path to output CSV file containing all mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = find_complete_core_paths(\n",
    "    dtw_result,\n",
    "    syn_log_a, \n",
    "    syn_log_b,\n",
    "    output_csv=f\"example_data/analytical_outputs/temp_synthetic_{'_'.join(LOG_COLUMNS)}_core_pair_metrics.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality Metric Distributions\n",
    "\n",
    "**Function: `plot_correlation_distribution()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Loads all mappings from CSV file\n",
    "2. Extracts quality metrics for the target mapping\n",
    "3. Plots histogram and probability distribution\n",
    "4. Compares target mapping against all other solutions\n",
    "5. Saves distribution plot as PNG\n",
    "\n",
    "**Key Parameters:**\n",
    "- `mapping_csv` *(str)*: Path to mappings CSV or Parquet file\n",
    "- `target_mapping_id` *(int, default=None)*: ID of mapping to highlight in the plot (optional)\n",
    "- `quality_index` *(str)*: Quality metric to plot - **required**. Options: 'corr_coef', 'norm_dtw', 'dtw_ratio', 'variance_deviation', 'perc_diag', 'match_min', 'match_mean', 'perc_age_overlap'\n",
    "- `save_png` *(bool, default=True)*: Whether to save plot as PNG\n",
    "- `png_filename` *(str, default=None)*: Output PNG filename (optional)\n",
    "- `core_a_name` *(str, default=None)*: Core A name for plot title (optional)\n",
    "- `core_b_name` *(str, default=None)*: Core B name for plot title (optional)\n",
    "- `bin_width` *(float, default=None)*: Histogram bin width (auto if None, based on quality_index)\n",
    "- `pdf_method` *(str, default='normal')*: PDF fitting method ('KDE', 'skew-normal', or 'normal')\n",
    "- `kde_bandwidth` *(float, default=0.05)*: Bandwidth for KDE when pdf_method='KDE'\n",
    "- `mute_mode` *(bool, default=False)*: If True, suppress all print statements\n",
    "- `targeted_binsize` *(tuple, default=None)*: (synthetic_bins, bin_width) for consistent bin sizing with synthetic data\n",
    "- `dpi` *(int, default=None)*: Resolution for saved figures in dots per inch. If None, uses default (150)\n",
    "\n",
    "**Returns:**\n",
    "- `fit_params` (dict): Dictionary containing distribution statistics including histogram data, PDF parameters, and percentile information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Correlation Coefficient Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='corr_coef'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Normalized DTW Cost Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_correlation_distribution(\n",
    "    mapping_csv=f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv',\n",
    "    quality_index='norm_dtw'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove demo temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv'):\n",
    "    os.remove(f\"example_data/analytical_outputs/temp_synthetic_{\"_\".join(LOG_COLUMNS)}_core_pair_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Run Multiple Synthetic Iterations**\n",
    "\n",
    "Generate and analyze many synthetic core pairs to establish null hypothesis distributions for correlation quality metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Iterative Synthetic Analysis\n",
    "\n",
    "**Function: `synthetic_correlation_quality()`**\n",
    "\n",
    "**What it does:**\n",
    "1. Generates multiple synthetic core pairs from the segment pool\n",
    "2. Runs DTW analysis on each pair\n",
    "3. Collects quality metrics from all correlation solutions\n",
    "4. Exports probability distributions for each quality metric to CSV\n",
    "\n",
    "**Key Parameters:**\n",
    "- `segment_logs` *(list)*: Segment log arrays from `load_segment_pool()` or `modify_segment_pool()`\n",
    "- `segment_depths` *(list)*: Segment depth arrays from `load_segment_pool()` or `modify_segment_pool()`\n",
    "- `log_data_type` *(list)*: List of log names to analyze\n",
    "- `quality_indices` *(list)*: Quality metrics to compute (e.g., ['corr_coef', 'norm_dtw'])\n",
    "- `number_of_iterations` *(int)*: Number of synthetic pairs to generate\n",
    "- `core_a_length` *(float)*: Target thickness for synthetic Core A\n",
    "- `core_b_length` *(float)*: Target thickness for synthetic Core B\n",
    "- `repetition` *(bool, default=False)*: Allow segment reuse within a core\n",
    "- `pca_for_dependent_dtw` *(bool, default=False)*: Use PCA for multidimensional DTW\n",
    "- `output_csv_dir` *(str, default=None)*: Directory for output CSV files\n",
    "- `max_search_path` *(int, default=5000)*: Maximum paths to search per segment pair\n",
    "- `mute_mode` *(bool, default=False)*: Suppress console output\n",
    "\n",
    "**Returns:**\n",
    "None (outputs CSV files for each quality index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_correlation_quality(\n",
    "    segment_logs=mod_seg_logs,\n",
    "    segment_depths=mod_seg_depths,\n",
    "    log_data_type=LOG_COLUMNS,\n",
    "    quality_indices=['corr_coef', 'norm_dtw'],\n",
    "    number_of_iterations=50,\n",
    "    core_a_length=400,\n",
    "    core_b_length=400,\n",
    "    output_csv_dir='example_data/analytical_outputs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Visualize Synthetic Correlation Results**\n",
    "\n",
    "Plot the probability distributions from multiple iterations to establish baseline correlation quality expectations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Individual Iteration PDFs\n",
    "\n",
    "**Function: `plot_synthetic_correlation_quality()`**\n",
    "\n",
    "**What it does:**\n",
    "Visualizes the probability distribution functions (PDFs) from synthetic correlation analysis, either as individual iteration curves or as a combined distribution.\n",
    "\n",
    "**Key Parameters:**\n",
    "- `input_csv` *(str)*: Path to CSV file with `{quality_index}` placeholder\n",
    "- `quality_indices` *(list)*: Quality metrics to plot\n",
    "- `bin_width` *(float, default=None)*: Histogram bin width (auto if None)\n",
    "- `plot_individual_pdf` *(bool, default=True)*: True shows individual PDFs, False shows combined\n",
    "- `save_plot` *(bool, default=False)*: Whether to save the figure\n",
    "- `plot_filename` *(str, default=None)*: Output filename with `{quality_index}` placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_data/analytical_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Combined Distribution from All Iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_indices = ['corr_coef', 'norm_dtw']\n",
    "\n",
    "plot_synthetic_correlation_quality(\n",
    "    input_csv=f'example_data/analytical_outputs/synthetic_PDFs_{\"_\".join(LOG_COLUMNS)}_{{quality_index}}.csv',\n",
    "    quality_indices=quality_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
