{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List, Callable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.signal import correlate\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Functions for Core CT Image Processing**\n",
    "\n",
    "The following functions are extracted from the core_ct package to handle CT scan image processing:\n",
    "\n",
    "### Data Loading\n",
    "- `load_dicom_files`: Loads DICOM files from a directory and returns 3D volume data along with pixel spacing and slice thickness information\n",
    "\n",
    "### Slice Operations  \n",
    "- `get_slice`: Extracts a 2D slice from the 3D volume along a specified axis\n",
    "- `trim_slice`: Trims empty space from a slice based on an intensity threshold\n",
    "\n",
    "### Brightness Analysis\n",
    "- `get_brightness_trace`: Calculates mean brightness along a specified axis\n",
    "- `get_brightness_stats`: Calculates brightness mean and standard deviation along an axis\n",
    "- `process_brightness_data`: Processes CT scan data to get masked brightness and standard deviation statistics\n",
    "\n",
    "### Visualization\n",
    "- `display_slice`: Shows a single slice with optional physical dimensions\n",
    "- `display_slice_bt_std`: Displays a core slice with corresponding brightness trace and standard deviation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_files(dir_path: str, force: bool = True) -> Tuple[np.ndarray, float, float, float]:\n",
    "    \"\"\"\n",
    "    Load DICOM files from a directory and return the 3D volume data.\n",
    "    \n",
    "    Args:\n",
    "        dir_path: Path to directory containing DICOM files\n",
    "        force: If True, ignore files that produce errors\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (volume_data, pixel_spacing_x, pixel_spacing_y, slice_thickness)\n",
    "    \"\"\"\n",
    "    # Get list of files in directory\n",
    "    files = sorted([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "    \n",
    "    slices = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            ds = pydicom.dcmread(os.path.join(dir_path, f))\n",
    "            slices.append(ds)\n",
    "        except:\n",
    "            if not force:\n",
    "                raise\n",
    "            continue\n",
    "    \n",
    "    # Sort slices by ImagePositionPatient z coordinate\n",
    "    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "    \n",
    "    # Get image dimensions and spacing info\n",
    "    pixel_spacing = slices[0].PixelSpacing\n",
    "    slice_thickness = float(slices[0].SliceThickness)\n",
    "    \n",
    "    # Create 3D numpy array\n",
    "    img_shape = list(slices[0].pixel_array.shape)\n",
    "    img_shape.append(len(slices))\n",
    "    volume_data = np.zeros(img_shape)\n",
    "    \n",
    "    # Fill 3D array with the images from the files\n",
    "    for i, s in enumerate(slices):\n",
    "        volume_data[:,:,i] = s.pixel_array\n",
    "        \n",
    "    return volume_data, pixel_spacing[0], pixel_spacing[1], slice_thickness\n",
    "\n",
    "def get_slice(volume: np.ndarray, index: int, axis: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract a 2D slice from the 3D volume along specified axis.\n",
    "    \n",
    "    Args:\n",
    "        volume: 3D numpy array of CT data\n",
    "        index: Index of slice to extract\n",
    "        axis: Axis along which to take slice (0, 1, or 2)\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array of the slice\n",
    "    \"\"\"\n",
    "    if axis == 0:\n",
    "        return volume[index, :, :]\n",
    "    elif axis == 1:\n",
    "        return volume[:, index, :]\n",
    "    else:\n",
    "        return volume[:, :, index]\n",
    "\n",
    "def trim_slice(slice_data: np.ndarray, threshold: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Trim empty space from a slice based on intensity threshold.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of slice data\n",
    "        threshold: Value below which pixels are considered empty\n",
    "        \n",
    "    Returns:\n",
    "        Trimmed 2D numpy array\n",
    "    \"\"\"\n",
    "    # Find non-empty rows and columns\n",
    "    row_mask = np.any(slice_data > threshold, axis=1)\n",
    "    col_mask = np.any(slice_data > threshold, axis=0)\n",
    "    \n",
    "    # Get indices of non-empty regions\n",
    "    row_indices = np.where(row_mask)[0]\n",
    "    col_indices = np.where(col_mask)[0]\n",
    "    \n",
    "    # Trim the slice\n",
    "    return slice_data[row_indices[0]:row_indices[-1]+1, \n",
    "                     col_indices[0]:col_indices[-1]+1]\n",
    "\n",
    "def get_brightness_trace(slice_data: np.ndarray, axis: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate brightness trace along specified axis.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of slice data\n",
    "        axis: Axis along which to calculate mean (0 for vertical, 1 for horizontal)\n",
    "    \n",
    "    Returns:\n",
    "        1D numpy array of mean values\n",
    "    \"\"\"\n",
    "    return np.mean(slice_data, axis=axis)\n",
    "\n",
    "def display_slice(slice_data: np.ndarray, \n",
    "                 pixel_spacing: Optional[Tuple[float, float]] = None,\n",
    "                 title: str = \"Core Slice\") -> None:\n",
    "    \"\"\"\n",
    "    Display a slice with optional physical dimensions.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of slice data\n",
    "        pixel_spacing: Optional tuple of (x, y) pixel spacing in mm\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if pixel_spacing is not None:\n",
    "        extent = [0, slice_data.shape[1] * pixel_spacing[0],\n",
    "                 0, slice_data.shape[0] * pixel_spacing[1]]\n",
    "        plt.imshow(slice_data, extent=extent)\n",
    "        plt.xlabel(\"Distance\")\n",
    "        plt.ylabel(\"Distance\")\n",
    "    else:\n",
    "        plt.imshow(slice_data)\n",
    "        plt.xlabel(\"Pixels\")\n",
    "        plt.ylabel(\"Pixels\")\n",
    "    \n",
    "    plt.colorbar(label=\"Intensity\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def get_brightness_stats(slice_data: np.ndarray, axis: int = 1, width_start_pct: float = 0.25, width_end_pct: float = 0.75) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate brightness mean and standard deviation along specified axis.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of slice data\n",
    "        axis: Axis along which to calculate stats (0 for vertical, 1 for horizontal)\n",
    "        width_start_pct: Starting percentage of width for the strip (default 0.25)\n",
    "        width_end_pct: Ending percentage of width for the strip (default 0.75)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (mean values array, standard deviation array)\n",
    "    \"\"\"\n",
    "    # Calculate the start and end indices based on provided percentages\n",
    "    width = slice_data.shape[1]\n",
    "    start_idx = int(width * width_start_pct)\n",
    "    end_idx = int(width * width_end_pct)\n",
    "    \n",
    "    # Use only the specified strip for calculations\n",
    "    center_slice = slice_data[:, start_idx:end_idx]\n",
    "    \n",
    "    return np.mean(center_slice, axis=axis), np.std(center_slice, axis=axis)\n",
    "\n",
    "def display_slice_bt_std(slice_data: np.ndarray,\n",
    "                        brightness: np.ndarray,\n",
    "                        stddev: np.ndarray,\n",
    "                        pixel_spacing: Optional[Tuple[float, float]] = None,\n",
    "                        core_name: str = \"\",\n",
    "                        save_figs: bool = False,\n",
    "                        output_dir: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Display a core slice and corresponding brightness trace and standard deviation.\n",
    "    Similar to core_ct's display_slice_bt_std function.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of slice data\n",
    "        brightness: 1D array of mean brightness values\n",
    "        stddev: 1D array of standard deviation values\n",
    "        pixel_spacing: Optional tuple of (x, y) pixel spacing in mm\n",
    "        core_name: Name of the core to display in title\n",
    "        save_figs: Whether to save figures to files (default False)\n",
    "        output_dir: Directory to save figures if save_figs is True\n",
    "    \"\"\"\n",
    "    # Create figure with 3 subplots with specific width ratios and smaller space between subplots\n",
    "    # Calculate height based on data dimensions while keeping width fixed at 8\n",
    "    height = 2 * (slice_data.shape[0] / slice_data.shape[1])\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "        1, 3, \n",
    "        figsize=(7, height),\n",
    "        sharey=True,\n",
    "        gridspec_kw={'width_ratios': [1.7, 0.6, 0.3], 'wspace': 0.22}\n",
    "    )\n",
    "    # Plot the slice\n",
    "    slice_dim = slice_data.shape\n",
    "    if pixel_spacing is not None:\n",
    "        extent = [\n",
    "            0, slice_dim[1] * pixel_spacing[0],\n",
    "            slice_dim[0] * pixel_spacing[1], 0\n",
    "        ]  # Note: y-axis inverted\n",
    "        im = ax1.imshow(slice_data, extent=extent, cmap='jet', vmin=400, vmax=1700)  # vmin set to the defined minimum brightness threshold\n",
    "        ax1.set_xlabel(\"Width\", fontsize='small')\n",
    "        ax1.set_ylabel(\"Depth\", fontsize='small')\n",
    "    else:\n",
    "        im = ax1.imshow(slice_data, cmap='jet', vmin=400, vmax=1700)  # vmin set to the defined minimum brightness threshold\n",
    "        ax1.set_xlabel(\"Width (pixels)\", fontsize='small')\n",
    "        ax1.set_ylabel(\"Depth (pixels)\", fontsize='small')\n",
    "    \n",
    "    # Add colorbar with small tick labels\n",
    "    cbar = plt.colorbar(im, ax=ax1)\n",
    "    cbar.ax.tick_params(labelsize='x-small')\n",
    "    \n",
    "    # Calculate y coordinates for brightness and stddev plots\n",
    "    y_coords = np.arange(len(brightness))\n",
    "    if pixel_spacing is not None:\n",
    "        y_coords = y_coords * pixel_spacing[1]\n",
    "    \n",
    "    # Plot brightness trace with standard deviation shading\n",
    "    ax2.plot(brightness, y_coords, 'b-', label='Mean')\n",
    "    ax2.fill_betweenx(\n",
    "        y_coords, \n",
    "        brightness - stddev, \n",
    "        brightness + stddev, \n",
    "        alpha=0.1, color='b', label='±1σ', linewidth=0\n",
    "    )\n",
    "    ax2.set_xlabel(\"CT# ±1σ\", fontsize='small')\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xlim(left=400)  # Set x-axis to start at 400\n",
    "    \n",
    "    # Plot standard deviation\n",
    "    ax3.plot(stddev, y_coords)\n",
    "    ax3.set_xlabel(\"σ (STDEV)\", fontsize='small')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Add text annotation if core name is provided\n",
    "    if core_name:\n",
    "        fig.text(.5, 0.92, core_name, fontweight='bold', ha='center', va='top')\n",
    "    \n",
    "    # Make tick labels smaller for all axes\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.tick_params(axis='both', which='major', labelsize='x-small')\n",
    "    \n",
    "    # show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Save figures if requested\n",
    "    if save_figs:\n",
    "        if output_dir is None:\n",
    "            raise ValueError(\"output_dir must be provided when save_figs is True\")\n",
    "            \n",
    "        # Save full figure as PNG and SVG\n",
    "        output_file = os.path.join(output_dir, f\"{core_name}.png\")\n",
    "        fig.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Composite CT results saved to: ~/{'/'.join(output_file.split('/')[-2:])}\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, f\"{core_name}.svg\") \n",
    "        fig.savefig(output_file, bbox_inches='tight')\n",
    "        print(f\"Composite CT image saved to: ~/{'/'.join(output_file.split('/')[-2:])}\")\n",
    "        \n",
    "        # Create and save colormap image as compressed TIFF\n",
    "        # Calculate aspect ratio of data\n",
    "        data_height, data_width = slice_data.shape\n",
    "        data_aspect = data_height / data_width\n",
    "        \n",
    "        # Set figure size to maintain data aspect ratio while filling width\n",
    "        fig_width = 2  # Keep original width\n",
    "        fig_height = fig_width * data_aspect\n",
    "        \n",
    "        fig_img = plt.figure(figsize=(fig_width, fig_height), dpi=300)\n",
    "        \n",
    "        # Create axes that fills entire figure\n",
    "        ax = plt.axes([0, 0, 1, 1])\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "        if pixel_spacing is not None:\n",
    "            im_img = plt.imshow(slice_data, extent=extent, cmap='jet', vmin=400, aspect='auto')\n",
    "        else:\n",
    "            im_img = plt.imshow(slice_data, cmap='jet', vmin=400, aspect='auto')\n",
    "            \n",
    "        # Ensure no padding\n",
    "        plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "        plt.margins(0,0)\n",
    "        \n",
    "        # Convert matplotlib figure to RGB array\n",
    "        fig_img.canvas.draw()\n",
    "        img_array = np.array(fig_img.canvas.renderer.buffer_rgba())[:,:,:3]\n",
    "        \n",
    "        # Save as compressed TIFF using PIL\n",
    "        output_file = os.path.join(output_dir, f\"{core_name}.tiff\")\n",
    "        img = Image.fromarray(img_array)\n",
    "        img.save(output_file, format='TIFF', compression='tiff_deflate')\n",
    "        print(f\"CT image saved to: ~/{'/'.join(output_file.split('/')[-2:])}\")\n",
    "        plt.close(fig_img)\n",
    "\n",
    "\n",
    "def process_brightness_data(slice_data, px_spacing_y, trim_top, trim_bottom, min_brightness=400, buffer=5, width_start_pct=0.25, width_end_pct=0.75):\n",
    "    \"\"\"\n",
    "    Process CT scan slice data to get brightness and standard deviation statistics with masking.\n",
    "    \n",
    "    Args:\n",
    "        slice_data: 2D numpy array of CT scan slice data\n",
    "        px_spacing_y: Pixel spacing in y direction (mm/pixel)\n",
    "        trim_top: Amount to trim from top in mm\n",
    "        trim_bottom: Amount to trim from bottom in mm \n",
    "        buffer_mm: Buffer size in mm around masked values (default 5)\n",
    "        min_brightness: Minimum brightness threshold (default 400)\n",
    "        width_start_pct: Starting percentage of width to use for brightness calculation (default 0.25)\n",
    "        width_end_pct: Ending percentage of width to use for brightness calculation (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        brightness: Masked brightness values\n",
    "        stddev: Masked standard deviation values\n",
    "    \"\"\"\n",
    "    # Trim the slice based on trim values\n",
    "    if trim_top == 0 and trim_bottom == 0:\n",
    "        trimmed_slice = trim_slice(slice_data)\n",
    "    elif trim_top == 0:\n",
    "        trimmed_slice = trim_slice(slice_data[:-trim_bottom])\n",
    "    elif trim_bottom == 0:\n",
    "        trimmed_slice = trim_slice(slice_data[trim_top:])\n",
    "    else:\n",
    "        trimmed_slice = trim_slice(slice_data[trim_top:-trim_bottom])\n",
    "    \n",
    "    # Get brightness stats with width percentage parameters\n",
    "    brightness, stddev = get_brightness_stats(trimmed_slice, width_start_pct=width_start_pct, width_end_pct=width_end_pct)\n",
    "    \n",
    "    # Convert buffer from mm to pixels\n",
    "    px_per = 1/px_spacing_y\n",
    "    buffer_px = int(buffer * px_per)\n",
    "    \n",
    "    # Find indices below minimum brightness\n",
    "    neg_indices = np.where(brightness < min_brightness)[0]\n",
    "    \n",
    "    # Create buffer zones around values below threshold\n",
    "    buffer_zones = []\n",
    "    for idx in neg_indices:\n",
    "        start = max(0, idx - buffer_px)\n",
    "        end = min(len(brightness), idx + buffer_px + 1)\n",
    "        buffer_zones.extend(range(start, end))\n",
    "        \n",
    "    # Create and apply mask\n",
    "    mask = np.ones(len(brightness), dtype=bool)\n",
    "    mask[buffer_zones] = False\n",
    "    brightness[~mask] = np.nan\n",
    "    stddev[~mask] = np.nan\n",
    "    \n",
    "    return brightness, stddev, trimmed_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Functions for Curve Matching and Stitching**\n",
    "\n",
    "The following functions handle matching and stitching of CT scan brightness curves:\n",
    "\n",
    "### Overlap Detection\n",
    "- `find_best_overlap`: Finds optimal overlap between two curves by maximizing:\n",
    "  1. Pearson correlation coefficient ($r$) between overlapping sections:\n",
    "     $$r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2\\sum(y_i - \\bar{y})^2}}$$\n",
    "  2. Peak matching score based on prominence alignment\n",
    "     Final score: $score = r + \\sum_{peaks} w_p$ where $w_p = 2.0$ per matched peak pair\n",
    "\n",
    "### Curve Stitching  \n",
    "- `stitch_curves`: Combines overlapping curves by:\n",
    "  1. Finding optimal overlap position\n",
    "  2. Averaging overlap region values: $v_{overlap} = \\frac{v_1 + v_2}{2}$\n",
    "  3. Concatenating sections: $v_{stitched} = [v_1[:-o], v_{overlap}, v_2[o:]]$\n",
    "     where $o$ is overlap length\n",
    "\n",
    "### Visualization\n",
    "- `plot_stitched_curves`: Displays stitching results with:\n",
    "  - Original curves and overlap regions\n",
    "  - Final stitched curve\n",
    "  - Stitch point markers\n",
    "  - Brightness and standard deviation plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate correlation at different overlaps\n",
    "def find_best_overlap(curve1, curve2, min_overlap=20, max_overlap=450):\n",
    "    max_corr = -np.inf\n",
    "    best_overlap = 0\n",
    "    \n",
    "    # Remove NaN values for correlation calculation\n",
    "    curve1_clean = pd.Series(curve1).fillna(0)\n",
    "    curve2_clean = pd.Series(curve2).fillna(0)\n",
    "    \n",
    "    # Find peaks with prominence to identify major peaks\n",
    "    curve1_peaks, properties1 = scipy.signal.find_peaks(curve1_clean, prominence=50)\n",
    "    curve2_peaks, properties2 = scipy.signal.find_peaks(curve2_clean, prominence=50)\n",
    "    \n",
    "    # Find valleys (negative peaks)\n",
    "    curve1_valleys, properties1_valleys = scipy.signal.find_peaks(-curve1_clean, prominence=50)\n",
    "    curve2_valleys, properties2_valleys = scipy.signal.find_peaks(-curve2_clean, prominence=50)\n",
    "    \n",
    "    # Sort peaks by prominence\n",
    "    curve1_peak_heights = properties1['prominences']\n",
    "    curve2_peak_heights = properties2['prominences']\n",
    "    curve1_valley_depths = properties1_valleys['prominences']\n",
    "    curve2_valley_depths = properties2_valleys['prominences']\n",
    "    \n",
    "    # Get first peak/valley and top peaks/valleys\n",
    "    curve1_first_peak = curve1_peaks[0] if len(curve1_peaks) > 0 else None\n",
    "    curve2_first_peak = curve2_peaks[0] if len(curve2_peaks) > 0 else None\n",
    "    curve1_first_valley = curve1_valleys[0] if len(curve1_valleys) > 0 else None\n",
    "    curve2_first_valley = curve2_valleys[0] if len(curve2_valleys) > 0 else None\n",
    "    curve1_major_peaks = curve1_peaks[np.argsort(curve1_peak_heights)[-10:]] # Top 10 peaks\n",
    "    curve2_major_peaks = curve2_peaks[np.argsort(curve2_peak_heights)[-10:]]\n",
    "    curve1_major_valleys = curve1_valleys[np.argsort(curve1_valley_depths)[-5:]] # Top 5 valleys\n",
    "    curve2_major_valleys = curve2_valleys[np.argsort(curve2_valley_depths)[-5:]]\n",
    "    \n",
    "    # Try different overlap positions\n",
    "    for overlap in range(min_overlap, min(len(curve1), len(curve2), max_overlap)):\n",
    "        # Get overlapping sections\n",
    "        overlap1 = curve1_clean[-overlap:]\n",
    "        overlap2 = curve2_clean[:overlap]\n",
    "        \n",
    "        if len(overlap1) == len(overlap2):\n",
    "            # Calculate regular correlation\n",
    "            corr = np.corrcoef(overlap1, overlap2)[0,1]\n",
    "            \n",
    "            # Calculate peak matching score with weighted priorities\n",
    "            peak_score = 0\n",
    "            \n",
    "            # Check first peaks in overlap region\n",
    "            if curve1_first_peak is not None and curve2_first_peak is not None:\n",
    "                if curve1_first_peak >= len(curve1)-overlap:\n",
    "                    p1_adjusted = curve1_first_peak - (len(curve1) - overlap)\n",
    "                    if abs(p1_adjusted - curve2_first_peak) < 5:  # Small tolerance\n",
    "                        peak_score += 2.0  # Highest weight for first peak match\n",
    "            \n",
    "            # Check first valleys in overlap region\n",
    "            if curve1_first_valley is not None and curve2_first_valley is not None:\n",
    "                if curve1_first_valley >= len(curve1)-overlap:\n",
    "                    v1_adjusted = curve1_first_valley - (len(curve1) - overlap)\n",
    "                    if abs(v1_adjusted - curve2_first_valley) < 5:  # Small tolerance\n",
    "                        peak_score += 1.2  # High weight for first valley match\n",
    "            \n",
    "            # Check major peaks in overlap region\n",
    "            overlap1_peaks = [p for p in curve1_major_peaks if p >= len(curve1)-overlap]\n",
    "            overlap2_peaks = [p for p in curve2_major_peaks if p < overlap]\n",
    "            \n",
    "            # Add bonus for matching major peaks\n",
    "            if len(overlap1_peaks) > 0 and len(overlap2_peaks) > 0:\n",
    "                for p1 in overlap1_peaks:\n",
    "                    for p2 in overlap2_peaks:\n",
    "                        p1_adjusted = p1 - (len(curve1) - overlap)\n",
    "                        if abs(p1_adjusted - p2) < 5:  # Small tolerance\n",
    "                            peak_score += 0.5  # Weight for major peak matches\n",
    "                            \n",
    "            # Check major valleys in overlap region\n",
    "            overlap1_valleys = [v for v in curve1_major_valleys if v >= len(curve1)-overlap]\n",
    "            overlap2_valleys = [v for v in curve2_major_valleys if v < overlap]\n",
    "            \n",
    "            # Add bonus for matching major valleys\n",
    "            if len(overlap1_valleys) > 0 and len(overlap2_valleys) > 0:\n",
    "                for v1 in overlap1_valleys:\n",
    "                    for v2 in overlap2_valleys:\n",
    "                        v1_adjusted = v1 - (len(curve1) - overlap)\n",
    "                        if abs(v1_adjusted - v2) < 3:  # Small tolerance\n",
    "                            peak_score += 0.3  # Weight for major valley matches\n",
    "            \n",
    "            # Combine scores with emphasis on peaks first, then correlation\n",
    "            total_score = peak_score + corr\n",
    "            \n",
    "            if total_score > max_corr:\n",
    "                max_corr = total_score\n",
    "                best_overlap = overlap\n",
    "                \n",
    "    return best_overlap, max_corr\n",
    "\n",
    "def stitch_curves(brightness_1, brightness_2, stddev_1, stddev_2, px_spacing_y_1, px_spacing_y_2, min_overlap=20, max_overlap=450):\n",
    "    # Convert to true depth values for overlap finding\n",
    "    depth_1 = np.arange(len(brightness_1)) * px_spacing_y_1\n",
    "    depth_2 = np.arange(len(brightness_2)) * px_spacing_y_2\n",
    "    \n",
    "    # Find best overlap position using only brightness\n",
    "    final_overlap, brightness_corr = find_best_overlap(brightness_1, brightness_2, min_overlap=min_overlap, max_overlap=max_overlap)\n",
    "    \n",
    "    print(f\"Brightness overlap: {final_overlap} pixels (correlation: {brightness_corr:.3f})\")\n",
    "    \n",
    "    # Get overlapping sections in true depth\n",
    "    overlap_depth_1 = np.arange(len(brightness_1)-final_overlap, len(brightness_1)) * px_spacing_y_1\n",
    "    overlap_depth_2 = np.arange(final_overlap) * px_spacing_y_2  # Use curve 2's spacing\n",
    "    \n",
    "    # Calculate shift values based on the overlap region\n",
    "    brightness_shift = np.nanmean(brightness_1[-final_overlap:] - brightness_2[:final_overlap])  #avoid NaN\n",
    "    stddev_shift = np.nanmean(stddev_1[-final_overlap:] - stddev_2[:final_overlap])              #avoid NaN\n",
    "    \n",
    "    # Shift the entire second dataset\n",
    "    brightness_2_shifted = brightness_2 + brightness_shift\n",
    "    stddev_2_shifted = stddev_2 + stddev_shift\n",
    "    \n",
    "    print(f\"Applied brightness shift: {brightness_shift:.3f}\")\n",
    "    print(f\"Applied stddev shift: {stddev_shift:.3f}\")\n",
    "    \n",
    "    # Create averaged values in overlap region using shifted brightness and stddev\n",
    "    # Create masks for invalid values (NaN or zero)\n",
    "    mask1_brightness = ~(np.isnan(brightness_1[-final_overlap:]) | (brightness_1[-final_overlap:] == 0))\n",
    "    mask2_brightness = ~(np.isnan(brightness_2_shifted[:final_overlap]) | (brightness_2_shifted[:final_overlap] == 0))\n",
    "    mask1_stddev = ~(np.isnan(stddev_1[-final_overlap:]) | (stddev_1[-final_overlap:] == 0))\n",
    "    mask2_stddev = ~(np.isnan(stddev_2_shifted[:final_overlap]) | (stddev_2_shifted[:final_overlap] == 0))\n",
    "    \n",
    "    # Only average where both values are valid\n",
    "    overlap_brightness = np.full(final_overlap, np.nan)\n",
    "    overlap_stddev = np.full(final_overlap, np.nan)\n",
    "    valid_mask_brightness = mask1_brightness & mask2_brightness\n",
    "    valid_mask_stddev = mask1_stddev & mask2_stddev\n",
    "    \n",
    "    overlap_brightness[valid_mask_brightness] = (brightness_1[-final_overlap:][valid_mask_brightness] + \n",
    "                                               brightness_2_shifted[:final_overlap][valid_mask_brightness]) / 2\n",
    "    overlap_stddev[valid_mask_stddev] = (stddev_1[-final_overlap:][valid_mask_stddev] + \n",
    "                                        stddev_2_shifted[:final_overlap][valid_mask_stddev]) / 2\n",
    "    \n",
    "    # Stitch the curves using the final overlap position with averaged overlap region\n",
    "    stitched_brightness = np.concatenate([\n",
    "        brightness_1[:-final_overlap],  # Non-overlapped part of curve 1\n",
    "        overlap_brightness,             # Averaged overlap region\n",
    "        brightness_2_shifted[final_overlap:]  # Non-overlapped part of curve 2\n",
    "    ])\n",
    "    stitched_stddev = np.concatenate([\n",
    "        stddev_1[:-final_overlap],\n",
    "        overlap_stddev,\n",
    "        stddev_2_shifted[final_overlap:]\n",
    "    ])\n",
    "    \n",
    "    # Create depth array for the stitched data using appropriate spacing for each section\n",
    "    depth_before_overlap = np.arange(len(brightness_1)-final_overlap) * px_spacing_y_1\n",
    "    depth_overlap = overlap_depth_1  # Use spacing from curve 1 for overlap region\n",
    "    depth_after_overlap = (np.arange(len(brightness_2)-final_overlap) * px_spacing_y_2) + overlap_depth_1[-1]\n",
    "    stitched_depth = np.concatenate([depth_before_overlap, depth_overlap, depth_after_overlap])\n",
    "    \n",
    "    return (final_overlap, overlap_depth_1, overlap_depth_2, \n",
    "            stitched_brightness, stitched_stddev, stitched_depth, \n",
    "            brightness_2_shifted, stddev_2_shifted)\n",
    "\n",
    "def plot_stitched_curves(stitched_depth, stitched_brightness, stitched_stddev, \n",
    "                        brightness_1, brightness_2, stddev_1, stddev_2,\n",
    "                        brightness_2_shifted, stddev_2_shifted,\n",
    "                        final_overlap, overlap_depth_1, overlap_depth_2, px_spacing_y_1, px_spacing_y_2):\n",
    "    # Plot the stitched results\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 5))\n",
    "    \n",
    "    # Calculate overlap region correctly using overlap_depth_1\n",
    "    overlap_start = overlap_depth_1[0]\n",
    "    overlap_end = overlap_depth_1[-1]\n",
    "    \n",
    "    # Add shaded overlap region for brightness\n",
    "    ax1.axvspan(overlap_start, overlap_end, \n",
    "                color='gray', alpha=0.2, label='Overlap Region')\n",
    "    \n",
    "    # Plot overlapping sections\n",
    "    ax1.plot(overlap_depth_1, brightness_1[-final_overlap:], 'g:', label='Overlapped Curve 1')\n",
    "    ax1.plot(overlap_depth_1, brightness_2_shifted[:final_overlap], 'r:', label='Adjusted Curve 2')\n",
    "    \n",
    "    # Plot brightness curves\n",
    "    ax1.plot(stitched_depth, stitched_brightness, 'b-', label='Stitched Curves')\n",
    "    \n",
    "    # Create depth arrays for original and shifted curves using respective spacings\n",
    "    depth_2 = np.arange(len(brightness_2)) * px_spacing_y_2\n",
    "    depth_2_shifted = depth_2 + overlap_start  # Adjust to use overlap_start\n",
    "    \n",
    "    ax1.set_xlabel('Depth')\n",
    "    ax1.set_ylabel('Adjusted CT#')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='upper left', fontsize='x-small')\n",
    "    \n",
    "    # Add shaded overlap region for stddev\n",
    "    ax2.axvspan(overlap_start, overlap_end, \n",
    "                color='gray', alpha=0.2, label='Overlap Region')\n",
    "    \n",
    "    # Plot overlapping sections\n",
    "    ax2.plot(overlap_depth_1, stddev_1[-final_overlap:], 'g:', label='Overlapped Curve 1')\n",
    "    ax2.plot(overlap_depth_1, stddev_2_shifted[:final_overlap], 'r:', label='Adjusted Curve 2')\n",
    "    \n",
    "    # Plot standard deviation curves\n",
    "    ax2.plot(stitched_depth, stitched_stddev, 'b-', label='Stitched Curves')\n",
    "    ax2.set_xlabel('Depth')\n",
    "    ax2.set_ylabel('Adjusted σ (STDEV)')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend(loc='upper left', fontsize='x-small')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_stitched_slice(trimmed_slice_1, trimmed_slice_2, final_overlap, px_spacing_x_1, px_spacing_y_1, px_spacing_x_2, px_spacing_y_2):\n",
    "    \"\"\"\n",
    "    Create a stitched CT slice from two overlapping slices.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trimmed_slice_1 : ndarray\n",
    "        First CT slice to stitch\n",
    "    trimmed_slice_2 : ndarray \n",
    "        Second CT slice to stitch\n",
    "    final_overlap : int\n",
    "        Number of overlapping pixels between slices\n",
    "    px_spacing_x_1 : float\n",
    "        Pixel spacing in x direction for first slice\n",
    "    px_spacing_y_1 : float\n",
    "        Pixel spacing in y direction for first slice\n",
    "    px_spacing_x_2 : float\n",
    "        Pixel spacing in x direction for second slice\n",
    "    px_spacing_y_2 : float\n",
    "        Pixel spacing in y direction for second slice\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple:\n",
    "        stitched_slice : ndarray\n",
    "            The stitched CT slice\n",
    "        pixel_spacing : tuple\n",
    "            (x_spacing, y_spacing) for the stitched slice\n",
    "    \"\"\"\n",
    "    # Get dimensions of both slices\n",
    "    height1, width1 = trimmed_slice_1.shape\n",
    "    height2, width2 = trimmed_slice_2.shape\n",
    "\n",
    "    # Use the smaller width for both slices\n",
    "    min_width = min(width1, width2)\n",
    "\n",
    "    # Calculate new heights maintaining aspect ratio\n",
    "    if width1 > width2:\n",
    "        new_height1 = int(height1 * (min_width / width1))\n",
    "        trimmed_slice_1 = cv2.resize(trimmed_slice_1, (min_width, new_height1))\n",
    "    elif width2 > width1:\n",
    "        new_height2 = int(height2 * (min_width / width2))\n",
    "        trimmed_slice_2 = cv2.resize(trimmed_slice_2, (min_width, new_height2))\n",
    "\n",
    "    stitched_slice = np.vstack([\n",
    "        trimmed_slice_1,\n",
    "        trimmed_slice_2[final_overlap:]\n",
    "    ])\n",
    "\n",
    "    # Calculate pixel spacing for stitched image - use average of both slices\n",
    "    stitched_px_spacing = ((px_spacing_x_1 + px_spacing_x_2)/2, \n",
    "                          (px_spacing_y_1 + px_spacing_y_2)/2)\n",
    "    \n",
    "    return stitched_slice, stitched_px_spacing\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions for CT data auto stitching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_scan(data_dir, params, segment, scan_name, width_start_pct=0.25, width_end_pct=0.75, max_value_side_trim=1200):\n",
    "    \"\"\"Process a single scan and return the processed data\"\"\"\n",
    "    volume_data, px_spacing_x, px_spacing_y, slice_thickness = load_dicom_files(data_dir)\n",
    "    slice_data = get_slice(volume_data, index=int(len(volume_data[0,0,:])*1/2), axis=2)\n",
    "    \n",
    "    # Trim left and right columns where all values are < max_value_side_trim (outside of the cores)\n",
    "    left_idx = 0\n",
    "    right_idx = slice_data.shape[1]\n",
    "    \n",
    "    for col in range(slice_data.shape[1]):\n",
    "        if (slice_data[:,col] >= max_value_side_trim).any():\n",
    "            left_idx = col\n",
    "            break\n",
    "            \n",
    "    for col in range(slice_data.shape[1]-1, -1, -1):\n",
    "        if (slice_data[:,col] >= max_value_side_trim).any():\n",
    "            right_idx = col + 1\n",
    "            break\n",
    "    \n",
    "    slice_data = slice_data[:, left_idx:right_idx]\n",
    "    \n",
    "    brightness, stddev, trimmed_slice = process_brightness_data(slice_data,\n",
    "                                              px_spacing_y,\n",
    "                                              trim_top=params['trim_top'],\n",
    "                                              trim_bottom=params['trim_bottom'],\n",
    "                                              min_brightness=params['min_brightness'],\n",
    "                                              buffer=params['buffer'],\n",
    "                                              width_start_pct=width_start_pct,\n",
    "                                              width_end_pct=width_end_pct)\n",
    "    \n",
    "    display_slice_bt_std(trimmed_slice, brightness, stddev,\n",
    "                        pixel_spacing=(px_spacing_x, px_spacing_y),\n",
    "                        core_name=f\"{segment} ({scan_name})\")\n",
    "    \n",
    "    return brightness, stddev, trimmed_slice, px_spacing_x, px_spacing_y\n",
    "\n",
    "def process_two_scans(segment_data, segment, mother_dir, width_start_pct=0.25, width_end_pct=0.75, max_value_side_trim=1200, min_overlap=20, max_overlap=450):\n",
    "    \"\"\"Process and stitch two scans together\"\"\"\n",
    "    scans = segment_data['scans']\n",
    "    data_dir_1 = f\"{mother_dir}/{segment}/{scans[0]}\"\n",
    "    data_dir_2 = f\"{mother_dir}/{segment}/{scans[1]}\"\n",
    "    \n",
    "    # Process first scan\n",
    "    bright1, std1, trimmed_slice1, px_spacing_x1, px_spacing_y1 = process_single_scan(\n",
    "        data_dir_1, \n",
    "        segment_data['params'][scans[0]], \n",
    "        segment, \n",
    "        scans[0],\n",
    "        width_start_pct=width_start_pct,\n",
    "        width_end_pct=width_end_pct,\n",
    "        max_value_side_trim=max_value_side_trim\n",
    "    )\n",
    "    \n",
    "    # Process second scan\n",
    "    bright2, std2, trimmed_slice2, px_spacing_x2, px_spacing_y2 = process_single_scan(\n",
    "        data_dir_2,\n",
    "        segment_data['params'][scans[1]],\n",
    "        segment,\n",
    "        scans[1],\n",
    "        width_start_pct=width_start_pct,\n",
    "        width_end_pct=width_end_pct,\n",
    "        max_value_side_trim=max_value_side_trim\n",
    "    )\n",
    "    \n",
    "    # Stitch scans\n",
    "    final_overlap, od1, od2, st_bright, st_std, st_depth, bright2_shifted, std2_shifted = stitch_curves(\n",
    "        bright1, bright2, std1, std2, px_spacing_y1, px_spacing_y2, min_overlap=min_overlap, max_overlap=max_overlap\n",
    "    )\n",
    "    \n",
    "    # Plot and display results\n",
    "    plot_stitched_curves(st_depth, st_bright, st_std,\n",
    "                        bright1, bright2, std1, std2,\n",
    "                        bright2_shifted, std2_shifted,\n",
    "                        final_overlap, od1, od2, px_spacing_y1, px_spacing_y2)\n",
    "\n",
    "    # Create stitched slice\n",
    "    st_slice, pixel_spacing = create_stitched_slice(\n",
    "        trimmed_slice1, trimmed_slice2, final_overlap,\n",
    "        px_spacing_x1, px_spacing_y1, px_spacing_x2, px_spacing_y2\n",
    "    )\n",
    "\n",
    "    # Recalculate brightness and std dev on stitched slice without trimming\n",
    "    st_bright_re, st_std_re, st_slice = process_brightness_data(st_slice, \n",
    "                                                               pixel_spacing[1],\n",
    "                                                               trim_top=0,\n",
    "                                                               trim_bottom=0,\n",
    "                                                               min_brightness=400,\n",
    "                                                               buffer=5,\n",
    "                                                               width_start_pct=width_start_pct,\n",
    "                                                               width_end_pct=width_end_pct)\n",
    "    \n",
    "    # Get depth array from length of recalculated brightness\n",
    "    st_depth_re = np.arange(len(st_bright_re))\n",
    "    \n",
    "    # Display stitched slice with recalculated brightness/std\n",
    "    display_slice_bt_std(st_slice, st_bright_re, st_std_re,\n",
    "                        pixel_spacing=pixel_spacing,\n",
    "                        core_name=f\"{segment} (stitched)\")\n",
    "    \n",
    "    return st_bright_re, st_std_re, st_depth_re, st_slice, pixel_spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_stitch_segments(core_structure, mother_dir, width_start_pct=0.25, width_end_pct=0.75, max_value_side_trim=1200, min_overlap=20, max_overlap=450):\n",
    "    # Dictionary to store stitched results for each core segment\n",
    "    stitched_segments = {}\n",
    "    \n",
    "    # Process each segment\n",
    "    for segment, segment_data in core_structure.items():\n",
    "        print(f\"Processing {segment}\")\n",
    "        \n",
    "        if 'suffixes' not in segment_data:  # Regular segments with one or two scans\n",
    "            if len(segment_data['scans']) == 1:  # Single scan\n",
    "                data_dir = f\"{mother_dir}/{segment}/{segment_data['scans'][0]}\"\n",
    "                brightness, stddev, trimmed_slice, px_spacing_x, px_spacing_y = process_single_scan(\n",
    "                    data_dir,\n",
    "                    segment_data['params'][segment_data['scans'][0]],\n",
    "                    segment,\n",
    "                    segment_data['scans'][0],\n",
    "                    width_start_pct=width_start_pct,\n",
    "                    width_end_pct=width_end_pct,\n",
    "                    max_value_side_trim=max_value_side_trim\n",
    "                )\n",
    "                \n",
    "                # Rescale slice to match rgb dimensions\n",
    "                target_height = segment_data['rgb_pxlength']\n",
    "                target_width = segment_data['rgb_pxwidth']\n",
    "                \n",
    "                rescaled_slice = cv2.resize(trimmed_slice, (target_width, target_height))\n",
    "                \n",
    "                # Interpolate brightness and stddev to match new height\n",
    "                new_bright = np.interp(np.linspace(0, len(brightness)-1, target_height),\n",
    "                                     np.arange(len(brightness)), brightness)\n",
    "                new_std = np.interp(np.linspace(0, len(stddev)-1, target_height),\n",
    "                                  np.arange(len(stddev)), stddev)\n",
    "                \n",
    "                stitched_segments[segment] = {\n",
    "                    'brightness': new_bright,\n",
    "                    'stddev': new_std,\n",
    "                    'depth': np.arange(target_height),  # Use pixel units\n",
    "                    'slice': rescaled_slice,\n",
    "                    'px_spacing': (1, 1)  # Use pixel units\n",
    "                }\n",
    "                \n",
    "                # If upside_down is True, rotate slice and reverse data arrays\n",
    "                if segment_data.get('upside_down', False):\n",
    "                    stitched_segments[segment]['slice'] = cv2.rotate(rescaled_slice, cv2.ROTATE_180)\n",
    "                    stitched_segments[segment]['brightness'] = np.flip(new_bright)\n",
    "                    stitched_segments[segment]['stddev'] = np.flip(new_std)\n",
    "                \n",
    "                # Display rescaled slice\n",
    "                core_name = f\"[UPSIDE DOWN] {segment} (rescaled to {target_height} x {target_width}px)\" if segment_data.get('upside_down', False) else f\"{segment} (rescaled to {target_height} x {target_width}px)\"\n",
    "                display_slice_bt_std(stitched_segments[segment]['slice'], stitched_segments[segment]['brightness'], stitched_segments[segment]['stddev'],\n",
    "                                   pixel_spacing=(1, 1),\n",
    "                                   core_name=core_name)\n",
    "                \n",
    "            else:  # Two scans\n",
    "                st_bright, st_std, st_depth, st_slice, pixel_spacing = process_two_scans(\n",
    "                    segment_data, segment, mother_dir, width_start_pct=width_start_pct, width_end_pct=width_end_pct, max_value_side_trim=max_value_side_trim, min_overlap=min_overlap, max_overlap=max_overlap\n",
    "                )\n",
    "                \n",
    "                # Rescale slice to match rgb dimensions\n",
    "                target_height = segment_data['rgb_pxlength']\n",
    "                target_width = segment_data['rgb_pxwidth']\n",
    "                \n",
    "                rescaled_slice = cv2.resize(st_slice, (target_width, target_height))\n",
    "                \n",
    "                # Interpolate brightness and stddev to match new height\n",
    "                new_bright = np.interp(np.linspace(0, len(st_bright)-1, target_height), \n",
    "                                     np.arange(len(st_bright)), st_bright)\n",
    "                new_std = np.interp(np.linspace(0, len(st_std)-1, target_height),\n",
    "                                  np.arange(len(st_std)), st_std)\n",
    "                \n",
    "                stitched_segments[segment] = {\n",
    "                    'brightness': new_bright,\n",
    "                    'stddev': new_std,\n",
    "                    'depth': np.arange(target_height),  # Use pixel units\n",
    "                    'slice': rescaled_slice,\n",
    "                    'px_spacing': (1, 1)  # Use pixel units\n",
    "                }\n",
    "                \n",
    "                # If upside_down is True, rotate slice and reverse data arrays\n",
    "                if segment_data.get('upside_down', False):\n",
    "                    stitched_segments[segment]['slice'] = cv2.rotate(rescaled_slice, cv2.ROTATE_180)\n",
    "                    stitched_segments[segment]['brightness'] = np.flip(new_bright)\n",
    "                    stitched_segments[segment]['stddev'] = np.flip(new_std)\n",
    "                \n",
    "                # Display rescaled slice\n",
    "                core_name = f\"[UPSIDE DOWN] {segment} (rescaled to {target_height} x {target_width}px)\" if segment_data.get('upside_down', False) else f\"{segment} (rescaled to {target_height} x {target_width}px)\"\n",
    "                display_slice_bt_std(stitched_segments[segment]['slice'], stitched_segments[segment]['brightness'], stitched_segments[segment]['stddev'],\n",
    "                                   pixel_spacing=(1, 1),\n",
    "                                   core_name=core_name)\n",
    "                \n",
    "        else:  # Segments with suffixes (A, B, C or A, B)\n",
    "            print(f\"Processing {segment}: Stitching sections {', '.join(segment_data['suffixes'])}\")\n",
    "            brightness_list = []\n",
    "            stddev_list = []\n",
    "            slice_list = []\n",
    "            \n",
    "            # Process each section\n",
    "            for suffix in segment_data['suffixes']:\n",
    "                folder_name = f\"{segment}{suffix}/{segment_data['scans'][0]}\"\n",
    "                data_dir = f\"{mother_dir}/{folder_name}\"\n",
    "                param_key = f\"{suffix}/{segment_data['scans'][0]}\"\n",
    "                \n",
    "                brightness, stddev, trimmed_slice, px_spacing_x, px_spacing_y = process_single_scan(\n",
    "                    data_dir,\n",
    "                    segment_data['params'][param_key],\n",
    "                    f\"{segment}{suffix}\",\n",
    "                    segment_data['scans'][0],\n",
    "                    width_start_pct=width_start_pct,\n",
    "                    width_end_pct=width_end_pct,\n",
    "                    max_value_side_trim=max_value_side_trim\n",
    "                )\n",
    "                \n",
    "                brightness_list.append(brightness)\n",
    "                stddev_list.append(stddev)\n",
    "                slice_list.append(trimmed_slice)\n",
    "            \n",
    "            if len(segment_data['suffixes']) == 1:  # Only A\n",
    "                # Use data from single section without stitching\n",
    "                st_bright = brightness_list[0]\n",
    "                st_std = stddev_list[0]\n",
    "                st_slice = slice_list[0]\n",
    "                \n",
    "                # Rescale slice to match rgb dimensions\n",
    "                target_height = segment_data['rgb_pxlength']\n",
    "                target_width = segment_data['rgb_pxwidth']\n",
    "                \n",
    "                rescaled_slice = cv2.resize(st_slice, (target_width, target_height))\n",
    "                \n",
    "                # Interpolate brightness and stddev to match new height\n",
    "                new_bright = np.interp(np.linspace(0, len(st_bright)-1, target_height),\n",
    "                                     np.arange(len(st_bright)), st_bright)\n",
    "                new_std = np.interp(np.linspace(0, len(st_std)-1, target_height),\n",
    "                                  np.arange(len(st_std)), st_std)\n",
    "                \n",
    "                stitched_segments[segment] = {\n",
    "                    'brightness': new_bright,\n",
    "                    'stddev': new_std,\n",
    "                    'depth': np.arange(target_height),  # Use pixel units\n",
    "                    'slice': rescaled_slice,\n",
    "                    'px_spacing': (1, 1)  # Use pixel units\n",
    "                }\n",
    "                \n",
    "                # If upside_down is True, rotate slice and reverse data arrays\n",
    "                if segment_data.get('upside_down', False):\n",
    "                    stitched_segments[segment]['slice'] = cv2.rotate(rescaled_slice, cv2.ROTATE_180)\n",
    "                    stitched_segments[segment]['brightness'] = np.flip(new_bright)\n",
    "                    stitched_segments[segment]['stddev'] = np.flip(new_std)\n",
    "                \n",
    "                # Display rescaled slice\n",
    "                core_name = f\"[UPSIDE DOWN] {segment} (rescaled to {target_height} x {target_width}px)\" if segment_data.get('upside_down', False) else f\"{segment} (rescaled to {target_height} x {target_width}px)\"\n",
    "                display_slice_bt_std(stitched_segments[segment]['slice'], stitched_segments[segment]['brightness'], stitched_segments[segment]['stddev'],\n",
    "                                   pixel_spacing=(1, 1),\n",
    "                                   core_name=core_name)\n",
    "                \n",
    "            elif len(segment_data['suffixes']) == 2:  # A and B\n",
    "                # Stitch A and B\n",
    "                final_overlap_ab, od1_ab, od2_ab, st_bright_ab, st_std_ab, st_depth_ab, bright2_shifted_ab, std2_shifted_ab = stitch_curves(\n",
    "                    brightness_list[0], brightness_list[1], \n",
    "                    stddev_list[0], stddev_list[1],\n",
    "                    px_spacing_y, px_spacing_y,  # Add second px_spacing_y parameter\n",
    "                    min_overlap=min_overlap, max_overlap=max_overlap\n",
    "                )\n",
    "                \n",
    "                st_slice_ab, pixel_spacing_ab = create_stitched_slice(\n",
    "                    slice_list[0], slice_list[1],\n",
    "                    final_overlap_ab, px_spacing_x, px_spacing_y, px_spacing_x, px_spacing_y\n",
    "                )\n",
    "                plot_stitched_curves(st_depth_ab, st_bright_ab, st_std_ab,\n",
    "                                   brightness_list[0], brightness_list[1],\n",
    "                                   stddev_list[0], stddev_list[1],\n",
    "                                   bright2_shifted_ab, std2_shifted_ab,\n",
    "                                   final_overlap_ab, od1_ab, od2_ab, px_spacing_y, px_spacing_y)\n",
    "                \n",
    "                # Rescale slice to match rgb dimensions\n",
    "                target_height = segment_data['rgb_pxlength']\n",
    "                target_width = segment_data['rgb_pxwidth']\n",
    "                \n",
    "                rescaled_slice = cv2.resize(st_slice_ab, (target_width, target_height))\n",
    "                \n",
    "                # Interpolate brightness and stddev to match new height\n",
    "                new_bright = np.interp(np.linspace(0, len(st_bright_ab)-1, target_height),\n",
    "                                     np.arange(len(st_bright_ab)), st_bright_ab)\n",
    "                new_std = np.interp(np.linspace(0, len(st_std_ab)-1, target_height),\n",
    "                                  np.arange(len(st_std_ab)), st_std_ab)\n",
    "                \n",
    "                stitched_segments[segment] = {\n",
    "                    'brightness': new_bright,\n",
    "                    'stddev': new_std,\n",
    "                    'depth': np.arange(target_height),  # Use pixel units\n",
    "                    'slice': rescaled_slice,\n",
    "                    'px_spacing': (1, 1)  # Use pixel units\n",
    "                }\n",
    "                \n",
    "                # If upside_down is True, rotate slice and reverse data arrays\n",
    "                if segment_data.get('upside_down', False):\n",
    "                    stitched_segments[segment]['slice'] = cv2.rotate(rescaled_slice, cv2.ROTATE_180)\n",
    "                    stitched_segments[segment]['brightness'] = np.flip(new_bright)\n",
    "                    stitched_segments[segment]['stddev'] = np.flip(new_std)\n",
    "                \n",
    "                # Display rescaled slice\n",
    "                core_name = f\"[UPSIDE DOWN] {segment} (rescaled to {target_height} x {target_width}px)\" if segment_data.get('upside_down', False) else f\"{segment} (rescaled to {target_height} x {target_width}px)\"\n",
    "                display_slice_bt_std(stitched_segments[segment]['slice'], stitched_segments[segment]['brightness'], stitched_segments[segment]['stddev'],\n",
    "                                   pixel_spacing=(1, 1),\n",
    "                                   core_name=core_name)\n",
    "                \n",
    "            else:  # A, B and C\n",
    "                # Stitch A and B first\n",
    "                final_overlap_ab, od1_ab, od2_ab, st_bright_ab, st_std_ab, st_depth_ab, bright2_shifted_ab, std2_shifted_ab = stitch_curves(\n",
    "                    brightness_list[0], brightness_list[1], \n",
    "                    stddev_list[0], stddev_list[1],\n",
    "                    px_spacing_y, px_spacing_y,  # Add second px_spacing_y parameter\n",
    "                    min_overlap=min_overlap, max_overlap=max_overlap\n",
    "                )\n",
    "                \n",
    "                st_slice_ab, pixel_spacing_ab = create_stitched_slice(\n",
    "                    slice_list[0], slice_list[1],\n",
    "                    final_overlap_ab, px_spacing_x, px_spacing_y, px_spacing_x, px_spacing_y\n",
    "                )\n",
    "                plot_stitched_curves(st_depth_ab, st_bright_ab, st_std_ab,\n",
    "                                   brightness_list[0], brightness_list[1],\n",
    "                                   stddev_list[0], stddev_list[1],\n",
    "                                   bright2_shifted_ab, std2_shifted_ab,\n",
    "                                   final_overlap_ab, od1_ab, od2_ab, px_spacing_y, px_spacing_y)\n",
    "                \n",
    "                # Stitch AB with C\n",
    "                final_overlap_abc, od1_abc, od2_abc, st_bright, st_std, st_depth, bright2_shifted_abc, std2_shifted_abc = stitch_curves(\n",
    "                    st_bright_ab, brightness_list[2],\n",
    "                    st_std_ab, stddev_list[2],\n",
    "                    px_spacing_y, px_spacing_y,  # Add second px_spacing_y parameter\n",
    "                    min_overlap=min_overlap, max_overlap=max_overlap\n",
    "                )\n",
    "                \n",
    "                st_slice, pixel_spacing = create_stitched_slice(\n",
    "                    st_slice_ab, slice_list[2],\n",
    "                    final_overlap_abc, px_spacing_x, px_spacing_y, px_spacing_x, px_spacing_y\n",
    "                )\n",
    "                \n",
    "                # Rescale slice to match rgb dimensions\n",
    "                target_height = segment_data['rgb_pxlength']\n",
    "                target_width = segment_data['rgb_pxwidth']\n",
    "                \n",
    "                rescaled_slice = cv2.resize(st_slice, (target_width, target_height))\n",
    "                \n",
    "                # Interpolate brightness and stddev to match new height\n",
    "                new_bright = np.interp(np.linspace(0, len(st_bright)-1, target_height),\n",
    "                                     np.arange(len(st_bright)), st_bright)\n",
    "                new_std = np.interp(np.linspace(0, len(st_std)-1, target_height),\n",
    "                                  np.arange(len(st_std)), st_std)\n",
    "                \n",
    "                stitched_segments[segment] = {\n",
    "                    'brightness': new_bright,\n",
    "                    'stddev': new_std,\n",
    "                    'depth': np.arange(target_height),  # Use pixel units\n",
    "                    'slice': rescaled_slice,\n",
    "                    'px_spacing': (1, 1)  # Use pixel units\n",
    "                }\n",
    "                \n",
    "                plot_stitched_curves(st_depth, st_bright, st_std,\n",
    "                                   st_bright_ab, brightness_list[2],\n",
    "                                   st_std_ab, stddev_list[2],\n",
    "                                   bright2_shifted_abc, std2_shifted_abc,\n",
    "                                   final_overlap_abc, od1_abc, od2_abc, px_spacing_y, px_spacing_y)\n",
    "                \n",
    "                # If upside_down is True, rotate slice and reverse data arrays\n",
    "                if segment_data.get('upside_down', False):\n",
    "                    stitched_segments[segment]['slice'] = cv2.rotate(rescaled_slice, cv2.ROTATE_180)\n",
    "                    stitched_segments[segment]['brightness'] = np.flip(new_bright)\n",
    "                    stitched_segments[segment]['stddev'] = np.flip(new_std)\n",
    "                \n",
    "                # Display rescaled slice\n",
    "                core_name = f\"[UPSIDE DOWN] {segment} (rescaled to {target_height} x {target_width}px)\" if segment_data.get('upside_down', False) else f\"{segment} (rescaled to {target_height} x {target_width}px)\"\n",
    "                display_slice_bt_std(stitched_segments[segment]['slice'], stitched_segments[segment]['brightness'], stitched_segments[segment]['stddev'],\n",
    "                                   pixel_spacing=(1, 1),\n",
    "                                   core_name=core_name)\n",
    "    \n",
    "    # Stack all segments together (from top to bottom)\n",
    "    segment_order = list(core_structure.keys())\n",
    "    print(f\"Stitching all core segments together: {', '.join(segment_order)}\")\n",
    "    final_slices = []\n",
    "    final_brightness = []\n",
    "    final_stddev = []\n",
    "    cumulative_depth = 0\n",
    "    \n",
    "    # Find minimum width among all segments\n",
    "    min_width = min([stitched_segments[seg]['slice'].shape[1] for seg in segment_order])\n",
    "\n",
    "    for segment in segment_order:\n",
    "        data = stitched_segments[segment]\n",
    "        slice_data = data['slice']\n",
    "        \n",
    "        # Calculate scale factors\n",
    "        current_width = slice_data.shape[1]\n",
    "        width_scale = min_width / current_width\n",
    "        \n",
    "        # Rescale slice while preserving aspect ratio\n",
    "        new_height = int(slice_data.shape[0] * width_scale)\n",
    "        slice_data = cv2.resize(slice_data, (min_width, new_height))\n",
    "        final_slices.append(slice_data)\n",
    "        \n",
    "        # Interpolate brightness and stddev to match new height\n",
    "        old_indices = np.arange(len(data['brightness']))\n",
    "        new_indices = np.linspace(0, len(data['brightness'])-1, new_height)\n",
    "        \n",
    "        new_brightness = np.interp(new_indices, old_indices, data['brightness'])\n",
    "        new_stddev = np.interp(new_indices, old_indices, data['stddev'])\n",
    "        \n",
    "        # Adjust depths to be continuous\n",
    "        depths = np.arange(new_height) + cumulative_depth\n",
    "        cumulative_depth = depths[-1]\n",
    "        \n",
    "        final_brightness.extend(new_brightness)\n",
    "        final_stddev.extend(new_stddev)\n",
    "\n",
    "    # Create final stitched arrays\n",
    "    final_stitched_slice = np.vstack(final_slices)\n",
    "    final_stitched_brightness = np.array(final_brightness)\n",
    "    final_stitched_stddev = np.array(final_stddev)\n",
    "    final_stitched_depth = np.arange(len(final_stitched_brightness))  # Use pixel units\n",
    "    \n",
    "    return final_stitched_slice, final_stitched_brightness, final_stitched_stddev, final_stitched_depth, 1, 1  # Use pixel units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Define core CT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-22PC CT data auto-stitiching & data csv table output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"22PC\"\n",
    "# total_length_cm = 501  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders. Order means from top to bottom\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 820, 'trim_bottom': 15, 'min_brightness': 400, 'buffer': 5}   #without cut off the T1 T2, trim_top = 30\n",
    "#         },\n",
    "#         'rgb_pxlength': 4555, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False   #True if the CT image is upside down\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 55, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 10},\n",
    "#             'SE000002': {'trim_top': 20, 'trim_bottom': 55, 'min_brightness': 400, 'buffer': 10}\n",
    "#         },\n",
    "#         'rgb_pxlength': 15050, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 55, 'trim_bottom': 110, 'min_brightness': 400, 'buffer': 10},\n",
    "#             'SE000002': {'trim_top': 120, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 10}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14970, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 45, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 1, 'trim_bottom': 35, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14890, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-23PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"23PC\"\n",
    "# total_length_cm = 783  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders for M9907-23PC\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-6': {\n",
    "#         'scans': ['SE000000'], #without cut off the T0\n",
    "#         # 'scans': ['SE000000', 'SE000002'], #to cut off the T0\n",
    "#         'params': {\n",
    "#             # 'SE000000': {'trim_top': 60, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 5}, #without cut off the T0\n",
    "#             # 'SE000002': {'trim_top': 5, 'trim_bottom': 60, 'min_brightness': 400, 'buffer': 5}  #without cut off the T0\n",
    "#             'SE000000': {'trim_top': 62, 'trim_bottom': 532, 'min_brightness': 400, 'buffer': 5}   #to cut off the T0\n",
    "#         },\n",
    "#         'rgb_pxlength': 6305, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': True\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-5': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 50, 'trim_bottom': 190, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'SE000002': {'trim_top': 150, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14965, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 50, 'trim_bottom': 150, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'SE000002': {'trim_top': 170, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14945, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 50, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 20, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 1, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14890, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 45, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 20, 'trim_bottom': 70, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 11185, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 65, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'SE000002': {'trim_top': 20, 'trim_bottom': 45, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14915, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-25PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"25PC\"\n",
    "# total_length_cm = 797  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-6': {\n",
    "#         # 'scans': ['SE000000', 'SE000002'], \n",
    "#         'scans': ['SE000002'], \n",
    "#         'params': {\n",
    "#             # 'SE000000': {'trim_top': 60, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 50}, \n",
    "#             'SE000002': {'trim_top': 122, 'trim_bottom': 42, 'min_brightness': 400, 'buffer': 3}  \n",
    "#         },\n",
    "#         'rgb_pxlength': 7635, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-5': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 60, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 20, 'trim_bottom': 60, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14958, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 40, 'trim_bottom': 180, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 20, 'trim_bottom': 45, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14955, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 50, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 320, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14860, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 80, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 230, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 11510, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 60, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 1},\n",
    "#             'SE000002': {'trim_top': 100, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 1}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14905, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-11PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"11PC\"\n",
    "# total_length_cm = 439  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 53, 'trim_bottom': 120, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 480, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 13625, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 50, 'trim_bottom': 3, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 360, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 15055, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 40, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 1},\n",
    "#             'SE000002': {'trim_top': 85, 'trim_bottom': 47, 'min_brightness': 400, 'buffer': 1}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14885, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-12PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"12PC\"\n",
    "# total_length_cm = 488  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 882, 'trim_bottom': 45, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 3535, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 45, 'trim_bottom': 3, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 230, 'trim_bottom': 47, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14935, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 37, 'trim_bottom': 150, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 60, 'trim_bottom': 60, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14845, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 47, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 1},\n",
    "#             'SE000002': {'trim_top': 315, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 1}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14870, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-56PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"RR0207\"\n",
    "# core_name = \"56PC\"\n",
    "# total_length_cm = 794  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.15 \n",
    "# width_end_pct=0.85\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders (for RR0207-56PC, core number order is 1 -> 6)\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 40, 'trim_bottom': 200, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 150, 'trim_bottom': 30, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14905, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'suffixes': ['A', 'B'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 37, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 35, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 7885, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 35, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 1, 'trim_bottom': 60, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 15010, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 40, 'trim_bottom': 300, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 100, 'trim_bottom': 27, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 15075, 'rgb_pxwidth': 996,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-5': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 45, 'trim_bottom': 400, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'SE000002': {'trim_top': 600, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 11355, 'rgb_pxwidth': 996,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-6': {\n",
    "#         'scans': ['SE000000', 'SE000002'],  \n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 20, 'trim_bottom': 250, 'min_brightness': 400, 'buffer': 3}, \n",
    "#             'SE000002': {'trim_top': 200, 'trim_bottom': 30, 'min_brightness': 400, 'buffer': 3}  \n",
    "#         },\n",
    "#         'rgb_pxlength': 14900, 'rgb_pxwidth': 996,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-14TC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"14TC\"\n",
    "# total_length_cm = 199  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.3\n",
    "# width_end_pct=0.7\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2022\"\n",
    "\n",
    "# # Define core segments and their scan folders\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'scans': ['SE000000', 'SE000002'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 60, 'trim_bottom':40, 'min_brightness': 450, 'buffer': 2},\n",
    "#             'SE000002': {'trim_top': 300, 'trim_bottom': 42, 'min_brightness': 420, 'buffer': 2}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14785, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'SE000000': {'trim_top': 18, 'trim_bottom': 825, 'min_brightness': 390, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 4705, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-30PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define core information\n",
    "# cruise_name = \"M9907\"\n",
    "# core_name = \"30PC\"\n",
    "# total_length_cm = 781  # Adjust this value based on actual core length\n",
    "# width_start_pct=0.25\n",
    "# width_end_pct=0.75\n",
    "\n",
    "# # Define base path\n",
    "# mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2024\"\n",
    "\n",
    "# # Define core segments and their scan folders\n",
    "# core_structure = {\n",
    "#     f'{cruise_name}-{core_name}-6': {\n",
    "#         'suffixes': ['A', 'B'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 47, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 95, 'min_brightness': 400, 'buffer': 3}\n",
    "#         },\n",
    "#         'rgb_pxlength': 7050, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     },\n",
    "#     f'{cruise_name}-{core_name}-5': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 50, 'trim_bottom': 10, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 20, 'trim_bottom': 50, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14975, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }, \n",
    "#     f'{cruise_name}-{core_name}-4': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 40, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 5, 'trim_bottom': 52, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 15055, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }, \n",
    "#     f'{cruise_name}-{core_name}-3': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 40, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 20, 'trim_bottom': 35, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 14860, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }, \n",
    "#     f'{cruise_name}-{core_name}-2': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 40, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 150, 'trim_bottom': 85, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 11355, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }, \n",
    "#     f'{cruise_name}-{core_name}-1': {\n",
    "#         'suffixes': ['A', 'B', 'C'],\n",
    "#         'scans': ['SE000000'],\n",
    "#         'params': {\n",
    "#             'A/SE000000': {'trim_top': 45, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 5},\n",
    "#             'C/SE000000': {'trim_top': 5, 'trim_bottom': 290, 'min_brightness': 400, 'buffer': 5}\n",
    "#         },\n",
    "#         'rgb_pxlength': 13820, 'rgb_pxwidth': 995,\n",
    "#         'upside_down': False\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M9907-31PC CT data auto-stitiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define core information\n",
    "cruise_name = \"M9907\"\n",
    "core_name = \"31PC\"\n",
    "total_length_cm = 767  # Adjust this value based on actual core length\n",
    "width_start_pct=0.2\n",
    "width_end_pct=0.8\n",
    "\n",
    "# Define base path\n",
    "mother_dir = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/CT_data_2024\"\n",
    "\n",
    "# Define core segments and their scan folders\n",
    "core_structure = {\n",
    "    f'{cruise_name}-{core_name}-6': {\n",
    "        'suffixes': ['A'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 60, 'trim_bottom': 100, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 4215, 'rgb_pxwidth': 995,\n",
    "        'upside_down': True\n",
    "    },\n",
    "    f'{cruise_name}-{core_name}-5': {\n",
    "        'suffixes': ['A', 'B', 'C'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 45, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "            'C/SE000000': {'trim_top': 5, 'trim_bottom': 65, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 14975, 'rgb_pxwidth': 995,\n",
    "        'upside_down': False\n",
    "    }, \n",
    "    f'{cruise_name}-{core_name}-4': {\n",
    "        'suffixes': ['A', 'B', 'C'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 49, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'B/SE000000': {'trim_top': 5, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "            'C/SE000000': {'trim_top': 5, 'trim_bottom': 52, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 14930, 'rgb_pxwidth': 995,\n",
    "        'upside_down': False\n",
    "    }, \n",
    "    f'{cruise_name}-{core_name}-3': {\n",
    "        'suffixes': ['A', 'B', 'C'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 37, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "            'C/SE000000': {'trim_top': 5, 'trim_bottom': 45, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 14905, 'rgb_pxwidth': 995,\n",
    "        'upside_down': False\n",
    "    }, \n",
    "    f'{cruise_name}-{core_name}-2': {\n",
    "        'suffixes': ['A', 'B', 'C'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 45, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'B/SE000000': {'trim_top': 1, 'trim_bottom': 5, 'min_brightness': 400, 'buffer': 3},\n",
    "            'C/SE000000': {'trim_top': 5, 'trim_bottom': 65, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 11430, 'rgb_pxwidth': 995,\n",
    "        'upside_down': False\n",
    "    }, \n",
    "    f'{cruise_name}-{core_name}-1': {\n",
    "        'suffixes': ['A', 'B', 'C'],\n",
    "        'scans': ['SE000000'],\n",
    "        'params': {\n",
    "            'A/SE000000': {'trim_top': 35, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'B/SE000000': {'trim_top': 1, 'trim_bottom': 1, 'min_brightness': 400, 'buffer': 3},\n",
    "            'C/SE000000': {'trim_top': 1, 'trim_bottom': 40, 'min_brightness': 400, 'buffer': 3}\n",
    "        },\n",
    "        'rgb_pxlength': 15025, 'rgb_pxwidth': 995,\n",
    "        'upside_down': False\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and stitch all segments\n",
    "final_stitched_slice, final_stitched_brightness, final_stitched_stddev, final_stitched_depth, px_spacing_x, px_spacing_y = process_and_stitch_segments(core_structure, mother_dir, \n",
    "                                                                                                                                                       width_start_pct=width_start_pct, \n",
    "                                                                                                                                                       width_end_pct=width_end_pct, \n",
    "                                                                                                                                                       max_value_side_trim=1300,\n",
    "                                                                                                                                                       min_overlap=10,\n",
    "                                                                                                                                                       max_overlap=200\n",
    "                                                                                                                                                       )\n",
    "\n",
    "\n",
    "# Create csv output directory if it doesn't exist\n",
    "output_dir_base = \"/Users/larryslai/Library/CloudStorage/Dropbox/My Documents/University of Texas Austin/(Project) NWP turbidites/Cascadia_core_data/OSU_dataset/_compiled_logs\"\n",
    "stitched_core_folder = f\"{cruise_name}-{core_name}\"\n",
    "output_dir = os.path.join(output_dir_base, stitched_core_folder)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Display & save final stitched results\n",
    "display_slice_bt_std(final_stitched_slice,\n",
    "                    final_stitched_brightness,\n",
    "                    final_stitched_stddev,\n",
    "                    pixel_spacing=(px_spacing_x, px_spacing_y),\n",
    "                    core_name=f\"{cruise_name}-{core_name}_CT\",\n",
    "                    save_figs = True,\n",
    "                    output_dir = output_dir)\n",
    "\n",
    "# Convert depth from pixels to cm\n",
    "depth_cm = final_stitched_depth * (total_length_cm / final_stitched_depth[-1])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'SB_DEPTH_pxl': final_stitched_depth,\n",
    "    'SB_DEPTH_cm': depth_cm,\n",
    "    'CT': final_stitched_brightness,\n",
    "    'CT_std': final_stitched_stddev\n",
    "})\n",
    "\n",
    "# Save stitched data into CSV\n",
    "output_file = os.path.join(output_dir, f'{cruise_name}-{core_name}_CT.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"CT data saved to: ~/{'/'.join(output_file.split('/')[-3:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Archived:** Another pattern matching method: Cross-Correlation (not used in stitching CT data)\n",
    "\n",
    "Cross-correlation measures the similarity between two signals as a function of the displacement of one relative to the other. For two discrete signals $f[n]$ and $g[n]$, the cross-correlation is defined as:\n",
    "\n",
    "$$(f \\star g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m]g[m+n]$$\n",
    "\n",
    "where $n$ represents the lag or displacement between signals.\n",
    "\n",
    "In our implementation:\n",
    "- $f[n]$ represents the y-values of Dataset 1\n",
    "- $g[n]$ represents the y-values of Dataset 2\n",
    "- The lag $n$ that maximizes $(f \\star g)[n]$ indicates the optimal alignment\n",
    "\n",
    "## Dataset Stitching Process\n",
    "\n",
    "1. **Finding Optimal Shift**: \n",
    "   - Calculate cross-correlation between datasets\n",
    "   - Find lag $n_{max}$ that maximizes correlation\n",
    "   - Convert lag to x-coordinate shift: $x_{shift} = x_1[0] - x_2[0] + n_{max}\\Delta x$\n",
    "   where $\\Delta x$ is the x-spacing between points\n",
    "\n",
    "2. **Overlapping Region Treatment**:\n",
    "   - Define overlap bounds: $[x_{overlap,min}, x_{overlap,max}]$\n",
    "   - For overlapping region, final values are computed as:\n",
    "   $y_{final}(x) = \\frac{y_1(x) + y_2(x)}{2}$\n",
    "   where $y_1(x)$ and $y_2(x)$ are interpolated values from respective datasets\n",
    "\n",
    "The resulting stitched dataset combines:\n",
    "- Dataset 1 values for $x < x_{overlap,min}$\n",
    "- Averaged values for $x_{overlap,min} \\leq x \\leq x_{overlap,max}$\n",
    "- Shifted Dataset 2 values for $x > x_{overlap,max}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample Data Creation\n",
    "# def create_dataset(start, end, num_points=150, noise_std=0.25):\n",
    "#     \"\"\"Create a dataset with regular sinusoidal patterns and noise\"\"\"\n",
    "#     x = np.linspace(start, end, num_points)\n",
    "#     y = (np.sin(x) + \n",
    "#          0.5 * np.sin(2*x) + \n",
    "#          0.3 * np.sin(3*x) + \n",
    "#          np.random.normal(0, noise_std, size=x.shape))\n",
    "#     return x, y\n",
    "\n",
    "# # Dataset 1 - First time series\n",
    "# x1, y1 = create_dataset(0, 10)\n",
    "\n",
    "# # Dataset 2 - Second time series with phase shift\n",
    "# x2, y2 = create_dataset(15, 25)\n",
    "\n",
    "# # Convert to DataFrames for easier manipulation\n",
    "# df1 = pd.DataFrame({'x': x1, 'y': y1})\n",
    "# df2 = pd.DataFrame({'x': x2, 'y': y2})\n",
    "\n",
    "# # Plot Dataset 1\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(df1['x'], df1['y'], label='Dataset 1', color='blue')\n",
    "# plt.title('Dataset 1')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot Dataset 2\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(df2['x'], df2['y'], label='Dataset 2', color='green')\n",
    "# plt.title('Dataset 2')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Function to find the largest matching pattern between datasets using dynamic time warping\n",
    "# def find_largest_pattern_match(df1, df2):\n",
    "#     \"\"\"Find the largest matching pattern between two datasets using cross-correlation\"\"\"\n",
    "#     # Get the y values\n",
    "#     y1 = df1['y'].values\n",
    "#     y2 = df2['y'].values\n",
    "    \n",
    "#     # Calculate cross-correlation\n",
    "#     correlation = correlate(y1, y2, mode='full')\n",
    "    \n",
    "#     # Find the peak correlation and corresponding lag\n",
    "#     max_corr_idx = np.argmax(correlation)\n",
    "#     lag = max_corr_idx - (len(y2) - 1)\n",
    "    \n",
    "#     # Calculate the optimal shift in x coordinates\n",
    "#     x_shift = df1['x'].iloc[0] - df2['x'].iloc[0] + lag * (df1['x'].iloc[1] - df1['x'].iloc[0])\n",
    "    \n",
    "#     return x_shift, np.max(correlation)\n",
    "\n",
    "# def stitch_datasets(df1, df2):\n",
    "#     \"\"\"Stitch two datasets together using pattern matching\"\"\"\n",
    "#     # Find optimal shift\n",
    "#     x_shift, correlation_score = find_largest_pattern_match(df1, df2)\n",
    "    \n",
    "#     # Apply the shift to dataset 2\n",
    "#     df2_shifted = df2.copy()\n",
    "#     df2_shifted['x'] = df2_shifted['x'] + x_shift\n",
    "    \n",
    "#     # Find overlapping region\n",
    "#     x_overlap_min = max(df1['x'].min(), df2_shifted['x'].min())\n",
    "#     x_overlap_max = min(df1['x'].max(), df2_shifted['x'].max())\n",
    "    \n",
    "#     # Create high-resolution x points for overlapping region\n",
    "#     x_common = np.linspace(x_overlap_min, x_overlap_max, 1000)\n",
    "    \n",
    "#     # Interpolate y values\n",
    "#     y1_interp = np.interp(x_common, df1['x'], df1['y'])\n",
    "#     y2_interp = np.interp(x_common, df2_shifted['x'], df2_shifted['y'])\n",
    "    \n",
    "#     # Weighted average in overlapping region\n",
    "#     y_avg = (y1_interp + y2_interp) / 2\n",
    "    \n",
    "#     # Create separate DataFrames for non-overlapping regions\n",
    "#     df1_left = df1[df1['x'] < x_overlap_min]\n",
    "#     df2_right = df2_shifted[df2_shifted['x'] > x_overlap_max]\n",
    "    \n",
    "#     # Create DataFrame for overlapping region\n",
    "#     df_overlap = pd.DataFrame({'x': x_common, 'y': y_avg})\n",
    "    \n",
    "#     # Combine all parts to create stitched dataset\n",
    "#     df_stitched = pd.concat([df1_left, df_overlap, df2_right]).sort_values('x').reset_index(drop=True)\n",
    "    \n",
    "#     return df_stitched, x_shift, correlation_score\n",
    "\n",
    "# # Stitch the datasets\n",
    "# df_stitched, x_shift, correlation_score = stitch_datasets(df1, df2)\n",
    "\n",
    "# print(f\"Optimal x-shift: {x_shift:.2f}\")\n",
    "# print(f\"Correlation score: {correlation_score:.2f}\")\n",
    "\n",
    "# # Plot final result\n",
    "# plt.figure(figsize=(7, 3))\n",
    "# plt.plot(df1['x'], df1['y'], label='Dataset 1', color='blue', alpha=0.5)\n",
    "# plt.plot(df2['x'] + x_shift, df2['y'], label='Dataset 2', color='green', alpha=0.5)\n",
    "# plt.plot(df_stitched['x'], df_stitched['y'], label='Stitched Dataset', color='red', linewidth=2)\n",
    "# plt.title('Stitched Dataset with Optimal Pattern Matching')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # # Print the stitched data\n",
    "# # print(\"\\nStitched Data (first 10 rows):\")\n",
    "# # print(df_stitched.head(10))\n",
    "# # print(\"\\nStitched Data (last 10 rows):\")\n",
    "# # print(df_stitched.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
